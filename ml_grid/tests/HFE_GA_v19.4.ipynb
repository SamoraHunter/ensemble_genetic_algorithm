{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa90b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Get the parent directory of the current directory\n",
    "# parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# # Get the parent directory of the parent directory\n",
    "# grandparent_dir = os.path.abspath(os.path.join(parent_dir, os.pardir))\n",
    "\n",
    "# # Path to requirements.txt file two directories up\n",
    "# requirements_file = os.path.join(grandparent_dir, 'requirements.txt')\n",
    "# requirements_file ='/home/samorah/_data/gloabl_files/ensemble_genetic_algorithm/requirements.txt'\n",
    "# # Open the requirements file and iterate over lines\n",
    "# with open(requirements_file, 'r') as f:\n",
    "#     for line in f:\n",
    "#         # Remove any leading/trailing whitespace and ignore comments or empty lines\n",
    "#         line = line.strip()\n",
    "#         if not line or line.startswith('#'):\n",
    "#             continue\n",
    "        \n",
    "#         # Try to install the package using %pip magic\n",
    "#         try:\n",
    "#             %pip install {line}\n",
    "#             print(f\"Successfully installed {line}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to install {line}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ec4f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\admin1\\\\Documents\\\\projects\\\\ensemble_genetic_algorithm\\\\ml_grid\\\\tests'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfa5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "#os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb18461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\admin1\\\\Documents\\\\projects\\\\ensemble_genetic_algorithm\\\\ml_grid'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afec0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e15edfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436402bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '30'\n",
    "\n",
    "#!jupyter nbconvert --to script geHFE.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f68280",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd4f892",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import date, datetime\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from operator import attrgetter, itemgetter\n",
    "from pathlib import Path\n",
    "from sys import getsizeof\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import pydotplus\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from deap import algorithms, base, creator, tools\n",
    "#from genetic_selection import GeneticSelectionCV#\n",
    "# from keras.layers import Dense\n",
    "# from keras.models import Sequential\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import absolute, asarray, loadtxt, mean, std\n",
    "from numpy.linalg import norm\n",
    "from pandas import DataFrame\n",
    "from scipy import stats\n",
    "from scoop import futures\n",
    "from sklearn import (datasets, feature_selection, linear_model, metrics, svm,\n",
    "                     tree)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import (ElasticNet, LinearRegression,\n",
    "                                  LogisticRegression, Perceptron)\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, matthews_corrcoef,\n",
    "                             mean_squared_error, #plot_confusion_matrix,\n",
    "                             precision_recall_curve, r2_score, roc_auc_score,\n",
    "                             roc_curve)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, RepeatedKFold,\n",
    "                                     RepeatedStratifiedKFold,\n",
    "                                     cross_val_predict, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import logging\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import traceback\n",
    "from fuzzysearch import find_near_matches#\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "import pathlib\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import itertools as it\n",
    "import datetime\n",
    "import pathlib\n",
    "from fuzzysearch import find_near_matches\n",
    "from scipy.stats import skewnorm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444395a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d73044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88621157",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "random.seed()\n",
    "\n",
    "\n",
    "debug = True\n",
    "model_train_time_warning_threshold = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e275cb74",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-01 1.e-03 1.e-05]\n",
      "[True, False]\n",
      "[  1  10 100]\n",
      "[100 144 208 301 436 630]\n",
      "[ 1  2  5 13 31]\n",
      "[ 1  5 31]\n",
      "[0.1        0.31622777 1.        ]\n",
      "[0.001  0.0505 0.1   ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "log_small = np.logspace(-1, -5, 3)\n",
    "print(log_small)\n",
    "bool_param = [True, False]\n",
    "print(bool_param)\n",
    "log_large = np.logspace(0, 2, 3).astype(int)\n",
    "print(log_large)\n",
    "log_large_long = np.floor(np.logspace(2, 2.8, 6)).astype(int)\n",
    "print(log_large_long)\n",
    "log_med_long = np.floor(np.logspace(0, 1.5, 5)).astype(int)\n",
    "print(log_med_long)\n",
    "log_med = np.floor(np.logspace(0, 1.5, 3)).astype(int)\n",
    "print(log_med)\n",
    "nstep = 3\n",
    "log_zero_one = np.logspace(0.0, 1.0, nstep) / 10\n",
    "print(log_zero_one)\n",
    "lin_zero_one = np.linspace(0.01, 1.0, nstep) / 10\n",
    "print(lin_zero_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ab443c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d1702c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_free_gpu():\n",
    "    gpu_stats = subprocess.check_output([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"])\n",
    "    gpu_df = pd.read_csv(StringIO(gpu_stats.decode('utf-8')),\n",
    "                         names=['memory.used', 'memory.free'],\n",
    "                         skiprows=1)\n",
    "    #print('GPU usage:\\n{}'.format(gpu_df))\n",
    "    gpu_df['memory.free'] = gpu_df['memory.free'].map(lambda x: x.rstrip(' [MiB]'))\n",
    "    idx = gpu_df['memory.free'].astype(int).idxmax()\n",
    "    print('Returning GPU{} with {} free MiB'.format(idx, gpu_df.iloc[idx]['memory.free']))\n",
    "    return int(idx)\n",
    "\n",
    "\n",
    "def ratioFunction(num1, num2):\n",
    "    #num1 = input('Enter the first number: ')\n",
    "    if (num1 == 0 or num2 == 0):\n",
    "        #print(\"zero found\")\n",
    "        return np.nan\n",
    "    num1 = float(num1)  # Now we are good\n",
    "    #num2 = input('Enter the second number: ')\n",
    "    num2 = float(num2)  # Good, good\n",
    "    ratio12 = float(num1/num2)\n",
    "    #print('The ratio of', str(num1), 'and', str(num2),'is', ratio12 + '.')\n",
    "    return ratio12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c3640f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def getNfeaturesANOVAF(n):\n",
    "    res = []\n",
    "    for colName in X_train.columns:\n",
    "        if colName != \"intercept\":\n",
    "            res.append(\n",
    "                (\n",
    "                    colName,\n",
    "                    sklearn.feature_selection.f_classif(\n",
    "                        np.array(X_train[colName]).reshape(-1, 1), y_train\n",
    "                    )[0],\n",
    "                )\n",
    "            )\n",
    "    sortedList = sorted(res, key=lambda x: x[1])\n",
    "    sortedList.reverse()\n",
    "    nFeatures = sortedList[:n]\n",
    "    finalColNames = []\n",
    "    for elem in nFeatures:\n",
    "        finalColNames.append(elem[0])\n",
    "    return finalColNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ddd3b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def getRandomForestFeatureColumns(X, y, n):\n",
    "    try:\n",
    "        X = X.drop(\"index\", axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    independentVariables = X\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    forest = RandomForestClassifier(random_state=1)\n",
    "    forest.fit(X_train, y_train)\n",
    "    importances = forest.feature_importances_\n",
    "    namedFeatures = []\n",
    "    for i in range(0, len(X_train.columns)):\n",
    "        namedFeatures.append((list(X_train.columns)[i], importances[i]))\n",
    "    sortedNamedFeatures = sorted(namedFeatures, key=itemgetter(1))\n",
    "    sortedNamedFeatures.reverse()\n",
    "    nFeatures = sortedNamedFeatures[:n]\n",
    "    finalColNames = []\n",
    "    for elem in nFeatures:\n",
    "        finalColNames.append(elem[0])\n",
    "    return finalColNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "319c568c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def getXGBoostFeatureColumns(X, y, n):\n",
    "    try:\n",
    "        X = X.drop(\"index\", axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model = XGBClassifier()\n",
    "        model.fit(X, y)\n",
    "        importances = model.feature_importances_\n",
    "        namedFeatures = []\n",
    "        for i in range(0, len(X_train.columns)):\n",
    "            namedFeatures.append((list(X_train.columns)[i], importances[i]))\n",
    "        sortedNamedFeatures = sorted(namedFeatures, key=itemgetter(1))\n",
    "        sortedNamedFeatures.reverse()\n",
    "        nFeatures = sortedNamedFeatures[:n]\n",
    "        finalColNames = []\n",
    "        for elem in nFeatures:\n",
    "            finalColNames.append(elem[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Failed to get xgboost feature columns\")\n",
    "\n",
    "    return finalColNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22e13cbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def getExtraTreesFeatureColumns(X, y, n):\n",
    "    independentVariables = X\n",
    "\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    try:\n",
    "        X = X.drop(\"index\", axis=1)\n",
    "    except:\n",
    "        X = X\n",
    "    forest = ExtraTreesClassifier(random_state=1)\n",
    "    forest.fit(X_train, y_train)\n",
    "    importances = forest.feature_importances_\n",
    "    namedFeatures = []\n",
    "    for i in range(0, len(X_train.columns)):\n",
    "        namedFeatures.append((list(X_train.columns)[i], importances[i]))\n",
    "    sortedNamedFeatures = sorted(namedFeatures, key=itemgetter(1))\n",
    "    sortedNamedFeatures.reverse()\n",
    "\n",
    "    #     xFeatureColNames = []\n",
    "    #     for i in range(0, n):\n",
    "    #         xFeatureColNames.append(sortedNamedFeatures[i][0])\n",
    "    nFeatures = sortedNamedFeatures[:n]\n",
    "    finalColNames = []\n",
    "    for elem in nFeatures:\n",
    "        finalColNames.append(elem[0])\n",
    "    return finalColNames\n",
    "\n",
    "\n",
    "# # Base learner and ensemble generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e673883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featured_selected_training_data(method='anova'):\n",
    "    \n",
    "    \n",
    "    #global X_train, X_test, y_train, y_test\n",
    "        # Select n features------------------------------------------------------------------------\n",
    "    f = feature_parameter_vector\n",
    "    nFeatures = random.choice(f)\n",
    "    if(method=='anova'):\n",
    "        xFeatureColumnNames = getNfeaturesANOVAF(\n",
    "            nFeatures)\n",
    "    \n",
    "    elif(method=='randomforest'):\n",
    "        xFeatureColumnNames = getRandomForestFeatureColumns(\n",
    "        X_train, y_train, nFeatures\n",
    "    )\n",
    "    elif(method=='extratrees'):\n",
    "        xFeatureColumnNames = getExtraTreesFeatureColumns(\n",
    "        X_train, y_train, nFeatures\n",
    "    )\n",
    "    elif(method=='xgb'):\n",
    "        xFeatureColumnNames = getXGBoostFeatureColumns(\n",
    "        X_train, y_train, nFeatures\n",
    "    )\n",
    "        \n",
    "        \n",
    "    X_train_fs = X_train[xFeatureColumnNames].copy()\n",
    "    X_test_fs = X_test[xFeatureColumnNames].copy()\n",
    "    \n",
    "    return X_train_fs, X_test_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc9f1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_base_learner(model, mccscore, X_train, auc_score, model_train_time):\n",
    "    print(str(model).split(\"(\")[0], round(mccscore, 5), len(X_train.columns), auc_score, model_train_time)\n",
    "    if(model_train_time> model_train_time_warning_threshold):\n",
    "        print(\"Warning long train time, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9066b9f3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def perceptronModelGen():\n",
    "    start = time.time()\n",
    "\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "\n",
    "    # Initialise parameter space----------------------------------------------------------------\n",
    "    maxIterList = [5, 7, 10, 12, 15, 20, 25, 50, 75]\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    # Apply the scaler to the X training data\n",
    "    X_train_std = sc.transform(X_train)\n",
    "\n",
    "    # Apply the SAME scaler to the X test data\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    # Create a perceptron object with the parameters: n iterations (epochs) over the data, and a learning rate of 0.1\n",
    "    model = Perceptron(max_iter=random.choice(\n",
    "        maxIterList), eta0=0.1, random_state=0)\n",
    "\n",
    "    # Train the perceptron--------------------------------------------------------------------\n",
    "    model.fit(X_train_std, y_train)\n",
    "    y_train_hat = model.predict(X_train)# predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97b2f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perceptronModelGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92e5e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_model(mccscore, model, feature_list, model_train_time, auc_score, y_pred, model_type='sklearn'): #**kwargs ):\n",
    "    #print(kwargs)\n",
    "    #torch=kwargs['torch'], \n",
    "    #xgb=kwargs['xgb']\n",
    "    \n",
    "    \n",
    "    with open(model_store_path, 'r') as f:\n",
    "        model_store_data = json.load(f)\n",
    "    \n",
    "    idx = len(model_store_data['models']) + 1\n",
    "    \n",
    "    time_stamp =  time.time_ns() \n",
    "    \n",
    "    \n",
    "    if(model_type=='sklearn'):\n",
    "        model = str(model)\n",
    "    \n",
    "    elif(model_type=='torch'):\n",
    "        y_pred = y_pred.astype(float)\n",
    "        torch.save(model, f=f\"{global_param_str + additional_naming}/\"+\"/torch/\"+str(time_stamp))\n",
    "        model=time_stamp\n",
    "        \n",
    "    elif(model_type=='xgb'):    \n",
    "        pickle.dump(model, open(f\"{global_param_str + additional_naming}/\"+\"/xgb/\"+str(time_stamp), \"wb\"))\n",
    "        model=time_stamp\n",
    "        y_pred = y_pred.astype(float)\n",
    "        \n",
    "    #print(type(model))\n",
    "    scale = global_param_dict.get('scale')\n",
    "    if(scale):\n",
    "        y_pred = y_pred.astype(float)\n",
    "    \n",
    "    model_store_entry = {\n",
    "        'index':idx,\n",
    "        'mcc_score':mccscore,\n",
    "        'model': model, \n",
    "        'feature_list':feature_list,\n",
    "        'model_train_time':model_train_time,\n",
    "        'auc_score':auc_score,\n",
    "        'y_pred': list(y_pred),\n",
    "        'model_type': model_type,\n",
    "\n",
    "    }\n",
    "    #print(model_store_entry)\n",
    "    \n",
    "    model_store_data['models'].update({idx: model_store_entry})\n",
    "    \n",
    "    jsonString = json.dumps(model_store_data)\n",
    "    jsonFile = open(model_store_path, \"w\", encoding='utf-8')\n",
    "    jsonFile.write(jsonString)\n",
    "    jsonFile.close()\n",
    "    \n",
    "    torch.cuda.empty_cache() #exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f7fbc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stored_model():\n",
    "    \n",
    "    with open(model_store_path, 'r', encoding='utf-8') as f:\n",
    "        model_store_data = json.load(f)\n",
    "    \n",
    "    model_key_list = list(model_store_data['models'].keys())\n",
    "    \n",
    "    try:\n",
    "        model_key = str(random.choice(model_key_list))\n",
    "\n",
    "        print(f\"Returning stored model at index {model_key}/{len(model_key_list)}\")\n",
    "        \n",
    "         \n",
    "        \n",
    "        if(model_store_data['models'].get(model_key)['model_type'] == 'sklearn'):\n",
    "            model = eval(model_store_data['models'].get(model_key)['model'])\n",
    "            \n",
    "        elif(model_store_data['models'].get(model_key)['model_type'] == 'torch'):\n",
    "            time_stamp = model_store_data['models'].get(model_key)['model']\n",
    "            model = torch.load(f=f\"{global_param_str + additional_naming}/\"+\"/torch/\"+str(time_stamp))\n",
    "            \n",
    "        elif(model_store_data['models'].get(model_key)['model_type'] == 'xgb'):\n",
    "            time_stamp = model_store_data['models'].get(model_key)['model']\n",
    "            model = pickle.load(open(f\"{global_param_str + additional_naming}/\"+\"/xgb/\"+str(time_stamp), \"rb\"))\n",
    "            \n",
    "        \n",
    "\n",
    "        return (model_store_data['models'].get(model_key)['mcc_score'],\n",
    "                model,\n",
    "               model_store_data['models'].get(model_key)['feature_list'],\n",
    "               model_store_data['models'].get(model_key)['model_train_time'],\n",
    "               model_store_data['models'].get(model_key)['auc_score'],\n",
    "                np.array(model_store_data['models'].get(model_key)['y_pred'])\n",
    "               )\n",
    "    except Exception as e:\n",
    "        print(\"Failed inside getting stored model, returning random new model\")\n",
    "        index = random.randint(0, len(modelFuncList)-1)\n",
    "\n",
    "\n",
    "        return modelFuncList[index]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48dfd519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def perceptronModelGen_dummy():\n",
    "    start = time.time()\n",
    "\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "\n",
    "    # Initialise parameter space----------------------------------------------------------------\n",
    "    maxIterList = [5, 7, 10, 12, 15, 20, 25, 50, 75]\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    # Apply the scaler to the X training data\n",
    "    X_train_std = sc.transform(X_train)\n",
    "\n",
    "    # Apply the SAME scaler to the X test data\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    # Create a perceptron object with the parameters: n iterations (epochs) over the data, and a learning rate of 0.1\n",
    "    model = Perceptron(max_iter=random.choice(\n",
    "        maxIterList), eta0=0.1, random_state=0)\n",
    "\n",
    "    # Train the perceptron--------------------------------------------------------------------\n",
    "    model.fit(X_train_std, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    \n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            #print(sample_parameter_space)\n",
    "#     if(store_base_learners):\n",
    "#         store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred) #Don't store dummy\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaaadab4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extraTreesModelGen():\n",
    "    start = time.time()\n",
    "    # Import base data set and outcome variable-----------------------------------------------\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise parameter space-----------------------------------------------------------------\n",
    "    seed = 7\n",
    "    num_trees = 30\n",
    "    max_features_n = random.choice(list(np.arange(0.05, 0.2, 0.001)))\n",
    "    min_samples_leaf_n = random.choice([2, 5, 8, 10, 15, 20, 25, 40, 50])\n",
    "    n_estimators_n = random.choice(\n",
    "        [\n",
    "            10,\n",
    "            20,\n",
    "            30,\n",
    "            40,\n",
    "            50,\n",
    "            60,\n",
    "            70,\n",
    "            80,\n",
    "            90,\n",
    "            100,\n",
    "            125,\n",
    "            150,\n",
    "            175,\n",
    "            200,\n",
    "            225,\n",
    "            250,\n",
    "            275,\n",
    "            300,\n",
    "            325,\n",
    "            350,\n",
    "            375,\n",
    "            400,\n",
    "            425,\n",
    "            450,\n",
    "            475,\n",
    "            500,\n",
    "            550,\n",
    "            600,\n",
    "            650,\n",
    "            700,\n",
    "        ]\n",
    "    )\n",
    "    max_depth_n = random.choice([2, 4, 8, 10, None])\n",
    "    class_weight_n = random.choice([\"balanced\"])\n",
    "\n",
    "    # warm_start = True\n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=n_estimators_n,\n",
    "        max_features=max_features_n,\n",
    "        min_samples_leaf=min_samples_leaf_n,\n",
    "        max_depth=max_depth_n,\n",
    "        class_weight=class_weight_n,\n",
    "    )\n",
    "\n",
    "    # Fit model-------------------------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    # print(score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "316f071f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def logModelGen():\n",
    "    start = time.time()\n",
    "    \n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise parameter space-----------------------------------------------------------------\n",
    "    solver_n = random.choice([\"sag\"])\n",
    "    class_weight_n = random.choice([\"balanced\"])\n",
    "    max_iter_n = random.choice([5, 7, 10, 12, 15, 20, 25, 50, 75])\n",
    "    C_n = random.choice([1e-5, 1e-4, 1e-3, 1e-2, 1e1,\n",
    "                        1, 1e1, 1e2, 1e3, 1e4, 1e5])\n",
    "    model = LogisticRegression(\n",
    "        solver=solver_n, class_weight=class_weight_n, max_iter=max_iter_n, C=C_n\n",
    "    )\n",
    "\n",
    "    # Fit model---------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    # print(score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            #print(sample_parameter_space)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce237a1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def randomForestModelGen():\n",
    "    start = time.time()\n",
    "    # Import base data set and outcome variable-----------------------------------------------\n",
    "    X_train, X_test = get_featured_selected_training_data(method='randomforest')\n",
    "    \n",
    "    # Initialise parameter space-----------------------------------------------------------------\n",
    "    num_trees = 30\n",
    "    max_features_n = random.choice(list(np.arange(0.05, 0.2, 0.001)))\n",
    "    min_samples_leaf_n = random.choice([2, 5, 8, 10, 15, 20, 25, 40, 50])\n",
    "    n_estimators_n = random.choice(\n",
    "        [\n",
    "            10,\n",
    "            20,\n",
    "            30,\n",
    "            40,\n",
    "            50,\n",
    "            60,\n",
    "            70,\n",
    "            80,\n",
    "            90,\n",
    "            100,\n",
    "            125,\n",
    "            150,\n",
    "            175,\n",
    "            200,\n",
    "            225,\n",
    "            250,\n",
    "            275,\n",
    "            300,\n",
    "            325,\n",
    "            350,\n",
    "            375,\n",
    "            400,\n",
    "            425,\n",
    "            450,\n",
    "            475,\n",
    "            500,\n",
    "            550,\n",
    "            600,\n",
    "            650,\n",
    "            700,\n",
    "        ]\n",
    "    )\n",
    "    max_depth_n = random.choice([2, 4, 8, 10, None])\n",
    "    class_weight_n = random.choice([\"balanced\"])\n",
    "\n",
    "    # warm_start = True\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators_n,\n",
    "        max_features=max_features_n,\n",
    "        min_samples_leaf=min_samples_leaf_n,\n",
    "        max_depth=max_depth_n,\n",
    "        class_weight=class_weight_n,\n",
    "    )\n",
    "\n",
    "    # Fit model-------------------------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    # print(score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4367db53",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kNearestNeighborsModelGen(*kwargs):\n",
    "    \n",
    "    start = time.time()\n",
    "    #print(\"Calling knn at \", start)\n",
    "    # Import base data set and outcome variable-----------------------------------------------\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise parameter space-----------------------------------------------------------------\n",
    "    n_neighbours_n = random.choice(\n",
    "        [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 50, 100]\n",
    "    )\n",
    "    \n",
    "    mccscore = 0\n",
    "    auc_score = 0.5\n",
    "    model_train_time = 0\n",
    "\n",
    "    if(n_neighbours_n > len(X_train)):\n",
    "        n_neighbours_n = len(X_train)-1\n",
    "        print(\"warning kNearestNeighborsModelGen\", \"nn > sample\")\n",
    "    \n",
    "    \n",
    "    weights_n = random.choice([\"uniform\", \"distance\"])\n",
    "    try:\n",
    "        #print(\"Creating knn model\")\n",
    "         # warm_start = True\n",
    "        model = KNeighborsClassifier(n_neighbors=n_neighbours_n, weights=weights_n, n_jobs=1)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to fit knn\")\n",
    "        print(e)\n",
    "   \n",
    "    try:\n",
    "        #print(\"Fitting knn\")\n",
    "        # Fit model-------------------------------------------------------------------------------------\n",
    "        #print(kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to fit knn\")\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "    #score = model.score(X_test, y_test)\n",
    "    # print(score)\n",
    "    #print(model.__dict__)\n",
    "    \n",
    "    \n",
    "    try:    \n",
    "        #print(\"predicting x test\")\n",
    "        #print(kwargs)\n",
    "        #display(X_test)\n",
    "        #y_train_hat = model.predict(X_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to predict knn\")\n",
    "        print(e)\n",
    "    \n",
    "    try:\n",
    "        #print(\"matthews scoring\")\n",
    "        #print(kwargs)\n",
    "        mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        #print(\"Auc scoring\")\n",
    "        #print(kwargs)\n",
    "        auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9355dada",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def elasticNeuralNetworkModelGen():\n",
    "    start = time.time()\n",
    "    # Import base data set and outcome variable-----------------------------------------------\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise parameter space-----------------------------------------------------------------\n",
    "    alpha_n = random.choice(\n",
    "        [1, 0.5, 0.1, 0.05, 0.04, 0.03, 0.02, 0.01, 0.005, 0.001, 0.0001]\n",
    "    )\n",
    "    max_iter_n = random.choice([5, 7, 10, 12, 15, 20, 25, 50, 75])\n",
    "    l1_ratio_n = random.choice(\n",
    "        [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "    loss_n = random.choice([\"log\"])\n",
    "    penalty_n = random.choice([\"elasticnet\"])\n",
    "    class_weight_n = random.choice([\"balanced\"])\n",
    "    shuffle_n = random.choice([True])\n",
    "\n",
    "    # warm_start = True\n",
    "    model = OneVsRestClassifier(\n",
    "        ElasticNet(\n",
    "            alpha=alpha_n,  # untested OneVsRestClassifier\n",
    "            max_iter=max_iter_n,\n",
    "            l1_ratio=l1_ratio_n,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Fit model-------------------------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    # print(score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce0c4e45",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def svcModelGen():\n",
    "    start = time.time()\n",
    "    # Import base data set and outcome variable-----------------------------------------------\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    \n",
    "    # Initialise parameter space-----------------------------------------------------------------\n",
    "\n",
    "    # warm_start = True\n",
    "    model = SVC(c=1)\n",
    "\n",
    "    # penalty = penalty_n,\n",
    "    # missing loss = loss_n,\n",
    "    \n",
    "    \n",
    "    #dual coefficients or intercepts are not finite\n",
    "    try:\n",
    "        # Fit model-------------------------------------------------------------------------------------\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_hat = model.predict(X_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        # print(score)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "        auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "        end = time.time()\n",
    "        model_train_time = int(end-start)\n",
    "        if(debug):\n",
    "            debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "    \n",
    "        return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(X_train.columns)\n",
    "        end = time.time()\n",
    "        model_train_time = int(end-start)\n",
    "        \n",
    "        \n",
    "        #return 0 dud random prediction\n",
    "        return (0, model, list(X_train.columns), model_train_time, 0.5, (np.random.choice(a=[False, True], size=(len(y_test,)))).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5417d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoostModelGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "723c443d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def XGBoostModelGen(*kwargs):\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    # Import base data set and outcome variable-----------------------------------------------\n",
    "    X_train, X_test = get_featured_selected_training_data(method='xgb')\n",
    "    \n",
    "    \n",
    "    # Initialise parameter space-----------------------------------------------------------------\n",
    "    gamma_n = random.choice([0.01, 0.1, 1, 3, 5, 7, 9, 10, 15])\n",
    "    reg_alpha_n = random.choice([0, 0.001, 0.005, 0.01, 0.1, 1, 3, 5])\n",
    "    reg_gamma_n = random.choice([0, 0.001, 0.005, 0.01, 0.1, 1, 3, 5])\n",
    "    learning_rate_n = random.choice(\n",
    "        [0.5, 0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01]\n",
    "    )\n",
    "    subsample_n = random.choice([1, 0.98, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7])\n",
    "    colsample_bytree_n = random.choice(\n",
    "        [1, 0.98, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7])\n",
    "    max_depth_n = random.choice([3, 4, 5, 6, 7, 8, 9, 10, 15])\n",
    "    min_child_weight_n = random.choice(\n",
    "        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "    )\n",
    "    n_estimators_n = random.choice(\n",
    "        [\n",
    "            10,\n",
    "            20,\n",
    "            30,\n",
    "            40,\n",
    "            50,\n",
    "            60,\n",
    "            70,\n",
    "            80,\n",
    "            90,\n",
    "            100,\n",
    "            125,\n",
    "            150,\n",
    "            175,\n",
    "            200,\n",
    "            225,\n",
    "            250,\n",
    "            275,\n",
    "            300,\n",
    "            325,\n",
    "            350,\n",
    "            375,\n",
    "            400,\n",
    "            425,\n",
    "            450,\n",
    "            475,\n",
    "            500,\n",
    "            550,\n",
    "            600,\n",
    "            650,\n",
    "            700,\n",
    "        ]\n",
    "    )\n",
    "    #gpu_id_n = random.randint(0, 7)\n",
    "    gpu_id_n = get_free_gpu()\n",
    "    \n",
    "    #print(f\"{kwargs}defining xgb {gpu_id_n}\")\n",
    "    try:\n",
    "        # warm_start = True\n",
    "        model = XGBClassifier(\n",
    "            gamma=gamma_n,\n",
    "            reg_alpha=reg_alpha_n,\n",
    "            # reg_gamma = reg_gamma_n,   #unused?\n",
    "            learning_rate=learning_rate_n,\n",
    "            subsample=subsample_n,\n",
    "            colsample_bytree=colsample_bytree_n,\n",
    "            max_depth=max_depth_n,\n",
    "            min_child_weight=min_child_weight_n,\n",
    "            n_estimators=n_estimators_n,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id = gpu_id_n,\n",
    "            #nthread=1,\n",
    "            #silent=True,\n",
    "            verbosity = 0,\n",
    "            eval_metric = 'logloss',\n",
    "            #max_workers=10\n",
    "        )\n",
    "\n",
    "        #print(f\"{kwargs}fitting xgb \")\n",
    "        # Fit model-------------------------------------------------------------------------------------\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        #print(f\"{kwargs}getting mccscore \")\n",
    "        mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        #print(f\"{kwargs}getting auc_score \")\n",
    "        auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "        end = time.time()\n",
    "        model_train_time = int(end-start)\n",
    "        if(debug):\n",
    "            print(str(model).split(\"(\")[0], round(mccscore, 5), len(X_train.columns), auc_score, model_train_time)\n",
    "            if(model_train_time> model_train_time_warning_threshold):\n",
    "                print(\"Warning long train time, \")\n",
    "                \n",
    "        #print(type(model))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run XGBoost on GPU {gpu_id_n}\") \n",
    "        print(e)\n",
    "        # warm_start = True\n",
    "        model = XGBClassifier(\n",
    "            gamma=gamma_n,\n",
    "            reg_alpha=reg_alpha_n,\n",
    "            # reg_gamma = reg_gamma_n,   #unused?\n",
    "            learning_rate=learning_rate_n,\n",
    "            subsample=subsample_n,\n",
    "            colsample_bytree=colsample_bytree_n,\n",
    "            max_depth=max_depth_n,\n",
    "            min_child_weight=min_child_weight_n,\n",
    "            n_estimators=n_estimators_n,\n",
    "            tree_method=\"hist\",\n",
    "            #gpu_id = gpu_id_n,\n",
    "            #nthread=1,\n",
    "            #silent=True,\n",
    "            verbosity = 0,\n",
    "            eval_metric = 'logloss',\n",
    "            #max_workers=10\n",
    "        )\n",
    "\n",
    "        #print(f\"{kwargs}fitting xgb \")\n",
    "        # Fit model-------------------------------------------------------------------------------------\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        #print(f\"{kwargs}getting mccscore \")\n",
    "        mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        #print(f\"{kwargs}getting auc_score \")\n",
    "        auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "        end = time.time()\n",
    "        model_train_time = int(end-start)\n",
    "        if(debug):\n",
    "            debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "                \n",
    "        if(store_base_learners):\n",
    "            try:\n",
    "                store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred, model_type = 'xgb')\n",
    "            except Exception as e:\n",
    "                print(e, 'store base learners')\n",
    "                \n",
    "        return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "\n",
    "    if(store_base_learners):\n",
    "        try:\n",
    "            store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred, model_type = 'xgb')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1441ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoostModelGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85bd1717",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def DecisionTreeClassifier_ModelGen():\n",
    "    start = time.time()\n",
    "    \n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        \"ccp_alpha\": log_small,\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "        + [{0: w} for w in [1, 2, 4, 6, 10]],  # enumerate?\n",
    "        \"criterion\": [\"gini\", \"entropy\" ],# \"log_loss\"],\n",
    "        \"max_depth\": log_large_long,\n",
    "        \"max_features\": [\"sqrt\", \"log2\"], #\"auto\", \n",
    "        'max_leaf_nodes': log_large_long,\n",
    "        \"min_impurity_decrease\": log_small,\n",
    "        'min_samples_leaf': log_med,\n",
    "        'min_samples_split': lin_zero_one,\n",
    "        \"min_weight_fraction_leaf\": log_small,\n",
    "        'random_state': [None],\n",
    "        \"splitter\": [\"best\", \"random\"],\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = DecisionTreeClassifier(**sample_parameter_space)\n",
    "\n",
    "    # Train the model--------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    #y_train_hat = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d02241f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def AdaBoostClassifier_ModelGen():\n",
    "    start = time.time()\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        \"algorithm\": [\"SAMME.R\", \"SAMME\"],\n",
    "        \"base_estimator\": [None],\n",
    "        \"learning_rate\": log_small,\n",
    "        \"n_estimators\": log_large_long,\n",
    "        \"random_state\": [None],\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = AdaBoostClassifier(**sample_parameter_space)\n",
    "\n",
    "    # Train the model--------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e68719e2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def GaussianNB_ModelGen():\n",
    "    start = time.time()\n",
    "    # Feature selection supposed to be done each iteration of cross validation\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    new_list = list(log_small).copy()\n",
    "    new_list.append(1e-09)\n",
    "    parameter_space = {\n",
    "        \"priors\": [\n",
    "            None,\n",
    "            [0.1, 0.9],\n",
    "            [0.9, 0.1],\n",
    "            [0.7, 0.3],\n",
    "            [0.3, 0.7],\n",
    "            [0.5, 0.5],\n",
    "            [0.6, 0.4],\n",
    "            [0.4, 0.6],\n",
    "        ],  # enumerate\n",
    "        \"var_smoothing\": new_list,\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = GaussianNB(**sample_parameter_space)\n",
    "\n",
    "    # Train the model--------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7529291",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def QuadraticDiscriminantAnalysis_ModelGen():\n",
    "    start = time.time()\n",
    "    \n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        \"priors\": [None],\n",
    "        \"reg_param\": log_small,\n",
    "        \"store_covariance\": [False],\n",
    "        \"tol\": log_small,\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = QuadraticDiscriminantAnalysis(**sample_parameter_space)\n",
    "\n",
    "    # Train the model--------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a909067d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SVC_ModelGen():\n",
    "    start = time.time()\n",
    "    # Feature selection supposed to be done each iteration of cross validation\n",
    "\n",
    "    # Import base data set and outcome variable-----------------------------------------------\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        \"C\": log_small,\n",
    "        \"break_ties\": bool_param,\n",
    "        'cache_size': [200],\n",
    "        'class_weight': [None, 'balanced'] + [{0: w} for w in [1, 2, 4, 6, 10]], # enumerate class weight\n",
    "        \"coef0\": log_small,\n",
    "        \"decision_function_shape\": [\"ovr\"],  # , 'ovo'\n",
    "        \"degree\": log_med,\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "        \"kernel\": [\"rbf\", \"linear\", \"poly\", \"sigmoid\"],\n",
    "        \"max_iter\": log_large_long,\n",
    "        'probability': [False],\n",
    "        'random_state': [None],\n",
    "        \"shrinking\": bool_param,\n",
    "        \"tol\": log_small,\n",
    "        \"verbose\": [False],\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = SVC(**sample_parameter_space)\n",
    "    \n",
    "    try:\n",
    "        # Train the model--------------------------------------------------------------------\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "        end = time.time()\n",
    "        model_train_time = int(end-start)\n",
    "        if(debug):\n",
    "            debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "        if(store_base_learners):\n",
    "            store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)        \n",
    "        \n",
    "        return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        end = time.time()\n",
    "        model_train_time = int(end-start)\n",
    "        return (0, model, list(X_train.columns), model_train_time, 0.5, (np.random.choice(a=[False, True], size=(len(y_test,))).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8e09721",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def GradientBoostingClassifier_ModelGen():\n",
    "    start = time.time()\n",
    "    # Feature selection supposed to be done each iteration of cross validation\n",
    "\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "    parameter_space = {\n",
    "        \"ccp_alpha\": log_small,\n",
    "        \"criterion\": [\"friedman_mse\"],\n",
    "        \"init\": [None],\n",
    "        \"learning_rate\": log_small,\n",
    "        #\"loss\": [\"log_loss\", \"exponential\"],\n",
    "        'max_depth': log_med,\n",
    "        \"max_features\": [1.0, \"sqrt\", \"log2\"],\n",
    "        'max_leaf_nodes': log_large_long,\n",
    "        'min_impurity_decrease': log_small,\n",
    "        'min_samples_leaf': log_med,\n",
    "        'min_samples_split': lin_zero_one,\n",
    "        'min_weight_fraction_leaf': log_small,\n",
    "        \"n_estimators\": log_large_long,\n",
    "        'n_iter_no_change': log_large_long,\n",
    "        \"random_state\": [None],\n",
    "        \"subsample\": lin_zero_one,\n",
    "        \"tol\": log_small,\n",
    "        \"validation_fraction\": [0.1],\n",
    "        \"verbose\": [0],\n",
    "        \"warm_start\": [0],\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = GradientBoostingClassifier(**sample_parameter_space)\n",
    "\n",
    "    # Train the model--------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e75526be",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def RandomForestClassifier_ModelGen():\n",
    "    start = time.time()\n",
    "    # Feature selection supposed to be done each iteration of cross validation\n",
    "\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        \"bootstrap\": bool_param,\n",
    "        \"ccp_alpha\": log_small,\n",
    "        'class_weight': [None, 'balanced'] + [{0: w} for w in [1, 2, 4, 6, 10]],\n",
    "        \"criterion\": [\"gini\", \"entropy\" ],# , \"log_loss\"],\n",
    "        \"max_depth\": log_med,\n",
    "        \"max_features\": [1.0, \"sqrt\", \"log2\"],\n",
    "        'max_leaf_nodes': log_large_long,\n",
    "        \"max_samples\": [None],\n",
    "        'min_impurity_decrease': log_small,\n",
    "        \"min_samples_leaf\": log_med,\n",
    "        \"min_samples_split\": lin_zero_one,\n",
    "        'min_weight_fraction_leaf': log_small,\n",
    "        \"n_estimators\": log_large_long,\n",
    "        \"n_jobs\": [-1],\n",
    "        \"oob_score\": [False],\n",
    "        \"random_state\": [None],\n",
    "        \"verbose\": [0],\n",
    "        \"warm_start\": [False],\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = RandomForestClassifier(**sample_parameter_space)\n",
    "\n",
    "    # Train the model--------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    #print(plot_cf_matrix(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb83d3e0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def MLPClassifier_ModelGen():\n",
    "    start = time.time()\n",
    "    # Feature selection supposed to be done each iteration of cross validation\n",
    "\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"alpha\": log_small,\n",
    "        \"batch_size\": [\"auto\"],\n",
    "        'beta_1': log_small,\n",
    "        'beta_2': log_small,\n",
    "        'early_stopping': bool_param,\n",
    "        'epsilon': log_small,\n",
    "        \"hidden_layer_sizes\": [5, 10, 50, 100],#log_large_long, # Possible DGX hang on 630\n",
    "        \"learning_rate\": [\"constant\"], #, \"adaptive\"],\n",
    "        'learning_rate_init': log_small,\n",
    "        'max_fun': [15000],\n",
    "        'max_iter': log_large_long,\n",
    "        \"momentum\": lin_zero_one,\n",
    "        'n_iter_no_change': log_large_long,\n",
    "        'nesterovs_momentum': [True],\n",
    "        'power_t': [0.5],\n",
    "        \"random_state\": [None],\n",
    "        \"shuffle\": bool_param,\n",
    "        'solver': ['adam', 'lbfgs', 'sgd'],\n",
    "        \"tol\": log_small,\n",
    "        \"validation_fraction\": [0.1],\n",
    "        \"verbose\": [False],\n",
    "        \"warm_start\": [False],\n",
    "    }\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    # fit model with random sample of global parameter space\n",
    "    #display(sample_parameter_space)\n",
    "    model = MLPClassifier(**sample_parameter_space)\n",
    "\n",
    "    # Train the model--------------------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "    if(store_base_learners):\n",
    "        store_model(mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3990f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_model_gen():\n",
    "    \n",
    "    mccscore = 0.5\n",
    "    #model = fitted_perceptron\n",
    "    model_train_time = 0\n",
    "    auc_score = 0.5\n",
    "    auc_score = random.uniform(0.5, 1)\n",
    "    #y_pred = y_test_orig\n",
    "    y_pred = y_test\n",
    "    y_pred = np.random.choice(a=[False, True], size=(len(y_test,)))\n",
    "    \n",
    "    \n",
    "    return (mccscore, fitted_perceptron, dummy_columns, model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93676f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "\n",
    "## test data    \n",
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ed471ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should deep model evaluation metric be mcc...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d018d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec8d0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self, column_length, deep_layers_1, batch_size, dropout_val):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(column_length, batch_size) \n",
    "        self.layer_2 = nn.Linear(batch_size, batch_size)\n",
    "        layers = []\n",
    "        for i in range(0, deep_layers_1):\n",
    "            layers.append(nn.Linear(batch_size, batch_size))\n",
    "\n",
    "        self.deep_layers = nn.Sequential(*layers)\n",
    "    \n",
    "        \n",
    "        self.layer_out = nn.Linear(batch_size, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_val)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(batch_size)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(batch_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.relu(self.deep_layers(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca4a403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Pytorch_binary_class_ModelGen():\n",
    "    start = time.time()\n",
    "    # Feature selection supposed to be done each iteration of cross validation\n",
    "\n",
    "    X_train, X_test = get_featured_selected_training_data(method='anova')\n",
    "    \n",
    "    if(scale==False):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    train_data = TrainData(torch.FloatTensor(X_train.to_numpy()), \n",
    "                           torch.FloatTensor(y_train.to_numpy()))    \n",
    "    test_data = TestData(torch.FloatTensor(X_test.to_numpy()))\n",
    "\n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        'column_length':[len(X_train.columns)],\n",
    "       #'epochs': [50, 200],\n",
    "    'batch_size': [int(X.shape[0]/100), int(X.shape[0]/200)],\n",
    "    #'learning_rate': lr_space,\n",
    "    #'learning_rate': [0.1, 0.001, 0.0005, 0.0001],\n",
    "    'deep_layers_1':[2, 4, 8, 16, 32],\n",
    "    'dropout_val':[0.1, 0.01, 0.001]\n",
    "    }\n",
    "    \n",
    "    additional_grid = {\n",
    "        'epochs': [10, 50, 100],\n",
    "    'learning_rate': [0.1, 0.001, 0.0005, 0.0001]\n",
    "    }\n",
    "    size_test = []\n",
    "    # Loop over al grid search combinations\n",
    "    for values in itertools.product(*additional_grid.values()):\n",
    "        point = dict(zip(additional_grid.keys(), values))\n",
    "        # merge the general settings\n",
    "        settings = { **point}\n",
    "        #print(settings)\n",
    "        size_test.append(settings)\n",
    "\n",
    "    #print(len(size_test))\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "        \n",
    "    additional_param_sample = random.choice(size_test)\n",
    "        \n",
    "    additional_param_sample = {}\n",
    "    for key in additional_grid.keys():\n",
    "        additional_param_sample[key] = random.choice(additional_grid.get(key))    \n",
    "        \n",
    "        \n",
    "    print(sample_parameter_space)\n",
    "    \n",
    "    print(additional_param_sample)\n",
    "        \n",
    "        \n",
    "    free_gpu = str(get_free_gpu())\n",
    "    \n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"]=free_gpu\n",
    "    \n",
    "    device = torch.device(f\"cuda:{free_gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=sample_parameter_space['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    \n",
    "    \n",
    "    # fit model with random sample of global parameter space\n",
    "    model = BinaryClassification(**sample_parameter_space)\n",
    "    \n",
    "    model.to(device)\n",
    "    #print(model)    \n",
    "        \n",
    "        \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=additional_param_sample['learning_rate'])\n",
    "    model.train()\n",
    "    for e in range(1, additional_param_sample['epochs']+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "        \n",
    "    para_str = (str(settings).replace(\"'\", \"_\").replace(\":\", \"_\").replace(\",\", \"_\").replace(\"{\", \"_\").replace(\"}\", \"_\").replace(\" \", \"_\")).replace(\"__\", \"_\")    \n",
    "        \n",
    "    y_pred = model(test_data.X_data.to(device))\n",
    "    \n",
    "    y_pred = torch.round(torch.sigmoid(y_pred)).cpu().detach().numpy().flatten()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(any(np.isnan(y_pred))):\n",
    "        print(\"Torch model nan, returning random y pred vector\")\n",
    "        #zero_vector = [x for x in range(0, len(y_pred))]\n",
    "        #y_pred = zero_vector\n",
    "        random_y_pred_vector = (np.random.choice(a=[False, True], size=(len(y_test,)))).astype(int)\n",
    "        y_pred = random_y_pred_vector\n",
    "    else:\n",
    "        #plot_auc(y_hat, f\"Deep ANN Torch {para_str}\")    \n",
    "        pass\n",
    "        \n",
    "\n",
    "    mccscore = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    auc_score = round(metrics.roc_auc_score(y_test,y_pred), 4)\n",
    "    \n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "            \n",
    "    if(store_base_learners):\n",
    "        try:\n",
    "            store_model(mccscore, model , list(X_train.columns), model_train_time, auc_score, y_pred,  model_type = 'torch')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    torch.cuda.empty_cache() #exp\n",
    "    \n",
    "    return (mccscore, model, list(X_train.columns), model_train_time, auc_score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc625d91",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "#v3\n",
    "def do_work(n):\n",
    "\n",
    "    index = random.randint(0, len(modelFuncList)-1)\n",
    "\n",
    "    try:\n",
    "        if(use_stored_base_learners and random.random()>0.5):\n",
    "            \n",
    "            return get_stored_model()\n",
    "\n",
    "        else:\n",
    "            return modelFuncList[index]()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Failed to return model at index {index}, returning perceptron\")\n",
    "        return modelFuncList[1]()\n",
    "    \n",
    "    #return random.choice(modelFuncList)\n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"RuntimeWarning\")\n",
    "#warnings.filterwarnings('error')\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "def multi_run_wrapper(args):\n",
    "           return do_work(*args)\n",
    "\n",
    "def ensembleGenerator(nb_val=28):\n",
    "    #print(\"ensembleGenerator: \", nb_val)\n",
    "    \n",
    "    #nb_val = random.randint(2, nb_val) # dynamic individual size\n",
    "    max_Value = nb_val - 2\n",
    "    skewness = +5\n",
    "    random_val = skewnorm.rvs(a = skewness,loc=max_Value, size=10000)  #Skewnorm function\n",
    "    \n",
    "    random_val = random_val - min(random_val)      #Shift the set so the minimum value is equal to zero.\n",
    "    random_val = random_val / max(random_val)      #Standadize all the vlues between 0 and 1. \n",
    "    random_val = random_val * max_Value         #Multiply the standardized values by the maximum value.\n",
    "\n",
    "    random_val = random_val.astype(int)  +2\n",
    "\n",
    "    nb_val = np.random.choice(random_val)\n",
    "    \n",
    "    \n",
    "\n",
    "    ensemble = []\n",
    "\n",
    "    \n",
    "    dummy_list = [x for x in range(0, nb_val)]\n",
    "   \n",
    "\n",
    "\n",
    "    if(nb_val>1):\n",
    "                            \n",
    "#         \n",
    "        if __name__ == \"__main__\":\n",
    "            from eventlet import GreenPool\n",
    "            pool = GreenPool()\n",
    "            for _ in tqdm(pool.imap(do_work, dummy_list), total=len(dummy_list)):\n",
    "                ensemble.append(_)\n",
    "                pass    \n",
    "\n",
    "            if(len(ensemble)!=nb_val):\n",
    "\n",
    "                print(f\"Error generating ensemble {len(ensemble)} {nb_val} {len(dummy_list)}\")\n",
    "                raise Exception(f\"Error generating ensemble {len(ensemble)} {nb_val} {len(dummy_list)}\")\n",
    "\n",
    "\n",
    "\n",
    "        #print(\"Returning ensemble of size \", len(ensemble))\n",
    "        return ensemble\n",
    "    else:\n",
    "        print(\"Nb_val passed <1 Returning individual of size from baseLearnerGenerator\", nb_val)\n",
    "        return baseLearnerGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "879406c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def baseLearnerGenerator():\n",
    "    \n",
    "    index = random.randint(0, len(modelFuncList)-1)\n",
    "\n",
    "    return modelFuncList[index]() #store as functions, pass as result of executed function\n",
    "\n",
    "\n",
    "# Model will be fit in generation stage and pass fitted state with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63829fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_binary_vector_diversity(ensemble, metric='jaccard'):\n",
    "    #beta\n",
    "    #can select any from scipy spatial distance pdist\n",
    "    #if two datasets have a Jaccard Similarity of 80% then they would have a Jaccard distance of 1  0.8 = 0.2 or 20%\n",
    "    #closer to zero, the more similar the vectors\n",
    "    #if all are similar the less diverse they are\n",
    "    ##assume mcc is 0.5, n = 2\n",
    "    #then (0.5 * 0.1)*2  = 0.1\n",
    "    #and  (0.5 * 0.5)*2) = 0.5\n",
    "    #needs diversity_parameter to modify strength?\n",
    "    \n",
    "    n_y_pred = len(ensemble[0]) #check level\n",
    "    \n",
    "    all_y_pred_arrays = []\n",
    "    \n",
    "    for i in range(0, n_y_pred):\n",
    "        \n",
    "        all_y_pred_arrays.append(ensemble[0][i][5])\n",
    "    \n",
    "    distance_vector = scipy.spatial.distance.pdist(all_y_pred_arrays,  \n",
    "                                       metric=metric)\n",
    "    \n",
    "\n",
    "    return np.mean(distance_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa7d9133",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(individual):\n",
    "    # Evaluate ensemble\n",
    "    #X_test = X_test_orig.copy()\n",
    "    #y_test = y_test_orig.copy()\n",
    "\n",
    "    mccScoresList = []\n",
    "    \n",
    "    aucScoresList = []\n",
    "    \n",
    "    print(\"Evaluating individual of size: \", len(individual[0]))\n",
    "    \n",
    "    individual_data = individual[0]\n",
    "    \n",
    "    with open(file_path+\"/progress_logs_scores/\"+current_log_scores_filename, \"a\") as myfile:\n",
    "            myfile.write(f\"Evaluating individual of size: {str(len(individual[0]))}\"\n",
    "                        )\n",
    "    myfile.close()\n",
    "\n",
    "    for modelSet in individual_data:\n",
    "        #print(modelSet)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            mccscore = modelSet[0]\n",
    "\n",
    "            mccScoresList.append(mccscore)\n",
    "            \n",
    "            aucscore = modelSet[4]\n",
    "            \n",
    "            aucScoresList.append(aucscore)\n",
    "\n",
    "            try:\n",
    "                mod_name = str(modelSet[1]).split(\"(\")[0]\n",
    "                #mod_name = modelSet[0][1]\n",
    "            except:\n",
    "                mod_name = modelSet[1]\n",
    "            if(debug):\n",
    "                print(\"Evaluate: \", mod_name, \"mccscore: \", mccscore, \"AUC:\", aucscore) \n",
    "            with open(file_path+\"/progress_logs_scores/\"+current_log_scores_filename, \"a\") as myfile:\n",
    "                myfile.write(f\"\\n Evaluate: mccscore:  {mccscore} AUC: {aucscore} {mod_name}\"\n",
    "                        )\n",
    "            myfile.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Failed, writing zero for mcc score\")\n",
    "            mccScoresList.append(0)\n",
    "    print(\n",
    "        \"Individuals mccscores list\",\n",
    "        mccScoresList)\n",
    "        \n",
    "        \n",
    "    print(\"Mean of mccscores:\",\n",
    "        (np.mean(np.array(mccScoresList))),\n",
    "          'n =',\n",
    "           len(mccScoresList)\n",
    "    )\n",
    "    #print(\"AUC scores:\", aucScoresList, \"mean AUC:\", str(round(np.mean(np.array(aucScoresList)),4)))\n",
    "    \n",
    "    print(f\"Mean MCC scores: {(round(np.mean(np.array(mccScoresList)), 4))} mean AUC: {(round(np.mean(np.array(aucScoresList)),4))} \\n\")\n",
    "    \n",
    "    with open(file_path+\"/progress_logs_scores/\"+current_log_scores_filename, \"a\") as myfile:\n",
    "                myfile.write(f\"\\n Mean MCC scores: {(round(np.mean(np.array(mccScoresList)), 4))} mean AUC: {(round(np.mean(np.array(aucScoresList)),4))} \\n\")\n",
    "    myfile.close()\n",
    "    \n",
    "     \n",
    "    #measure and incorporate diversity\n",
    "    diversity_metric = measure_binary_vector_diversity(individual)\n",
    "    \n",
    "#     nv = 10\n",
    "\n",
    "#     diversity_score = 0.4\n",
    "#     vec = [(x/nv* diversity_score * 0.1) for x in range(nv)]\n",
    "#     vec2 = [(x/nv* diversity_score * 0.5) for x in range(nv)]\n",
    "#     vec3 = [(x/nv* diversity_score * 0.9) for x in range(nv)]\n",
    "\n",
    "\n",
    "#     ypoints = np.array(vec)\n",
    "#     plt.plot(ypoints, linestyle = 'dotted', color='g')\n",
    "#     ypoints = np.array(vec2)\n",
    "#     plt.plot(ypoints, linestyle = 'dotted', color='b')\n",
    "#     ypoints = np.array(vec3)\n",
    "#     plt.plot(ypoints, linestyle = 'dotted', color='y')\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    #return mcc for genetic algorithm evalutation\n",
    "    #return (((np.mean(np.array(mccScoresList))),)\n",
    "    final_score =  ((np.mean(np.array(mccScoresList))),)\n",
    "    diversity_parameter = 0.1\n",
    "    final_score = (final_score* diversity_metric * diversity_parameter)/2\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1998d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred_resolver(ensemble, valid=False):\n",
    "#     if(debug):\n",
    "#         print(f\"get_y_pred_resolver {global_param_dict.get('weighted')}\")\n",
    "    if(global_param_dict.get('weighted')== None or global_param_dict.get('weighted')=='unweighted'):\n",
    "        y_pred = get_best_y_pred_unweighted(ensemble, valid=valid)\n",
    "    elif(global_param_dict.get('weighted')=='de'):\n",
    "        \n",
    "        y_pred = get_weighted_ensemble_prediction_de_y_pred_valid(ensemble, super_ensemble_weight_finder_differential_evolution(ensemble, valid=valid), valid=valid)\n",
    "        #print(y_pred.shape)\n",
    "    elif(global_param_dict.get('weighted')=='ann'):\n",
    "        y_pred = get_y_pred_ann_torch_weighting(ensemble, valid=valid)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dedf5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_weighted_ensemble_auc(individual):\n",
    "    global log_store_dataframe_path\n",
    "    # Evaluate ensemble\n",
    "    #X_test = X_test_orig.copy()\n",
    "    #y_test = y_test_orig.copy()\n",
    "\n",
    "    mccScoresList = []\n",
    "    \n",
    "    aucScoresList = []\n",
    "    \n",
    "    #print(\"Evaluating individual of size: \", len(individual[0]))\n",
    "    \n",
    "    #individual_data = individual[0]\n",
    "    \n",
    "    with open(file_path+\"/progress_logs_scores/\"+current_log_scores_filename, \"a\") as myfile:\n",
    "            myfile.write(f\"Evaluating individual of size: {str(len(individual[0]))}\"\n",
    "                        )\n",
    "    myfile.close()\n",
    "    \n",
    "    y_pred = get_y_pred_resolver(individual, valid=False)\n",
    "    \n",
    "    #print(y_test.shape, y_pred.shape, )\n",
    "            #should write mcc parallel instead of auc also, need pair functions\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    f1  = f1_score(y_test, y_pred, average='binary')\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    with open(file_path+\"/progress_logs_scores/\"+current_log_scores_filename, \"a\") as myfile:\n",
    "                myfile.write(f\"\\n ensemble MCC score: {round(mcc, 4)} ensemble AUC: {(round(auc,4))} \\n\")\n",
    "    myfile.close()\n",
    "    \n",
    "    if(debug):\n",
    "        print(f\"Ensemble MCC {mcc}, AUC {auc}, nb {len(individual[0])}\")\n",
    "    \n",
    "    #?? how does the diversity weighting and the order of operations interact with the ensemble weights already\n",
    "    #measure and incorporate diversity\n",
    "    diversity_metric = measure_binary_vector_diversity(individual)\n",
    "    \n",
    "    \n",
    "    diversity_parameter = global_param_dict.get('div_p')\n",
    "#     final_score = (auc* diversity_metric * diversity_parameter)/2\n",
    "#     final_score_mcc = (mcc* diversity_metric * diversity_parameter)/2\n",
    "    \n",
    "    #Simple diversity incorporation\n",
    "    auc_div = auc * ((-1 + (diversity_metric + diversity_parameter) )) \n",
    "    # div metric should decrease score as 1=similar, we want to penalise similarity of prediction\n",
    "    \n",
    "    mcc_div = mcc * ((-1 + (diversity_metric + diversity_parameter) ))\n",
    "    \n",
    "    #blank init with headers in main log_store_dataframe_path\n",
    "    ensemble_model_list = []\n",
    "    feature_count_list  = []\n",
    "    auc_score_list = []\n",
    "    mcc_score_list = []\n",
    "    #For each member in the ensemble\n",
    "    for i in range(0, len(individual[0])-1):\n",
    "        ensemble_model_list.append(str(individual[0][i][1])) # str or model?\n",
    "        feature_count_list.append(individual[0][i][2]) #could replace with length of list to reduce size on disk\n",
    "        auc_score_list.append(individual[0][i][4])\n",
    "        mcc_score_list.append(individual[0][i][0])\n",
    "        \n",
    "    \n",
    "    \n",
    "    orignal_feature_names  \n",
    "    \n",
    "    feature_map_vector = []\n",
    "    for col in orignal_feature_names:\n",
    "        if(col in feature_count_list):\n",
    "            feature_map_vector.append(1)\n",
    "        else:\n",
    "            feature_map_vector.append(0)\n",
    "        \n",
    "    feature_map_vector = np.array(feature_map_vector)\n",
    "    \n",
    "    #set score log dataframe in main\n",
    "    df_data = [[len(individual[0]),auc, np.mean(auc_score_list), auc_div, mcc, np.mean(mcc_score_list), mcc_div, f1, precision, recall, accuracy,\n",
    "                ensemble_model_list, feature_map_vector, auc_score_list, mcc_score_list\n",
    "               ]]\n",
    "    column_headers = ['n','auc', 'auc_mean', 'auc_div', 'mcc','mcc_mean', 'mcc_div', 'f1', 'precision', 'recall', 'accuracy',\n",
    "                'ensemble_model_list', 'feature_count_list', 'auc_score_list', 'mcc_score_list']\n",
    "    \n",
    "#     column_headers = ['nb_size', 'f_list', 'auc','mcc','f1','precision','recall','accuracy', 'nb_val', 'pop_val', 'g_val', 'g', 'weighted', 'use_stored_base_learners', 'store_base_learners',\n",
    "#        'resample', 'scale', 'n_features', 'param_space_size', 'n_unique_out',\n",
    "#        'outcome_var_n', 'div_p', 'percent_missing', 'corr', \n",
    "#                        'age', 'sex', 'bmi','ethnicity', 'bloods', 'diagnostic_order',\n",
    "#                       'drug_order', 'annotation_n', 'meta_sp_annotation_n',\n",
    "#                       'X_train_size', 'X_test_orig_size', 'X_test_size',\n",
    "#                    'run_time', 'cxpb', 'mutpb', 'indpb', 't_size']\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data = df_data, columns=column_headers)\n",
    "    df.to_csv(f\"{file_path}/progress_logs_scores/{log_store_dataframe_path}.csv\", mode='a', index=True, header=False)\n",
    "    \n",
    "    if(debug):\n",
    "        print(f\"\"\"Ensemble MCC {mcc}, diversity weighted MCC {mcc_div}\n",
    "        , \\n f1 {f1} precision {precision} recall {recall} accuracy {accuracy}\n",
    "        , \\n AUC {auc}, diversity weighted AUC {auc_div}\n",
    "        , \\n nb {len(individual[0])}, diversity_score: {diversity_metric}, diff: {auc_div-auc} \"\"\")\n",
    "    \n",
    "    \n",
    "    #return mcc for genetic algorithm evalutation\n",
    "    if(diversity_parameter>0):\n",
    "        return (auc_div,)\n",
    "    else:\n",
    "        return (auc,)\n",
    "    #return (auc,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8f3bac9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mutateEnsemble(individual):\n",
    "    # print(individual[0])\n",
    "    # print(len(individual[0]))\n",
    "    try:\n",
    "        print(f\"original individual of size {len(individual[0])-1}:\")\n",
    "        n = random.randint(0, len(individual[0])-1)\n",
    "        print(f\"Mutating individual at index {n}\")\n",
    "        try:\n",
    "            individual[0].pop(n)\n",
    "            print(f\"Successfully popped {n} from individual\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to pop {n} from individual of length {len(individual[0])} , popping zero\")\n",
    "            individual[0].pop(0)\n",
    "            \n",
    "            print(e)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(n)\n",
    "        #individual[0].pop(n)\n",
    "        # print(individual)\n",
    "        individual[0].append(baseLearnerGenerator())\n",
    "        # print(individual)\n",
    "        #print(\"Mutated individual:\")\n",
    "        #print(individual)\n",
    "        return individual\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Failed to mutate Ensemble\")\n",
    "        print(\"Len individual\", len(individual))\n",
    "        #print(individual[0])\n",
    "        #print(individual)\n",
    "        return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c17172e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_prediction_de_y_pred(best, weights):\n",
    "    \"\"\"Return the weighted prediction vector\"\"\"\n",
    "\n",
    "    prediction_array = []\n",
    "    target_ensemble = best[0]\n",
    "    for i in range(0, len(target_ensemble)):\n",
    "        # For model i, predict it's x_test\n",
    "        feature_columns = target_ensemble[i][2]\n",
    "        y_pred = target_ensemble[i][5]\n",
    "\n",
    "\n",
    "        prediction_array.append(y_pred)\n",
    "    prediction_matrix = np.matrix(prediction_array)\n",
    "    prediction_matrix = prediction_matrix.astype(float)\n",
    "    prediction_matrix_raw = prediction_matrix   \n",
    "    #auc = metrics.roc_auc_score(y_test, y_pred_best)\n",
    "    #print(\"Unweighted ensemble AUC: \", auc)\n",
    "\n",
    "    clean_prediction_matrix = prediction_matrix_raw.copy()\n",
    "    weights = normalize(weights)\n",
    "\n",
    "    weighted_prediction_matrix_array = (np.array(clean_prediction_matrix) * weights[:, None])\n",
    "    collapsed_weighted_prediction_matrix_array = weighted_prediction_matrix_array.sum(axis=0)\n",
    "\n",
    "    y_pred_weighted = round_v(collapsed_weighted_prediction_matrix_array)\n",
    "    \n",
    "    return y_pred_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f9a823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_prediction_de_y_pred_valid(best, weights, valid=False):\n",
    "    \"\"\"Return the weighted prediction vector\"\"\"\n",
    "\n",
    "    #global get_weighted_ensemble_prediction\n",
    "    \n",
    "    #Need to calculate weights from x_train (weights are passed in already)\n",
    "    #then call each model in the ensemble and have them predict on the x_test_orig validation \n",
    "    #Then apply the weights learned from training set\n",
    "    \n",
    "    # Get prediction matrix:\n",
    "\n",
    "    target_ensemble = best[0]\n",
    "    if(valid):\n",
    "        print(\"Evaluating weighted ensemble on validation set\")\n",
    "        x_test = X_test_orig.copy()\n",
    "        y_test = y_test_orig.copy()\n",
    "    \n",
    "        prediction_array = []\n",
    "\n",
    "        for i in range(0, len(target_ensemble)):\n",
    "            # For model i, predict it's x_test\n",
    "            feature_columns = target_ensemble[i][2]\n",
    "\n",
    "            model = target_ensemble[i][1]\n",
    "\n",
    "\n",
    "    #         is evaluate calling model text also fitting?\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "                model.fit(X_train[feature_columns], y_train)\n",
    "                prediction_array.append(\n",
    "                    model.predict(x_test[feature_columns])) # Target for resolving GPU/torch model types\n",
    "\n",
    "            else:\n",
    "                print(\"get_weighted_ensemble_prediction_de_y_pred_valid, handling torch model prediction\")\n",
    "\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(x_test[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "    #             model = target_ensemble[i][1]                                     #Has this model already been trained?\n",
    "                model.to(device)\n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "\n",
    "                print(\"numpy.isnan(y_hat).any()\", numpy.isnan(y_hat).any())\n",
    "                if(numpy.isnan(y_hat).any()):\n",
    "                    print(\"Returning dummy random yhat vector for torch pred, nan found\")\n",
    "                    y_hat = np.random.choice(a=[False, True], size=(len(y_hat,)))\n",
    "\n",
    "                prediction_array.append(y_hat                                   \n",
    "                       )\n",
    "    else:\n",
    "        prediction_array = []\n",
    "\n",
    "        for i in range(0, len(target_ensemble)):\n",
    "            #print(target_ensemble[i][5].shape)\n",
    "            prediction_array.append(\n",
    "                    target_ensemble[i][5]) \n",
    "\n",
    "        \n",
    "    prediction_matrix = np.matrix(prediction_array)\n",
    "    prediction_matrix = prediction_matrix.astype(float)\n",
    "    prediction_matrix_raw = prediction_matrix   \n",
    "\n",
    "    \n",
    "    clean_prediction_matrix = prediction_matrix_raw.copy()\n",
    "    weights = normalize(weights)\n",
    "\n",
    "    weighted_prediction_matrix_array = (np.array(clean_prediction_matrix) * weights[:, None])\n",
    "    collapsed_weighted_prediction_matrix_array = weighted_prediction_matrix_array.sum(axis=0)\n",
    "\n",
    "    y_pred_weighted = round_v(collapsed_weighted_prediction_matrix_array)\n",
    "    \n",
    "    torch.cuda.empty_cache() # exp\n",
    "\n",
    "    return y_pred_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24905574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble=best\n",
    "# valid=True\n",
    "# get_weighted_ensemble_prediction_de_y_pred_valid(ensemble, super_ensemble_weight_finder_differential_evolution(ensemble, valid=valid), valid=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74065985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep me\n",
    "round_v = np.vectorize(round) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20de8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_weighted_ensemble_prediction_de(weights, prediction_matrix_raw):\n",
    "        \"\"\"Function used by DE algo to search for optimal weights with scoring\"\"\"\n",
    "        #print(score_list[0:5])\n",
    "        #global prediction_matrix_raw\n",
    "        #y_test = y_test_orig.copy()\n",
    "\n",
    "        clean_prediction_matrix = prediction_matrix_raw.copy()\n",
    "        weights = normalize(weights)\n",
    "\n",
    "\n",
    "        #profiler points at this matrix definition:\n",
    "        #for each case, for the column of models in the ensemble...\n",
    "        # for i in range(0, len(prediction_array[0])):\n",
    "        #     clean_prediction_matrix[:,i] = np.matrix(np.array(clean_prediction_matrix[:,i]).transpose()[0] * weights).transpose()\n",
    "\n",
    "        weighted_prediction_matrix_array = (np.array(clean_prediction_matrix) * weights[:, None])\n",
    "        collapsed_weighted_prediction_matrix_array = weighted_prediction_matrix_array.sum(axis=0)\n",
    "\n",
    "        # can be done outside function\n",
    "\n",
    "        y_pred_best = round_v(collapsed_weighted_prediction_matrix_array)\n",
    "        \n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_best) #where on earth is this y_test taken from... it is the same global one?\n",
    "        score = auc\n",
    "        #         if(score > best_score):\n",
    "        #             best_score = score\n",
    "        #             best_weights = weights\n",
    "        #             print(best_score, best_weights, \"-\" + \"\\n\")\n",
    "        #score_list.append((score, weights))\n",
    "        mcc = matthews_corrcoef(y_test, y_pred_best)\n",
    "        #score = mcc\n",
    "        #print(f\"AUC: {score}\" )\n",
    "        return 1-score\n",
    "        #print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b858d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cython call function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "398b2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redundant? weights only derived from xtrain, weight vec is size of ensemble not train set\n",
    "\n",
    "#Only get weights from xtrain/ytrain, never get weights from xtest y test. Use weights on x_validation yhat to compare to ytrue_valid\n",
    "def super_ensemble_weight_finder_differential_evolution(best, valid=False):\n",
    "\n",
    "    model_train_time_warning_threshold = 5\n",
    "    # Get prediction matrix:\n",
    "    prediction_array = []\n",
    "    target_ensemble = best[0]\n",
    "    for i in range(0, len(target_ensemble)):\n",
    "        # For model i, predict it's x_test\n",
    "        #feature_columns = target_ensemble[i][2]\n",
    "        y_pred = target_ensemble[i][5]\n",
    "        #print(y_pred.shape)\n",
    "\n",
    "\n",
    "        prediction_array.append(y_pred)\n",
    "    \n",
    "    prediction_matrix = np.matrix(prediction_array)\n",
    "    #print(prediction_matrix.shape)\n",
    "    prediction_matrix = prediction_matrix.astype(float)\n",
    "    prediction_matrix_raw = prediction_matrix\n",
    "    y_pred_best = []\n",
    "    for i in range(0, len(prediction_array[0])):\n",
    "        y_pred_best.append(round(np.mean(prediction_matrix_raw[:,i])))    \n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_best)\n",
    "    print(\"Unweighted ensemble AUC: \", auc)\n",
    "    \n",
    "    \n",
    "    #Set valid set after #don't set valid ever\n",
    "    #print(\"super_ensemble_weight_finder_differential_evolution\", valid)\n",
    "#     if(valid):\n",
    "#         x_test = X_test_orig.copy()\n",
    "#         y_test = y_test_orig.copy()\n",
    "\n",
    "\n",
    "    bounds = [(0, 1) for x in range(0, len(best[0]))]\n",
    "\n",
    "    start = time.time()\n",
    "    de = scipy.optimize.differential_evolution(get_weighted_ensemble_prediction_de_cython,\n",
    "                                  bounds,\n",
    "                                  args=((prediction_matrix_raw,y_test)),\n",
    "                                  strategy='best1bin',\n",
    "                                  maxiter=20,\n",
    "                                  popsize=15,\n",
    "                                  tol=0.01,\n",
    "                                  mutation=(0.5, 1),\n",
    "                                  recombination=0.7,\n",
    "                                  seed=None,\n",
    "                                  callback=None,\n",
    "                                  disp=False,\n",
    "                                  polish=True,\n",
    "                                  init='latinhypercube',\n",
    "                                  atol=0,\n",
    "                                  updating='immediate',\n",
    "                                  workers=4,\n",
    "                                  constraints=(),\n",
    "                                  x0=None,\n",
    "                                  #integrality=None,\n",
    "                                  #vectorized=False\n",
    "                                              )\n",
    "    \n",
    "    score = (1-de.fun)\n",
    "    optimal_weights = de.x\n",
    "    \n",
    "        \n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        \n",
    "        if(model_train_time> model_train_time_warning_threshold):\n",
    "            print(\"Warning long DE weights train time, \", model_train_time, model_train_time_warning_threshold)\n",
    "\n",
    "\n",
    "    print(\"best weighted score: \", score, \"difference:\", score-auc)\n",
    "    #print(\"best weights\", optimal_weights, optimal_weights.shape)\n",
    "    return optimal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef61e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayesian model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90f33003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred_ann_torch_weighting(best, valid=False):\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_test_ann = y_test.copy()\n",
    "    \n",
    "    model_train_time_warning_threshold = 15\n",
    "    start = time.time()\n",
    "\n",
    "    target_ensemble = best[0]\n",
    "    #Get prediction matrix\n",
    "    #print('Get prediction matrix')\n",
    "    if(valid):\n",
    "        print(f\"get_y_pred_ann_torch_weighting {valid}\")\n",
    "        x_test = X_test_orig.copy()\n",
    "        y_test_ann = y_test_orig.copy()\n",
    "\n",
    "        prediction_array = []\n",
    "\n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "            # For model i, predict it's x_test\n",
    "            feature_columns = list(target_ensemble[i][2]) #get features model was trained on\n",
    "\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "                \n",
    "                model = target_ensemble[i][1]\n",
    "                \n",
    "                model.fit(X_train[feature_columns], y_train)\n",
    "                \n",
    "                prediction_array.append(\n",
    "                    model.predict(X_train[feature_columns])) #Use model to predict x train\n",
    "\n",
    "            else:\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(X_train[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "                model = target_ensemble[i][1]                                     \n",
    "                model.to(device) # Has this model been fitted??\n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "                prediction_array.append(y_hat                                    \n",
    "                    )\n",
    "\n",
    "        prediction_matrix_X_train = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_train = prediction_matrix_X_train.astype(float)\n",
    "        prediction_matrix_raw_X_train = prediction_matrix_X_train #Store predictions from x_train into matrix\n",
    "        \n",
    "        X_prediction_matrix_raw_X_train = prediction_matrix_raw_X_train.T\n",
    "\n",
    "        #Produce test results for valid   \n",
    "        prediction_array = []\n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "            feature_columns = list(target_ensemble[i][2])\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "                prediction_array.append(\n",
    "                    target_ensemble[i][1].predict(x_test[feature_columns])) #Generate predictions from stored models on validset\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(x_test[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "                model = target_ensemble[i][1]                                     \n",
    "                model.to(device)\n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "                prediction_array.append(y_hat                               \n",
    "                    )\n",
    "\n",
    "\n",
    "        prediction_matrix_X_test = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_test = prediction_matrix_X_test.astype(float)\n",
    "        prediction_matrix_raw_X_test = prediction_matrix_X_test\n",
    "\n",
    "        prediction_matrix_raw_X_test = prediction_matrix_raw_X_test.T #Transpose predictions into columns for each model. X >>y\n",
    "        test_data = TestData(torch.FloatTensor(prediction_matrix_raw_X_test))\n",
    "\n",
    "    elif valid==False:\n",
    "        #Make predictions on xtrain and y train, feed results into nn to learn weights to map ensemble to true. Apply nn to test ensemble preds\n",
    "        prediction_array = []\n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "\n",
    "\n",
    "                prediction_array.append(\n",
    "                        target_ensemble[i][5]) #Get stored y_pred from x_test (non validation set)\n",
    "\n",
    "\n",
    "        prediction_matrix_X_train = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_train = prediction_matrix_X_train.astype(float)\n",
    "        prediction_matrix_raw_X_train = prediction_matrix_X_train\n",
    "\n",
    "        X_prediction_matrix_raw_X_train = prediction_matrix_raw_X_train.T # transpose to matrix, columns are each model yhat vector\n",
    "\n",
    "        test_data = TestData(torch.FloatTensor(X_prediction_matrix_raw_X_train)) #set test data to train set, only learn weights from training\n",
    "        #y_test = y_train.copy()\n",
    "        prediction_matrix_raw_X_test = X_prediction_matrix_raw_X_train \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_data = TrainData(torch.FloatTensor(X_prediction_matrix_raw_X_train), \n",
    "                           torch.FloatTensor(np.array(y_train)))    #data set to learn weights for x_train model preds to y_train labels\n",
    "\n",
    "\n",
    "\n",
    "    #print(len(prediction_array[0]))\n",
    "    #print(prediction_matrix_raw_X_test.shape)\n",
    "\n",
    "\n",
    "    y_pred_unweighted = []\n",
    "    for i in range(0, len(prediction_array[0])):\n",
    "        y_pred_unweighted.append(round(np.mean(prediction_matrix_raw_X_test.T[:,i])))    \n",
    "\n",
    "\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test_ann, y_pred_unweighted)\n",
    "\n",
    "    mccscore_unweighted = matthews_corrcoef(y_test_ann, y_pred_unweighted)\n",
    "\n",
    "\n",
    "    y_pred_ensemble = train_ann_weight(X_prediction_matrix_raw_X_train.shape[1], int(X_prediction_matrix_raw_X_train.shape[0]), train_data, test_data)\n",
    "\n",
    "    #print(\"Ensemble ANN weighting training AUC: \", auc_score_weighted)\n",
    "\n",
    "\n",
    "    if(any(np.isnan(y_pred_ensemble))):\n",
    "        print(\"Torch model nan, returning random y pred vector\")\n",
    "        #zero_vector = [x for x in range(0, len(y_pred))]\n",
    "        #y_pred = zero_vector\n",
    "        random_y_pred_vector = (np.random.choice(a=[False, True], size=(len(y_test_ann,)))).astype(int)\n",
    "        y_pred = random_y_pred_vector\n",
    "        y_pred_ensemble = random_y_pred_vector\n",
    "    else:\n",
    "        #plot_auc(y_hat, f\"Deep ANN Torch {para_str}\")    \n",
    "        pass\n",
    "\n",
    "    auc_score_weighted = metrics.roc_auc_score(y_test_ann, y_pred_ensemble)\n",
    "\n",
    "    mccscore_weighted = matthews_corrcoef(y_test_ann, y_pred_ensemble)\n",
    "\n",
    "    auc_score_weighted = round(metrics.roc_auc_score(y_test_ann,y_pred_ensemble), 4)\n",
    "    print(\"ANN unweighted ensemble AUC: \", auc)\n",
    "    print(\"ANN weighted   ensemble AUC: \", auc_score_weighted)\n",
    "    print(\"ANN weighted   ensemble AUC difference: \", auc_score_weighted-auc)\n",
    "    print(\"ANN unweighted ensemble MCC: \", mccscore_unweighted)\n",
    "    print(\"ANN weighted   ensemble MCC: \", mccscore_weighted)\n",
    "\n",
    "\n",
    "    #score = (1-de.fun)\n",
    "    #optimal_weights = de.x\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "#     \n",
    "    #print(len(y_pred_ensemble))\n",
    "    torch.cuda.empty_cache() # exp\n",
    "    \n",
    "    return y_pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "031f6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ann_weight(input_shape, batch_size, train_data, test_data):\n",
    "    free_gpu = str(get_free_gpu())\n",
    "\n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "    parameter_space = {\n",
    "        'column_length':[input_shape],\n",
    "       #'epochs': [50, 200],\n",
    "    'batch_size': [batch_size],#,int(X_train.shape[0]/100), int(X_train.shape[0]/200)],\n",
    "    #'learning_rate': lr_space,\n",
    "    #'learning_rate': [0.1, 0.001, 0.0005, 0.0001],\n",
    "    'deep_layers_1':[2],\n",
    "    'dropout_val':[0.001]\n",
    "    }\n",
    "\n",
    "    additional_grid = {\n",
    "        'epochs': [20],\n",
    "        #'epochs':[100],\n",
    "    'learning_rate': [0.0001]\n",
    "    }\n",
    "    size_test = []\n",
    "    # Loop over al grid search combinations\n",
    "    for values in itertools.product(*additional_grid.values()):\n",
    "        point = dict(zip(additional_grid.keys(), values))\n",
    "        # merge the general settings\n",
    "        settings = { **point}\n",
    "        #print(settings)\n",
    "        size_test.append(settings)\n",
    "\n",
    "    #print(len(size_test))\n",
    "\n",
    "    # Select a random sample from the global parameter space\n",
    "    sample_parameter_space = {}\n",
    "    for key in parameter_space.keys():\n",
    "        sample_parameter_space[key] = random.choice(parameter_space.get(key))\n",
    "\n",
    "    additional_param_sample = random.choice(size_test)\n",
    "\n",
    "    additional_param_sample = {}\n",
    "    for key in additional_grid.keys():\n",
    "        additional_param_sample[key] = random.choice(additional_grid.get(key))    \n",
    "\n",
    "    print(sample_parameter_space)\n",
    "\n",
    "    print(additional_param_sample)\n",
    "\n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"]=free_gpu\n",
    "\n",
    "    device = torch.device(f\"cuda:{free_gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=sample_parameter_space['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "    # fit model with random sample of global parameter space\n",
    "    model = BinaryClassification(**sample_parameter_space)\n",
    "    \n",
    "    model.to(device)\n",
    "    #print(model)    \n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=additional_param_sample['learning_rate'])\n",
    "    model.train()\n",
    "    for e in range(1, additional_param_sample['epochs']+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f} | AUC: {torchmetrics.functional.auc(y_batch, y_pred, reorder=True)}')\n",
    "\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f} | AUC: {torchmetrics.functional.auc(y_batch, y_pred, reorder=True)}')\n",
    "\n",
    "    para_str = (str(settings).replace(\"'\", \"_\").replace(\":\", \"_\").replace(\",\", \"_\").replace(\"{\", \"_\").replace(\"}\", \"_\").replace(\" \", \"_\")).replace(\"__\", \"_\")    \n",
    "\n",
    "    y_pred_ensemble = model(test_data.X_data.to(device))\n",
    "\n",
    "    y_pred_ensemble = torch.round(torch.sigmoid(y_pred_ensemble)).cpu().detach().numpy().flatten()\n",
    "\n",
    "    return y_pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bf0d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = get_y_pred_ann_torch_weighting(best, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "972b608e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#res = get_y_pred_log_reg_weighting(best, valid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d561a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6f79dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred_log_reg_weighting(best, valid=False):\n",
    "\n",
    "    model_train_time_warning_threshold = 15\n",
    "    start = time.time()\n",
    "    \n",
    "    global y_test\n",
    "\n",
    "    target_ensemble = best[0]\n",
    "    #Get prediction matrix\n",
    "    print('Get prediction matrix')\n",
    "    if(valid):\n",
    "        print(f\"get_y_pred_log_reg_weighting {valid}\")\n",
    "        x_test = X_test_orig.copy()\n",
    "        y_test = y_test_orig.copy()\n",
    "\n",
    "        prediction_array = []\n",
    "\n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "            # For model i, predict it's x_test\n",
    "            feature_columns = list(target_ensemble[i][2]) #get features model was trained on\n",
    "\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "                \n",
    "                model = target_ensemble[i][1]\n",
    "                \n",
    "                model.fit(X_train[feature_columns], y_train)\n",
    "                \n",
    "                prediction_array.append(\n",
    "                    model.predict(X_train[feature_columns])) #Use model to predict x train\n",
    "\n",
    "            else:\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(X_train[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "                model = target_ensemble[i][1]                                     \n",
    "                model.to(device) # Has this model been fitted??\n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "                prediction_array.append(y_hat                                    \n",
    "                    )\n",
    "\n",
    "        prediction_matrix_X_train = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_train = prediction_matrix_X_train.astype(float)\n",
    "        prediction_matrix_raw_X_train = prediction_matrix_X_train #Store predictions from x_train into matrix\n",
    "        \n",
    "        X_prediction_matrix_raw_X_train = prediction_matrix_raw_X_train.T\n",
    "\n",
    "        #Produce test results for valid   \n",
    "        prediction_array = []\n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "            feature_columns = list(target_ensemble[i][2])\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "                prediction_array.append(\n",
    "                    target_ensemble[i][1].predict(x_test[feature_columns])) #Generate predictions from stored models on validset\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(x_test[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "                model = target_ensemble[i][1]                                     \n",
    "                model.to(device)\n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "                prediction_array.append(y_hat                               \n",
    "                    )\n",
    "\n",
    "\n",
    "        prediction_matrix_X_test = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_test = prediction_matrix_X_test.astype(float)\n",
    "        prediction_matrix_raw_X_test = prediction_matrix_X_test\n",
    "\n",
    "        prediction_matrix_raw_X_test = prediction_matrix_raw_X_test.T #Transpose predictions into columns for each model. X >>y\n",
    "        test_data = TestData(torch.FloatTensor(prediction_matrix_raw_X_test))\n",
    "\n",
    "    elif valid==False:\n",
    "        #Make predictions on xtrain and y train, feed results into nn to learn weights to map ensemble to true. Apply nn to test ensemble preds\n",
    "        prediction_array = []\n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "\n",
    "\n",
    "                prediction_array.append(\n",
    "                        target_ensemble[i][5]) #Get stored y_pred from x_test (non validation set)\n",
    "\n",
    "\n",
    "        prediction_matrix_X_train = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_train = prediction_matrix_X_train.astype(float)\n",
    "        prediction_matrix_raw_X_train = prediction_matrix_X_train\n",
    "\n",
    "        X_prediction_matrix_raw_X_train = prediction_matrix_raw_X_train.T # transpose to matrix, columns are each model yhat vector\n",
    "\n",
    "        test_data = X_prediction_matrix_raw_X_train #TestData(torch.FloatTensor(X_prediction_matrix_raw_X_train)) #set test data to train set, only learn weights from training\n",
    "        #y_test = y_train.copy()\n",
    "        prediction_matrix_raw_X_test = X_prediction_matrix_raw_X_train \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     train_data = TrainData(torch.FloatTensor(X_prediction_matrix_raw_X_train), \n",
    "#                            torch.FloatTensor(np.array(y_train)))    #data set to learn weights for x_train model preds to y_train labels\n",
    "    train_data_X = X_prediction_matrix_raw_X_train.copy()\n",
    "    train_data_y = y_test.copy()\n",
    "    print(train_data_X.shape, train_data_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred_unweighted = []\n",
    "    for i in range(0, len(prediction_array[0])):\n",
    "        y_pred_unweighted.append(round(np.mean(prediction_matrix_raw_X_test.T[:,i])))    \n",
    "\n",
    "\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_unweighted)\n",
    "\n",
    "    mccscore_unweighted = matthews_corrcoef(y_test, y_pred_unweighted)\n",
    "\n",
    "    \n",
    "    y_pred_ensemble = get_weighted_log_reg_ensemble(train_data_X, train_data_y, train_data_y)\n",
    "\n",
    "    \n",
    "    auc_score_weighted = metrics.roc_auc_score(y_test, y_pred_ensemble)\n",
    "\n",
    "    mccscore_weighted = matthews_corrcoef(y_test, y_pred_ensemble)\n",
    "\n",
    "    auc_score_weighted = round(metrics.roc_auc_score(y_test,y_pred_ensemble), 4)\n",
    "    print(\"LogReg unweighted ensemble AUC: \", auc)\n",
    "    print(\"LogReg weighted   ensemble AUC: \", auc_score_weighted)\n",
    "    print(\"LogReg weighted   ensemble AUC difference: \", auc_score_weighted-auc)\n",
    "    print(\"LogReg unweighted ensemble MCC: \", mccscore_unweighted)\n",
    "    print(\"LogReg weighted   ensemble MCC: \", mccscore_weighted)\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "\n",
    "    print(len(y_pred_ensemble))\n",
    "    return y_pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "940a0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_log_reg_ensemble(X_train, y_train, X_test):\n",
    "    \n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_ensemble = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "    return y_pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb043711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred_ann_torch_weighting_grid(best, sample_parameter_space, additional_param_sample, valid=False):\n",
    "    #dont split pred matrix. it is produced by train set...\n",
    "    \n",
    "    #just apply its results to test data results \n",
    "\n",
    "    \n",
    "    #%%prun\n",
    "    #X = allData_float3_imputed\n",
    "    #global get_weighted_ensemble_prediction\n",
    "    model_train_time_warning_threshold = 15\n",
    "    start = time.time()\n",
    "    # Get prediction matrix:\n",
    "    X_train, x_test, y_train, y_test = train_test_split( #Here we DONT effectively crossfold validate +1 ypred must be uniform across all base\n",
    "            X, y, test_size=0.25, random_state=1 \n",
    "        )\n",
    "    print(len(X_train),len(X_test),len(y_test),len(y_test),len(X_test_orig),len(y_test_orig))\n",
    "\n",
    "    #print(len(x_test), 'x_test')\n",
    "    target_ensemble = best[0]\n",
    "    #Get prediction matrix\n",
    "    #print('Get prediction matrix')\n",
    "    if(valid):\n",
    "        #print(f\"get_y_pred_ann_torch_weighting {valid}\")\n",
    "        x_test = X_test_orig.copy()\n",
    "        y_test = y_test_orig.copy()\n",
    "\n",
    "        #print(len(x_test), 'x_test')\n",
    "\n",
    "        prediction_array = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "            # For model i, predict it's x_test\n",
    "            feature_columns = list(target_ensemble[i][2])#list(target_ensemble[i][3].columns)\n",
    "\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "                prediction_array.append(\n",
    "                    target_ensemble[i][1].predict(X_train[feature_columns])) # Target for resolving GPU/torch model types\n",
    "\n",
    "            else:\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(X_train[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "                model = target_ensemble[i][1]                                     #Has this model already been trained?\n",
    "                model.to(device)\n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "                prediction_array.append(y_hat                                    #Do we need to handle nans here?\n",
    "                    )\n",
    "\n",
    "        prediction_matrix_X_train = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_train = prediction_matrix_X_train.astype(float)\n",
    "        prediction_matrix_raw_X_train = prediction_matrix_X_train\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        #Make predictions on xtrain and y train, feed results into nn to learn weights to map ensemble to true. Apply nn to test ensemble preds\n",
    "        prediction_array = []\n",
    "        for i in tqdm(range(0, len(target_ensemble))):\n",
    "            feature_columns = list(target_ensemble[i][2])\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "                    prediction_array.append(\n",
    "                        target_ensemble[i][1].predict(X_train[feature_columns])) # Target for resolving GPU/torch model types\n",
    "\n",
    "            else:\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(X_train[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "                model = target_ensemble[i][1]                                     #Has this model already been trained?\n",
    "                model.to(device)\n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "                prediction_array.append(y_hat                                    #Do we need to handle nans here?\n",
    "                    )\n",
    "\n",
    "\n",
    "        prediction_matrix_X_train = np.matrix(prediction_array)\n",
    "        prediction_matrix_X_train = prediction_matrix_X_train.astype(float)\n",
    "        prediction_matrix_raw_X_train = prediction_matrix_X_train\n",
    "\n",
    "    #Produce test results    \n",
    "    prediction_array = []\n",
    "    for i in tqdm(range(0, len(target_ensemble))):\n",
    "        feature_columns = list(target_ensemble[i][2])\n",
    "        if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "            prediction_array.append(\n",
    "                target_ensemble[i][1].predict(x_test[feature_columns])) # Target for resolving GPU/torch model types\n",
    "\n",
    "        else:\n",
    "\n",
    "            test_data = TestData(torch.FloatTensor(x_test[feature_columns].values))\n",
    "            test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "            device = torch.device(\"cpu\")\n",
    "            model = target_ensemble[i][1]                                     #Has this model already been trained?\n",
    "            model.to(device)\n",
    "            y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "            y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "            y_hat = y_hat.astype(int).flatten()\n",
    "            prediction_array.append(y_hat                                    #Do we need to handle nans here?\n",
    "                )\n",
    "\n",
    "\n",
    "    prediction_matrix_X_test = np.matrix(prediction_array)\n",
    "    prediction_matrix_X_test = prediction_matrix_X_test.astype(float)\n",
    "    prediction_matrix_raw_X_test = prediction_matrix_X_test\n",
    "\n",
    "\n",
    "    #With prediction matrix    \n",
    "    #print('With prediction matrix..')\n",
    "    X_prediction_matrix_raw_X_train = prediction_matrix_raw_X_train.T\n",
    "    prediction_matrix_raw_X_test = prediction_matrix_raw_X_test.T\n",
    "    # if(valid):\n",
    "\n",
    "\n",
    "    train_data = TrainData(torch.FloatTensor(X_prediction_matrix_raw_X_train), \n",
    "                           torch.FloatTensor(np.array(y_train)))    \n",
    "    test_data = TestData(torch.FloatTensor(prediction_matrix_raw_X_test))\n",
    "\n",
    "\n",
    "    #print(\"Dimensions of test_ensemble data for first calc\", X_test_ensemble.shape)\n",
    "\n",
    "    free_gpu = str(get_free_gpu())\n",
    "\n",
    "    # Initialise global parameter space----------------------------------------------------------------\n",
    "\n",
    "  \n",
    "\n",
    "    print(sample_parameter_space)\n",
    "\n",
    "    print(additional_param_sample)\n",
    "\n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"]=free_gpu\n",
    "\n",
    "    device = torch.device(f\"cuda:{free_gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #print(device)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=sample_parameter_space['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "    # fit model with random sample of global parameter space\n",
    "    model = BinaryClassification(**sample_parameter_space)\n",
    "\n",
    "    model.to(device)\n",
    "    #print(model)    \n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=additional_param_sample['learning_rate'])\n",
    "    model.train()\n",
    "    for e in range(1, additional_param_sample['epochs']+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f} | AUC: {torchmetrics.functional.auc(y_batch, y_pred, reorder=True)}')\n",
    "\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f} | AUC: {torchmetrics.functional.auc(y_batch, y_pred, reorder=True)}')\n",
    "\n",
    "    para_str = (str(settings).replace(\"'\", \"_\").replace(\":\", \"_\").replace(\",\", \"_\").replace(\"{\", \"_\").replace(\"}\", \"_\").replace(\" \", \"_\")).replace(\"__\", \"_\")    \n",
    "\n",
    "    y_pred_ensemble = model(test_data.X_data.to(device))\n",
    "\n",
    "    y_pred_ensemble = torch.round(torch.sigmoid(y_pred_ensemble)).cpu().detach().numpy().flatten()\n",
    "\n",
    "    #print(\"y_pred_ensemble_weights_shape:\", y_pred_ensemble.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_unweighted = []\n",
    "    for i in range(0, len(prediction_array[0])):\n",
    "        y_pred_unweighted.append(round(np.mean(prediction_matrix_X_test[:,i])))    \n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_unweighted)\n",
    "\n",
    "    mccscore_unweighted = matthews_corrcoef(y_test, y_pred_unweighted)\n",
    "\n",
    "\n",
    "    #print(\"Ensemble ANN weighting training AUC: \", auc_score_weighted)\n",
    "\n",
    "\n",
    "    if(any(np.isnan(y_pred_ensemble))):\n",
    "        print(\"Torch model nan, returning random y pred vector\")\n",
    "        #zero_vector = [x for x in range(0, len(y_pred))]\n",
    "        #y_pred = zero_vector\n",
    "        random_y_pred_vector = (np.random.choice(a=[False, True], size=(len(y_test,)))).astype(int)\n",
    "        y_pred = random_y_pred_vector\n",
    "        y_pred_ensemble = random_y_pred_vector\n",
    "    else:\n",
    "        #plot_auc(y_hat, f\"Deep ANN Torch {para_str}\")    \n",
    "        pass\n",
    "\n",
    "    auc_score_weighted = metrics.roc_auc_score(y_test, y_pred_ensemble)\n",
    "    \n",
    "    mccscore_weighted = matthews_corrcoef(y_test, y_pred_ensemble)\n",
    "\n",
    "    auc_score_weighted = round(metrics.roc_auc_score(y_test,y_pred_ensemble), 4)\n",
    "    print(\"ANN unweighted ensemble AUC: \", auc)\n",
    "    print(\"ANN weighted   ensemble AUC: \", auc_score_weighted)\n",
    "    print(\"ANN weighted   ensemble AUC difference: \", auc_score_weighted-auc)\n",
    "    print(\"ANN unweighted ensemble MCC: \", mccscore_unweighted)\n",
    "    print(\"ANN weighted   ensemble MCC: \", mccscore_weighted)\n",
    "\n",
    "\n",
    "    #score = (1-de.fun)\n",
    "    #optimal_weights = de.x\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    model_train_time = int(end-start)\n",
    "    if(debug):\n",
    "        debug_base_learner(model, mccscore, X_train, auc_score, model_train_time)\n",
    "\n",
    "    with open(file_path + \"ann_weight_log.txt\",\"a\") as file:\n",
    "        file.write(\"\\n\")\n",
    "        file.write(str(sample_parameter_space))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(str(additional_param_sample))\n",
    "        file.write(str(\"\\n\"+\n",
    "        str(X_train.shape)+\n",
    "       \"ANN weighted ensemble AUC: \"+ str(auc_score_weighted)+ \"_\"+\n",
    "       \"ANN weighted ensemble AUC difference: \" + str(auc_score_weighted-auc)\n",
    "       ))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    #print(len(y_pred_ensemble))\n",
    "    return auc_score_weighted-auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40122626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target function to append weighting function/neural network for weighting\n",
    "\n",
    "def get_best_y_pred(best):\n",
    "    X_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=1 # should this be one...?\n",
    "    )\n",
    "    \n",
    "    x_test = X_test_orig.copy()\n",
    "    y_test = y_test_orig.copy()\n",
    "    \n",
    "    prediction_array = []\n",
    "    target_ensemble = best[0]\n",
    "    for i in tqdm(range(0, len(target_ensemble))):\n",
    "        # For model i, predict it's x_test\n",
    "        feature_columns = list(target_ensemble[i][2])#list(target_ensemble[i][3].columns)\n",
    "        \n",
    "        if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "            prediction_array.append(\n",
    "                target_ensemble[i][1].predict(x_test)) # Target for resolving GPU/torch model types\n",
    "        \n",
    "        else:\n",
    "\n",
    "            test_data = TestData(torch.FloatTensor(x_test.values))\n",
    "            test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "        \n",
    "            device = torch.device(\"cpu\")\n",
    "            model = target_ensemble[i][1]                                     #Has this model already been trained?\n",
    "            model.to(device)\n",
    "            y_hat = model(test_data.X_data.to(device))\n",
    "    \n",
    "            y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "            \n",
    "            y_hat = y_hat.astype(int).flatten()\n",
    "            prediction_array.append(y_hat                                    #Do we need to handle nans here?\n",
    "                )\n",
    "        \n",
    "    prediction_matrix = np.matrix(prediction_array)\n",
    "\n",
    "    # collapse the mean of each models prediction for each case into a binary label returning a final y_pred composite score from each model\n",
    "    y_pred_best = []\n",
    "    for i in tqdm(range(0, len(prediction_array[0]))):\n",
    "        # y_pred_best.append(round(np.mean(np.matrix(prediction_array)[:,i])))\n",
    "        try:\n",
    "            y_pred_best.append(stats.mode(\n",
    "                np.matrix(prediction_array)[:, i], keepdims=True)[0][0][0])\n",
    "        except:\n",
    "            y_pred_best.append(stats.mode(\n",
    "                np.matrix(prediction_array)[:, i])[0][0][0])\n",
    "            \n",
    "    return y_pred_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e284484c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Target function to append weighting function/neural network for weighting\n",
    "\n",
    "def get_best_y_pred_valid(best):\n",
    "    X_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=1 # should this be one...?\n",
    "    )\n",
    "    #x_test = X_test_orig.copy()\n",
    "    #y_test = y_test_orig.copy()\n",
    "    prediction_array = []\n",
    "    target_ensemble = best[0]\n",
    "    for i in tqdm(range(0, len(target_ensemble))):\n",
    "        # For model i, predict it's x_test\n",
    "        feature_columns = list(target_ensemble[i][2])#list(target_ensemble[i][3].columns)\n",
    "        \n",
    "        if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "            prediction_array.append(\n",
    "                target_ensemble[i][1].predict(X_test_orig[feature_columns])) # Target for resolving GPU/torch model types\n",
    "        \n",
    "        else:\n",
    "#             print(\"get_best_y_pred, handling torch model prediction\")\n",
    "#             scaler = StandardScaler()\n",
    "#             print(\"feature_columns:\")\n",
    "#             print(feature_columns)\n",
    "#             print(X_train)\n",
    "#             X_train = scaler.fit_transform(X_train[feature_columns])\n",
    "#             x_test = scaler.transform(x_test[feature_columns])\n",
    "\n",
    "#             train_data = TrainData(torch.FloatTensor(X_train), \n",
    "#                                    torch.FloatTensor(y_train))\n",
    "            test_data = TestData(torch.FloatTensor(X_test_orig[feature_columns].values))\n",
    "            test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "        \n",
    "            device = torch.device(\"cpu\")\n",
    "            model = target_ensemble[i][1]                                     #Has this model already been trained?\n",
    "            model.to(device)\n",
    "            y_hat = model(test_data.X_data.to(device))\n",
    "    \n",
    "            y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "            \n",
    "            y_hat = y_hat.astype(int).flatten()\n",
    "            prediction_array.append(y_hat                                    #Do we need to handle nans here?\n",
    "                )\n",
    "        \n",
    "    prediction_matrix = np.matrix(prediction_array)\n",
    "\n",
    "    # collapse the mean of each models prediction for each case into a binary label returning a final y_pred composite score from each model\n",
    "    y_pred_best = []\n",
    "    for i in tqdm(range(0, len(prediction_array[0]))):\n",
    "        # y_pred_best.append(round(np.mean(np.matrix(prediction_array)[:,i])))\n",
    "        y_pred_best.append(stats.mode(\n",
    "            #np.matrix(prediction_array)[:, i], keepdims=None)[0][0][0])\n",
    "            np.matrix(prediction_array)[:, i])[0][0][0])\n",
    "    return y_pred_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c28def81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_y_pred_unweighted(best, valid=False):\n",
    "    X_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=1 # should this be one...?\n",
    "    )\n",
    "    \n",
    "    if(valid):\n",
    "        x_test = X_test_orig.copy()\n",
    "        y_test = y_test_orig.copy()\n",
    "    \n",
    "    prediction_array = []\n",
    "    target_ensemble = best[0]\n",
    "    for i in range(0, len(target_ensemble)):\n",
    "\n",
    "        feature_columns = list(target_ensemble[i][2])#list(target_ensemble[i][3].columns)\n",
    "        \n",
    "        if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "            prediction_array.append(\n",
    "                target_ensemble[i][1].predict(x_test[feature_columns])) # Target for resolving GPU/torch model types\n",
    "        \n",
    "        else:\n",
    "\n",
    "            test_data = TestData(torch.FloatTensor(x_test[feature_columns].values))\n",
    "            test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "        \n",
    "            device = torch.device(\"cpu\")\n",
    "            model = target_ensemble[i][1]                                     #Has this model already been trained?\n",
    "            model.to(device)\n",
    "            y_hat = model(test_data.X_data.to(device))\n",
    "    \n",
    "            y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "            \n",
    "            y_hat = y_hat.astype(int).flatten()\n",
    "            prediction_array.append(y_hat                                    #Do we need to handle nans here?\n",
    "                )\n",
    "    \n",
    "    prediction_matrix = np.matrix(prediction_array)\n",
    "\n",
    "    # collapse the mean of each models prediction for each case into a binary label returning a final y_pred composite score from each model\n",
    "    y_pred_best = []\n",
    "    for i in range(0, len(prediction_array[0])):\n",
    "        # y_pred_best.append(round(np.mean(np.matrix(prediction_array)[:,i])))\n",
    "        try:\n",
    "            y_pred_best.append(stats.mode(\n",
    "                np.matrix(prediction_array)[:, i], keepdims=True)[0][0][0])\n",
    "        except:\n",
    "            y_pred_best.append(stats.mode(\n",
    "                np.matrix(prediction_array)[:, i])[0][0][0])\n",
    "    return y_pred_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76825c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_y_pred_unweighted(best, valid=False):\n",
    "    \n",
    "    if(valid):\n",
    "        x_test = X_test_orig.copy()\n",
    "        y_test = y_test_orig.copy()\n",
    "    \n",
    "    prediction_array = []\n",
    "    target_ensemble = best[0]\n",
    "    if(valid):\n",
    "        for i in range(0, len(target_ensemble)):\n",
    "\n",
    "            feature_columns = list(target_ensemble[i][2])#list(target_ensemble[i][3].columns)\n",
    "\n",
    "            if(type(target_ensemble[i][1]) is not BinaryClassification):\n",
    "\n",
    "                model = target_ensemble[i][1]\n",
    "                \n",
    "                model.fit(X_train[feature_columns], y_train)\n",
    "\n",
    "                prediction_array.append(\n",
    "                    model.predict(x_test[feature_columns])) \n",
    "\n",
    "            else:\n",
    "\n",
    "                test_data = TestData(torch.FloatTensor(x_test[feature_columns].values))\n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                device = torch.device(\"cpu\")\n",
    "                model = target_ensemble[i][1]                                #Has this model been fitted already?     \n",
    "                model.to(device)\n",
    "                \n",
    "                #model.fit(X_train, y_train)\n",
    "                \n",
    "                y_hat = model(test_data.X_data.to(device))\n",
    "\n",
    "                y_hat = torch.round(torch.sigmoid(y_hat)).cpu().detach().numpy()\n",
    "\n",
    "                y_hat = y_hat.astype(int).flatten()\n",
    "                prediction_array.append(y_hat                                    \n",
    "                    )\n",
    "                \n",
    "    else:\n",
    "        for i in range(0, len(target_ensemble)):\n",
    "            y_pred = target_ensemble[i][5]\n",
    "            prediction_array.append(y_pred                                    \n",
    "                    )\n",
    "    \n",
    "    \n",
    "    prediction_matrix = np.matrix(prediction_array)\n",
    "\n",
    "    # collapse the mean of each models prediction for each case into a binary label returning a final y_pred composite score from each model\n",
    "    y_pred_best = []\n",
    "    for i in range(0, len(prediction_array[0])):\n",
    "        # y_pred_best.append(round(np.mean(np.matrix(prediction_array)[:,i])))\n",
    "        try:\n",
    "            y_pred_best.append(stats.mode(\n",
    "                np.matrix(prediction_array)[:, i], keepdims=True)[0][0][0])\n",
    "        except:\n",
    "            y_pred_best.append(stats.mode(\n",
    "                np.matrix(prediction_array)[:, i])[0][0][0])\n",
    "    return y_pred_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75c2e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2755490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<!-- Generated by Cython 3.0.8 -->\n",
       "<html>\n",
       "<head>\n",
       "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
       "    <title>Cython: _cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61.pyx</title>\n",
       "    <style type=\"text/css\">\n",
       "    \n",
       "body.cython { font-family: courier; font-size: 12; }\n",
       "\n",
       ".cython.tag  {  }\n",
       ".cython.line { color: #000000; margin: 0em }\n",
       ".cython.code { font-size: 9; color: #444444; display: none; margin: 0px 0px 0px 8px; border-left: 8px none; }\n",
       "\n",
       ".cython.line .run { background-color: #B0FFB0; }\n",
       ".cython.line .mis { background-color: #FFB0B0; }\n",
       ".cython.code.run  { border-left: 8px solid #B0FFB0; }\n",
       ".cython.code.mis  { border-left: 8px solid #FFB0B0; }\n",
       "\n",
       ".cython.code .py_c_api  { color: red; }\n",
       ".cython.code .py_macro_api  { color: #FF7000; }\n",
       ".cython.code .pyx_c_api  { color: #FF3000; }\n",
       ".cython.code .pyx_macro_api  { color: #FF7000; }\n",
       ".cython.code .refnanny  { color: #FFA000; }\n",
       ".cython.code .trace  { color: #FFA000; }\n",
       ".cython.code .error_goto  { color: #FFA000; }\n",
       "\n",
       ".cython.code .coerce  { color: #008000; border: 1px dotted #008000 }\n",
       ".cython.code .py_attr { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_attr  { color: #0000FF; }\n",
       ".cython.code .py_call { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_call  { color: #0000FF; }\n",
       "\n",
       ".cython.score-0 {background-color: #FFFFff;}\n",
       ".cython.score-1 {background-color: #FFFFe7;}\n",
       ".cython.score-2 {background-color: #FFFFd4;}\n",
       ".cython.score-3 {background-color: #FFFFc4;}\n",
       ".cython.score-4 {background-color: #FFFFb6;}\n",
       ".cython.score-5 {background-color: #FFFFaa;}\n",
       ".cython.score-6 {background-color: #FFFF9f;}\n",
       ".cython.score-7 {background-color: #FFFF96;}\n",
       ".cython.score-8 {background-color: #FFFF8d;}\n",
       ".cython.score-9 {background-color: #FFFF86;}\n",
       ".cython.score-10 {background-color: #FFFF7f;}\n",
       ".cython.score-11 {background-color: #FFFF79;}\n",
       ".cython.score-12 {background-color: #FFFF73;}\n",
       ".cython.score-13 {background-color: #FFFF6e;}\n",
       ".cython.score-14 {background-color: #FFFF6a;}\n",
       ".cython.score-15 {background-color: #FFFF66;}\n",
       ".cython.score-16 {background-color: #FFFF62;}\n",
       ".cython.score-17 {background-color: #FFFF5e;}\n",
       ".cython.score-18 {background-color: #FFFF5b;}\n",
       ".cython.score-19 {background-color: #FFFF57;}\n",
       ".cython.score-20 {background-color: #FFFF55;}\n",
       ".cython.score-21 {background-color: #FFFF52;}\n",
       ".cython.score-22 {background-color: #FFFF4f;}\n",
       ".cython.score-23 {background-color: #FFFF4d;}\n",
       ".cython.score-24 {background-color: #FFFF4b;}\n",
       ".cython.score-25 {background-color: #FFFF48;}\n",
       ".cython.score-26 {background-color: #FFFF46;}\n",
       ".cython.score-27 {background-color: #FFFF44;}\n",
       ".cython.score-28 {background-color: #FFFF43;}\n",
       ".cython.score-29 {background-color: #FFFF41;}\n",
       ".cython.score-30 {background-color: #FFFF3f;}\n",
       ".cython.score-31 {background-color: #FFFF3e;}\n",
       ".cython.score-32 {background-color: #FFFF3c;}\n",
       ".cython.score-33 {background-color: #FFFF3b;}\n",
       ".cython.score-34 {background-color: #FFFF39;}\n",
       ".cython.score-35 {background-color: #FFFF38;}\n",
       ".cython.score-36 {background-color: #FFFF37;}\n",
       ".cython.score-37 {background-color: #FFFF36;}\n",
       ".cython.score-38 {background-color: #FFFF35;}\n",
       ".cython.score-39 {background-color: #FFFF34;}\n",
       ".cython.score-40 {background-color: #FFFF33;}\n",
       ".cython.score-41 {background-color: #FFFF32;}\n",
       ".cython.score-42 {background-color: #FFFF31;}\n",
       ".cython.score-43 {background-color: #FFFF30;}\n",
       ".cython.score-44 {background-color: #FFFF2f;}\n",
       ".cython.score-45 {background-color: #FFFF2e;}\n",
       ".cython.score-46 {background-color: #FFFF2d;}\n",
       ".cython.score-47 {background-color: #FFFF2c;}\n",
       ".cython.score-48 {background-color: #FFFF2b;}\n",
       ".cython.score-49 {background-color: #FFFF2b;}\n",
       ".cython.score-50 {background-color: #FFFF2a;}\n",
       ".cython.score-51 {background-color: #FFFF29;}\n",
       ".cython.score-52 {background-color: #FFFF29;}\n",
       ".cython.score-53 {background-color: #FFFF28;}\n",
       ".cython.score-54 {background-color: #FFFF27;}\n",
       ".cython.score-55 {background-color: #FFFF27;}\n",
       ".cython.score-56 {background-color: #FFFF26;}\n",
       ".cython.score-57 {background-color: #FFFF26;}\n",
       ".cython.score-58 {background-color: #FFFF25;}\n",
       ".cython.score-59 {background-color: #FFFF24;}\n",
       ".cython.score-60 {background-color: #FFFF24;}\n",
       ".cython.score-61 {background-color: #FFFF23;}\n",
       ".cython.score-62 {background-color: #FFFF23;}\n",
       ".cython.score-63 {background-color: #FFFF22;}\n",
       ".cython.score-64 {background-color: #FFFF22;}\n",
       ".cython.score-65 {background-color: #FFFF22;}\n",
       ".cython.score-66 {background-color: #FFFF21;}\n",
       ".cython.score-67 {background-color: #FFFF21;}\n",
       ".cython.score-68 {background-color: #FFFF20;}\n",
       ".cython.score-69 {background-color: #FFFF20;}\n",
       ".cython.score-70 {background-color: #FFFF1f;}\n",
       ".cython.score-71 {background-color: #FFFF1f;}\n",
       ".cython.score-72 {background-color: #FFFF1f;}\n",
       ".cython.score-73 {background-color: #FFFF1e;}\n",
       ".cython.score-74 {background-color: #FFFF1e;}\n",
       ".cython.score-75 {background-color: #FFFF1e;}\n",
       ".cython.score-76 {background-color: #FFFF1d;}\n",
       ".cython.score-77 {background-color: #FFFF1d;}\n",
       ".cython.score-78 {background-color: #FFFF1c;}\n",
       ".cython.score-79 {background-color: #FFFF1c;}\n",
       ".cython.score-80 {background-color: #FFFF1c;}\n",
       ".cython.score-81 {background-color: #FFFF1c;}\n",
       ".cython.score-82 {background-color: #FFFF1b;}\n",
       ".cython.score-83 {background-color: #FFFF1b;}\n",
       ".cython.score-84 {background-color: #FFFF1b;}\n",
       ".cython.score-85 {background-color: #FFFF1a;}\n",
       ".cython.score-86 {background-color: #FFFF1a;}\n",
       ".cython.score-87 {background-color: #FFFF1a;}\n",
       ".cython.score-88 {background-color: #FFFF1a;}\n",
       ".cython.score-89 {background-color: #FFFF19;}\n",
       ".cython.score-90 {background-color: #FFFF19;}\n",
       ".cython.score-91 {background-color: #FFFF19;}\n",
       ".cython.score-92 {background-color: #FFFF19;}\n",
       ".cython.score-93 {background-color: #FFFF18;}\n",
       ".cython.score-94 {background-color: #FFFF18;}\n",
       ".cython.score-95 {background-color: #FFFF18;}\n",
       ".cython.score-96 {background-color: #FFFF18;}\n",
       ".cython.score-97 {background-color: #FFFF17;}\n",
       ".cython.score-98 {background-color: #FFFF17;}\n",
       ".cython.score-99 {background-color: #FFFF17;}\n",
       ".cython.score-100 {background-color: #FFFF17;}\n",
       ".cython.score-101 {background-color: #FFFF16;}\n",
       ".cython.score-102 {background-color: #FFFF16;}\n",
       ".cython.score-103 {background-color: #FFFF16;}\n",
       ".cython.score-104 {background-color: #FFFF16;}\n",
       ".cython.score-105 {background-color: #FFFF16;}\n",
       ".cython.score-106 {background-color: #FFFF15;}\n",
       ".cython.score-107 {background-color: #FFFF15;}\n",
       ".cython.score-108 {background-color: #FFFF15;}\n",
       ".cython.score-109 {background-color: #FFFF15;}\n",
       ".cython.score-110 {background-color: #FFFF15;}\n",
       ".cython.score-111 {background-color: #FFFF15;}\n",
       ".cython.score-112 {background-color: #FFFF14;}\n",
       ".cython.score-113 {background-color: #FFFF14;}\n",
       ".cython.score-114 {background-color: #FFFF14;}\n",
       ".cython.score-115 {background-color: #FFFF14;}\n",
       ".cython.score-116 {background-color: #FFFF14;}\n",
       ".cython.score-117 {background-color: #FFFF14;}\n",
       ".cython.score-118 {background-color: #FFFF13;}\n",
       ".cython.score-119 {background-color: #FFFF13;}\n",
       ".cython.score-120 {background-color: #FFFF13;}\n",
       ".cython.score-121 {background-color: #FFFF13;}\n",
       ".cython.score-122 {background-color: #FFFF13;}\n",
       ".cython.score-123 {background-color: #FFFF13;}\n",
       ".cython.score-124 {background-color: #FFFF13;}\n",
       ".cython.score-125 {background-color: #FFFF12;}\n",
       ".cython.score-126 {background-color: #FFFF12;}\n",
       ".cython.score-127 {background-color: #FFFF12;}\n",
       ".cython.score-128 {background-color: #FFFF12;}\n",
       ".cython.score-129 {background-color: #FFFF12;}\n",
       ".cython.score-130 {background-color: #FFFF12;}\n",
       ".cython.score-131 {background-color: #FFFF12;}\n",
       ".cython.score-132 {background-color: #FFFF11;}\n",
       ".cython.score-133 {background-color: #FFFF11;}\n",
       ".cython.score-134 {background-color: #FFFF11;}\n",
       ".cython.score-135 {background-color: #FFFF11;}\n",
       ".cython.score-136 {background-color: #FFFF11;}\n",
       ".cython.score-137 {background-color: #FFFF11;}\n",
       ".cython.score-138 {background-color: #FFFF11;}\n",
       ".cython.score-139 {background-color: #FFFF11;}\n",
       ".cython.score-140 {background-color: #FFFF11;}\n",
       ".cython.score-141 {background-color: #FFFF10;}\n",
       ".cython.score-142 {background-color: #FFFF10;}\n",
       ".cython.score-143 {background-color: #FFFF10;}\n",
       ".cython.score-144 {background-color: #FFFF10;}\n",
       ".cython.score-145 {background-color: #FFFF10;}\n",
       ".cython.score-146 {background-color: #FFFF10;}\n",
       ".cython.score-147 {background-color: #FFFF10;}\n",
       ".cython.score-148 {background-color: #FFFF10;}\n",
       ".cython.score-149 {background-color: #FFFF10;}\n",
       ".cython.score-150 {background-color: #FFFF0f;}\n",
       ".cython.score-151 {background-color: #FFFF0f;}\n",
       ".cython.score-152 {background-color: #FFFF0f;}\n",
       ".cython.score-153 {background-color: #FFFF0f;}\n",
       ".cython.score-154 {background-color: #FFFF0f;}\n",
       ".cython.score-155 {background-color: #FFFF0f;}\n",
       ".cython.score-156 {background-color: #FFFF0f;}\n",
       ".cython.score-157 {background-color: #FFFF0f;}\n",
       ".cython.score-158 {background-color: #FFFF0f;}\n",
       ".cython.score-159 {background-color: #FFFF0f;}\n",
       ".cython.score-160 {background-color: #FFFF0f;}\n",
       ".cython.score-161 {background-color: #FFFF0e;}\n",
       ".cython.score-162 {background-color: #FFFF0e;}\n",
       ".cython.score-163 {background-color: #FFFF0e;}\n",
       ".cython.score-164 {background-color: #FFFF0e;}\n",
       ".cython.score-165 {background-color: #FFFF0e;}\n",
       ".cython.score-166 {background-color: #FFFF0e;}\n",
       ".cython.score-167 {background-color: #FFFF0e;}\n",
       ".cython.score-168 {background-color: #FFFF0e;}\n",
       ".cython.score-169 {background-color: #FFFF0e;}\n",
       ".cython.score-170 {background-color: #FFFF0e;}\n",
       ".cython.score-171 {background-color: #FFFF0e;}\n",
       ".cython.score-172 {background-color: #FFFF0e;}\n",
       ".cython.score-173 {background-color: #FFFF0d;}\n",
       ".cython.score-174 {background-color: #FFFF0d;}\n",
       ".cython.score-175 {background-color: #FFFF0d;}\n",
       ".cython.score-176 {background-color: #FFFF0d;}\n",
       ".cython.score-177 {background-color: #FFFF0d;}\n",
       ".cython.score-178 {background-color: #FFFF0d;}\n",
       ".cython.score-179 {background-color: #FFFF0d;}\n",
       ".cython.score-180 {background-color: #FFFF0d;}\n",
       ".cython.score-181 {background-color: #FFFF0d;}\n",
       ".cython.score-182 {background-color: #FFFF0d;}\n",
       ".cython.score-183 {background-color: #FFFF0d;}\n",
       ".cython.score-184 {background-color: #FFFF0d;}\n",
       ".cython.score-185 {background-color: #FFFF0d;}\n",
       ".cython.score-186 {background-color: #FFFF0d;}\n",
       ".cython.score-187 {background-color: #FFFF0c;}\n",
       ".cython.score-188 {background-color: #FFFF0c;}\n",
       ".cython.score-189 {background-color: #FFFF0c;}\n",
       ".cython.score-190 {background-color: #FFFF0c;}\n",
       ".cython.score-191 {background-color: #FFFF0c;}\n",
       ".cython.score-192 {background-color: #FFFF0c;}\n",
       ".cython.score-193 {background-color: #FFFF0c;}\n",
       ".cython.score-194 {background-color: #FFFF0c;}\n",
       ".cython.score-195 {background-color: #FFFF0c;}\n",
       ".cython.score-196 {background-color: #FFFF0c;}\n",
       ".cython.score-197 {background-color: #FFFF0c;}\n",
       ".cython.score-198 {background-color: #FFFF0c;}\n",
       ".cython.score-199 {background-color: #FFFF0c;}\n",
       ".cython.score-200 {background-color: #FFFF0c;}\n",
       ".cython.score-201 {background-color: #FFFF0c;}\n",
       ".cython.score-202 {background-color: #FFFF0c;}\n",
       ".cython.score-203 {background-color: #FFFF0b;}\n",
       ".cython.score-204 {background-color: #FFFF0b;}\n",
       ".cython.score-205 {background-color: #FFFF0b;}\n",
       ".cython.score-206 {background-color: #FFFF0b;}\n",
       ".cython.score-207 {background-color: #FFFF0b;}\n",
       ".cython.score-208 {background-color: #FFFF0b;}\n",
       ".cython.score-209 {background-color: #FFFF0b;}\n",
       ".cython.score-210 {background-color: #FFFF0b;}\n",
       ".cython.score-211 {background-color: #FFFF0b;}\n",
       ".cython.score-212 {background-color: #FFFF0b;}\n",
       ".cython.score-213 {background-color: #FFFF0b;}\n",
       ".cython.score-214 {background-color: #FFFF0b;}\n",
       ".cython.score-215 {background-color: #FFFF0b;}\n",
       ".cython.score-216 {background-color: #FFFF0b;}\n",
       ".cython.score-217 {background-color: #FFFF0b;}\n",
       ".cython.score-218 {background-color: #FFFF0b;}\n",
       ".cython.score-219 {background-color: #FFFF0b;}\n",
       ".cython.score-220 {background-color: #FFFF0b;}\n",
       ".cython.score-221 {background-color: #FFFF0b;}\n",
       ".cython.score-222 {background-color: #FFFF0a;}\n",
       ".cython.score-223 {background-color: #FFFF0a;}\n",
       ".cython.score-224 {background-color: #FFFF0a;}\n",
       ".cython.score-225 {background-color: #FFFF0a;}\n",
       ".cython.score-226 {background-color: #FFFF0a;}\n",
       ".cython.score-227 {background-color: #FFFF0a;}\n",
       ".cython.score-228 {background-color: #FFFF0a;}\n",
       ".cython.score-229 {background-color: #FFFF0a;}\n",
       ".cython.score-230 {background-color: #FFFF0a;}\n",
       ".cython.score-231 {background-color: #FFFF0a;}\n",
       ".cython.score-232 {background-color: #FFFF0a;}\n",
       ".cython.score-233 {background-color: #FFFF0a;}\n",
       ".cython.score-234 {background-color: #FFFF0a;}\n",
       ".cython.score-235 {background-color: #FFFF0a;}\n",
       ".cython.score-236 {background-color: #FFFF0a;}\n",
       ".cython.score-237 {background-color: #FFFF0a;}\n",
       ".cython.score-238 {background-color: #FFFF0a;}\n",
       ".cython.score-239 {background-color: #FFFF0a;}\n",
       ".cython.score-240 {background-color: #FFFF0a;}\n",
       ".cython.score-241 {background-color: #FFFF0a;}\n",
       ".cython.score-242 {background-color: #FFFF0a;}\n",
       ".cython.score-243 {background-color: #FFFF0a;}\n",
       ".cython.score-244 {background-color: #FFFF0a;}\n",
       ".cython.score-245 {background-color: #FFFF0a;}\n",
       ".cython.score-246 {background-color: #FFFF09;}\n",
       ".cython.score-247 {background-color: #FFFF09;}\n",
       ".cython.score-248 {background-color: #FFFF09;}\n",
       ".cython.score-249 {background-color: #FFFF09;}\n",
       ".cython.score-250 {background-color: #FFFF09;}\n",
       ".cython.score-251 {background-color: #FFFF09;}\n",
       ".cython.score-252 {background-color: #FFFF09;}\n",
       ".cython.score-253 {background-color: #FFFF09;}\n",
       ".cython.score-254 {background-color: #FFFF09;}\n",
       "pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".cython .hll { background-color: #ffffcc }\n",
       ".cython { background: #f8f8f8; }\n",
       ".cython .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".cython .err { border: 1px solid #FF0000 } /* Error */\n",
       ".cython .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".cython .o { color: #666666 } /* Operator */\n",
       ".cython .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".cython .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".cython .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".cython .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".cython .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".cython .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".cython .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".cython .ge { font-style: italic } /* Generic.Emph */\n",
       ".cython .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".cython .gr { color: #E40000 } /* Generic.Error */\n",
       ".cython .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".cython .gi { color: #008400 } /* Generic.Inserted */\n",
       ".cython .go { color: #717171 } /* Generic.Output */\n",
       ".cython .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".cython .gs { font-weight: bold } /* Generic.Strong */\n",
       ".cython .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".cython .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".cython .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".cython .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".cython .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".cython .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".cython .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".cython .kt { color: #B00040 } /* Keyword.Type */\n",
       ".cython .m { color: #666666 } /* Literal.Number */\n",
       ".cython .s { color: #BA2121 } /* Literal.String */\n",
       ".cython .na { color: #687822 } /* Name.Attribute */\n",
       ".cython .nb { color: #008000 } /* Name.Builtin */\n",
       ".cython .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".cython .no { color: #880000 } /* Name.Constant */\n",
       ".cython .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".cython .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".cython .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".cython .nf { color: #0000FF } /* Name.Function */\n",
       ".cython .nl { color: #767600 } /* Name.Label */\n",
       ".cython .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".cython .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".cython .nv { color: #19177C } /* Name.Variable */\n",
       ".cython .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".cython .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".cython .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".cython .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".cython .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".cython .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".cython .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".cython .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".cython .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".cython .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".cython .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".cython .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".cython .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".cython .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".cython .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".cython .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".cython .sx { color: #008000 } /* Literal.String.Other */\n",
       ".cython .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".cython .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".cython .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".cython .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".cython .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".cython .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".cython .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".cython .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".cython .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".cython .il { color: #666666 } /* Literal.Number.Integer.Long */\n",
       "    </style>\n",
       "</head>\n",
       "<body class=\"cython\">\n",
       "<p><span style=\"border-bottom: solid 1px grey;\">Generated by Cython 3.0.8</span></p>\n",
       "<p>\n",
       "    <span style=\"background-color: #FFFF00\">Yellow lines</span> hint at Python interaction.<br />\n",
       "    Click on a line that starts with a \"<code>+</code>\" to see the C code that Cython generated for it.\n",
       "</p>\n",
       "<div class=\"cython\"><pre class=\"cython line score-0\">&#xA0;<span class=\"\">01</span>: </pre>\n",
       "<pre class=\"cython line score-28\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">02</span>: <span class=\"k\">from</span> <span class=\"nn\">sklearn</span> <span class=\"k\">import</span> <span class=\"n\">metrics</span></pre>\n",
       "<pre class='cython code score-28 '>  __pyx_t_2 = <span class='py_c_api'>PyList_New</span>(1);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_n_s_metrics);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_n_s_metrics);\n",
       "  if (<span class='pyx_c_api'>__Pyx_PyList_SET_ITEM</span>(__pyx_t_2, 0, __pyx_n_s_metrics)) <span class='error_goto'>__PYX_ERR(0, 2, __pyx_L1_error)</span>;\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_Import</span>(__pyx_n_s_sklearn, __pyx_t_2, 0);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_ImportFrom</span>(__pyx_t_3, __pyx_n_s_metrics);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_metrics, __pyx_t_2) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "/*  */\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyDict_NewPresized</span>(0);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_test, __pyx_t_2) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 2, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "</pre><pre class=\"cython line score-8\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">03</span>: <span class=\"k\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span></pre>\n",
       "<pre class='cython code score-8 '>  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_ImportDottedModule</span>(__pyx_n_s_numpy, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 3, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_np, __pyx_t_3) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 3, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "</pre><pre class=\"cython line score-20\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">04</span>: <span class=\"k\">from</span> <span class=\"nn\">numpy.linalg</span> <span class=\"k\">import</span> <span class=\"n\">norm</span></pre>\n",
       "<pre class='cython code score-20 '>  __pyx_t_3 = <span class='py_c_api'>PyList_New</span>(1);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 4, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_n_s_norm);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_n_s_norm);\n",
       "  if (<span class='pyx_c_api'>__Pyx_PyList_SET_ITEM</span>(__pyx_t_3, 0, __pyx_n_s_norm)) <span class='error_goto'>__PYX_ERR(0, 4, __pyx_L1_error)</span>;\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_Import</span>(__pyx_n_s_numpy_linalg, __pyx_t_3, 0);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 4, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_ImportFrom</span>(__pyx_t_2, __pyx_n_s_norm);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 4, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_norm, __pyx_t_3) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 4, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">05</span>: </pre>\n",
       "<pre class=\"cython line score-19\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">06</span>: <span class=\"n\">round_v</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">vectorize</span><span class=\"p\">(</span><span class=\"nb\">round</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-19 '>  <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_t_2, __pyx_n_s_np);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 6, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_t_2, __pyx_n_s_vectorize);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 6, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_t_3, __pyx_tuple__5, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 6, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_round_v, __pyx_t_2) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 6, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "/*  */\n",
       "  __pyx_tuple__5 = <span class='py_c_api'>PyTuple_Pack</span>(1, __pyx_builtin_round);<span class='error_goto'> if (unlikely(!__pyx_tuple__5)) __PYX_ERR(0, 6, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__5);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__5);\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">07</span>: </pre>\n",
       "<pre class=\"cython line score-54\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">08</span>: <span class=\"k\">def</span> <span class=\"nf\">normalize</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-54 '>/* Python wrapper */\n",
       "static PyObject *__pyx_pw_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_1normalize(PyObject *__pyx_self, \n",
       "#if CYTHON_METH_FASTCALL\n",
       "PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds\n",
       "#else\n",
       "PyObject *__pyx_args, PyObject *__pyx_kwds\n",
       "#endif\n",
       "); /*proto*/\n",
       "static PyMethodDef __pyx_mdef_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_1normalize = {\"normalize\", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_1normalize, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0};\n",
       "static PyObject *__pyx_pw_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_1normalize(PyObject *__pyx_self, \n",
       "#if CYTHON_METH_FASTCALL\n",
       "PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds\n",
       "#else\n",
       "PyObject *__pyx_args, PyObject *__pyx_kwds\n",
       "#endif\n",
       ") {\n",
       "  PyObject *__pyx_v_weights = 0;\n",
       "  #if !CYTHON_METH_FASTCALL\n",
       "  CYTHON_UNUSED Py_ssize_t __pyx_nargs;\n",
       "  #endif\n",
       "  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;\n",
       "  PyObject *__pyx_r = 0;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"normalize (wrapper)\", 0);\n",
       "  #if !CYTHON_METH_FASTCALL\n",
       "  #if CYTHON_ASSUME_SAFE_MACROS\n",
       "  __pyx_nargs = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args);\n",
       "  #else\n",
       "  __pyx_nargs = <span class='py_c_api'>PyTuple_Size</span>(__pyx_args); if (unlikely(__pyx_nargs &lt; 0)) return NULL;\n",
       "  #endif\n",
       "  #endif\n",
       "  __pyx_kwvalues = <span class='pyx_c_api'>__Pyx_KwValues_FASTCALL</span>(__pyx_args, __pyx_nargs);\n",
       "  {\n",
       "    PyObject **__pyx_pyargnames[] = {&amp;__pyx_n_s_weights,0};\n",
       "  PyObject* values[1] = {0};\n",
       "    if (__pyx_kwds) {\n",
       "      Py_ssize_t kw_args;\n",
       "      switch (__pyx_nargs) {\n",
       "        case  1: values[0] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 0);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  0: break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      kw_args = <span class='pyx_c_api'>__Pyx_NumKwargs_FASTCALL</span>(__pyx_kwds);\n",
       "      switch (__pyx_nargs) {\n",
       "        case  0:\n",
       "        if (likely((values[0] = <span class='pyx_c_api'>__Pyx_GetKwValue_FASTCALL</span>(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_weights)) != 0)) {\n",
       "          (void)<span class='pyx_c_api'>__Pyx_Arg_NewRef_FASTCALL</span>(values[0]);\n",
       "          kw_args--;\n",
       "        }\n",
       "        else if (unlikely(<span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "        else goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      if (unlikely(kw_args &gt; 0)) {\n",
       "        const Py_ssize_t kwd_pos_args = __pyx_nargs;\n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_ParseOptionalKeywords</span>(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, \"normalize\") &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "      }\n",
       "    } else if (unlikely(__pyx_nargs != 1)) {\n",
       "      goto __pyx_L5_argtuple_error;\n",
       "    } else {\n",
       "      values[0] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 0);\n",
       "    }\n",
       "    __pyx_v_weights = values[0];\n",
       "  }\n",
       "  goto __pyx_L6_skip;\n",
       "  __pyx_L5_argtuple_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"normalize\", 1, 1, 1, __pyx_nargs); <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L3_error)</span>\n",
       "  __pyx_L6_skip:;\n",
       "  goto __pyx_L4_argument_unpacking_done;\n",
       "  __pyx_L3_error:;\n",
       "  {\n",
       "    Py_ssize_t __pyx_temp;\n",
       "    for (__pyx_temp=0; __pyx_temp &lt; (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {\n",
       "      <span class='pyx_c_api'>__Pyx_Arg_XDECREF_FASTCALL</span>(values[__pyx_temp]);\n",
       "    }\n",
       "  }\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61.normalize\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return NULL;\n",
       "  __pyx_L4_argument_unpacking_done:;\n",
       "  __pyx_r = __pyx_pf_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_normalize(__pyx_self, __pyx_v_weights);\n",
       "  int __pyx_lineno = 0;\n",
       "  const char *__pyx_filename = NULL;\n",
       "  int __pyx_clineno = 0;\n",
       "\n",
       "  /* function exit code */\n",
       "  {\n",
       "    Py_ssize_t __pyx_temp;\n",
       "    for (__pyx_temp=0; __pyx_temp &lt; (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {\n",
       "      <span class='pyx_c_api'>__Pyx_Arg_XDECREF_FASTCALL</span>(values[__pyx_temp]);\n",
       "    }\n",
       "  }\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_normalize(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_weights) {\n",
       "  PyObject *__pyx_v_result = NULL;\n",
       "  PyObject *__pyx_r = NULL;\n",
       "/*  */\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61.normalize\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_result);\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "/*  */\n",
       "  __pyx_tuple__6 = <span class='py_c_api'>PyTuple_Pack</span>(2, __pyx_n_s_weights, __pyx_n_s_result);<span class='error_goto'> if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__6);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__6);\n",
       "/*  */\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_CyFunction_New</span>(&amp;__pyx_mdef_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_1normalize, 0, __pyx_n_s_normalize, NULL, __pyx_n_s_cython_magic_697e9e395b79369c27, __pyx_d, ((PyObject *)__pyx_codeobj__7));<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_normalize, __pyx_t_2) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  __pyx_codeobj__7 = (PyObject*)<span class='pyx_c_api'>__Pyx_PyCode_New</span>(1, 0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__6, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_C_Users_admin1_ipython_cython__c, __pyx_n_s_normalize, 8, __pyx_empty_bytes);<span class='error_goto'> if (unlikely(!__pyx_codeobj__7)) __PYX_ERR(0, 8, __pyx_L1_error)</span>\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">09</span>:     <span class=\"c\"># calculate l1 vector norm</span></pre>\n",
       "<pre class=\"cython line score-16\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">10</span>:     <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">norm</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">,</span> <span class=\"mf\">1</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-16 '>  <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_t_2, __pyx_n_s_norm);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 10, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = NULL;\n",
       "  __pyx_t_4 = 0;\n",
       "  #if CYTHON_UNPACK_METHODS\n",
       "  if (unlikely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_2))) {\n",
       "    __pyx_t_3 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_2);\n",
       "    if (likely(__pyx_t_3)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_2);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_3);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_2, function);\n",
       "      __pyx_t_4 = 1;\n",
       "    }\n",
       "  }\n",
       "  #endif\n",
       "  {\n",
       "    PyObject *__pyx_callargs[3] = {__pyx_t_3, __pyx_v_weights, __pyx_int_1};\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_FastCall</span>(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 2+__pyx_t_4);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "    if (unlikely(!__pyx_t_1)) <span class='error_goto'>__PYX_ERR(0, 10, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  }\n",
       "  __pyx_v_result = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">11</span>:     <span class=\"c\"># check for a vector of all zeros</span></pre>\n",
       "<pre class=\"cython line score-2\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">12</span>:     <span class=\"k\">if</span> <span class=\"n\">result</span> <span class=\"o\">==</span> <span class=\"mf\">0.0</span><span class=\"p\">:</span></pre>\n",
       "<pre class='cython code score-2 '>  __pyx_t_5 = (<span class='pyx_c_api'>__Pyx_PyFloat_BoolEqObjC</span>(__pyx_v_result, __pyx_float_0_0, 0.0, 0, 0)); if (unlikely((__pyx_t_5 &lt; 0))) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  if (__pyx_t_5) {\n",
       "/*  */\n",
       "  }\n",
       "</pre><pre class=\"cython line score-2\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">13</span>:         <span class=\"k\">return</span> <span class=\"n\">weights</span></pre>\n",
       "<pre class='cython code score-2 '>    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "    <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_v_weights);\n",
       "    __pyx_r = __pyx_v_weights;\n",
       "    goto __pyx_L0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">14</span>:     <span class=\"c\"># return normalized vector (unit norm)</span></pre>\n",
       "<pre class=\"cython line score-3\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">15</span>:     <span class=\"k\">return</span> <span class=\"n\">weights</span> <span class=\"o\">/</span> <span class=\"n\">result</span></pre>\n",
       "<pre class='cython code score-3 '>  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "  __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyNumber_Divide</span>(__pyx_v_weights, __pyx_v_result);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 15, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  __pyx_r = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "  goto __pyx_L0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">16</span>: </pre>\n",
       "<pre class=\"cython line score-90\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">17</span>: <span class=\"k\">def</span> <span class=\"nf\">get_weighted_ensemble_prediction_de_cython</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">,</span> <span class=\"n\">prediction_matrix_raw</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-90 '>/* Python wrapper */\n",
       "static PyObject *__pyx_pw_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_3get_weighted_ensemble_prediction_de_cython(PyObject *__pyx_self, \n",
       "#if CYTHON_METH_FASTCALL\n",
       "PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds\n",
       "#else\n",
       "PyObject *__pyx_args, PyObject *__pyx_kwds\n",
       "#endif\n",
       "); /*proto*/\n",
       "<span class='py_macro_api'>PyDoc_STRVAR</span>(__pyx_doc_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_2get_weighted_ensemble_prediction_de_cython, \"Function used by DE algo to search for optimal weights with scoring\");\n",
       "static PyMethodDef __pyx_mdef_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_3get_weighted_ensemble_prediction_de_cython = {\"get_weighted_ensemble_prediction_de_cython\", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_3get_weighted_ensemble_prediction_de_cython, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_2get_weighted_ensemble_prediction_de_cython};\n",
       "static PyObject *__pyx_pw_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_3get_weighted_ensemble_prediction_de_cython(PyObject *__pyx_self, \n",
       "#if CYTHON_METH_FASTCALL\n",
       "PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds\n",
       "#else\n",
       "PyObject *__pyx_args, PyObject *__pyx_kwds\n",
       "#endif\n",
       ") {\n",
       "  PyObject *__pyx_v_weights = 0;\n",
       "  PyObject *__pyx_v_prediction_matrix_raw = 0;\n",
       "  PyObject *__pyx_v_y_test = 0;\n",
       "  #if !CYTHON_METH_FASTCALL\n",
       "  CYTHON_UNUSED Py_ssize_t __pyx_nargs;\n",
       "  #endif\n",
       "  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;\n",
       "  PyObject *__pyx_r = 0;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"get_weighted_ensemble_prediction_de_cython (wrapper)\", 0);\n",
       "  #if !CYTHON_METH_FASTCALL\n",
       "  #if CYTHON_ASSUME_SAFE_MACROS\n",
       "  __pyx_nargs = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args);\n",
       "  #else\n",
       "  __pyx_nargs = <span class='py_c_api'>PyTuple_Size</span>(__pyx_args); if (unlikely(__pyx_nargs &lt; 0)) return NULL;\n",
       "  #endif\n",
       "  #endif\n",
       "  __pyx_kwvalues = <span class='pyx_c_api'>__Pyx_KwValues_FASTCALL</span>(__pyx_args, __pyx_nargs);\n",
       "  {\n",
       "    PyObject **__pyx_pyargnames[] = {&amp;__pyx_n_s_weights,&amp;__pyx_n_s_prediction_matrix_raw,&amp;__pyx_n_s_y_test,0};\n",
       "  PyObject* values[3] = {0,0,0};\n",
       "    if (__pyx_kwds) {\n",
       "      Py_ssize_t kw_args;\n",
       "      switch (__pyx_nargs) {\n",
       "        case  3: values[2] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 2);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2: values[1] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 0);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  0: break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      kw_args = <span class='pyx_c_api'>__Pyx_NumKwargs_FASTCALL</span>(__pyx_kwds);\n",
       "      switch (__pyx_nargs) {\n",
       "        case  0:\n",
       "        if (likely((values[0] = <span class='pyx_c_api'>__Pyx_GetKwValue_FASTCALL</span>(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_weights)) != 0)) {\n",
       "          (void)<span class='pyx_c_api'>__Pyx_Arg_NewRef_FASTCALL</span>(values[0]);\n",
       "          kw_args--;\n",
       "        }\n",
       "        else if (unlikely(<span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L3_error)</span>\n",
       "        else goto __pyx_L5_argtuple_error;\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1:\n",
       "        if (likely((values[1] = <span class='pyx_c_api'>__Pyx_GetKwValue_FASTCALL</span>(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_prediction_matrix_raw)) != 0)) {\n",
       "          (void)<span class='pyx_c_api'>__Pyx_Arg_NewRef_FASTCALL</span>(values[1]);\n",
       "          kw_args--;\n",
       "        }\n",
       "        else if (unlikely(<span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L3_error)</span>\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"get_weighted_ensemble_prediction_de_cython\", 1, 3, 3, 1); <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L3_error)</span>\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2:\n",
       "        if (likely((values[2] = <span class='pyx_c_api'>__Pyx_GetKwValue_FASTCALL</span>(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_y_test)) != 0)) {\n",
       "          (void)<span class='pyx_c_api'>__Pyx_Arg_NewRef_FASTCALL</span>(values[2]);\n",
       "          kw_args--;\n",
       "        }\n",
       "        else if (unlikely(<span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L3_error)</span>\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"get_weighted_ensemble_prediction_de_cython\", 1, 3, 3, 2); <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L3_error)</span>\n",
       "        }\n",
       "      }\n",
       "      if (unlikely(kw_args &gt; 0)) {\n",
       "        const Py_ssize_t kwd_pos_args = __pyx_nargs;\n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_ParseOptionalKeywords</span>(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, \"get_weighted_ensemble_prediction_de_cython\") &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L3_error)</span>\n",
       "      }\n",
       "    } else if (unlikely(__pyx_nargs != 3)) {\n",
       "      goto __pyx_L5_argtuple_error;\n",
       "    } else {\n",
       "      values[0] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 0);\n",
       "      values[1] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 1);\n",
       "      values[2] = <span class='pyx_c_api'>__Pyx_Arg_FASTCALL</span>(__pyx_args, 2);\n",
       "    }\n",
       "    __pyx_v_weights = values[0];\n",
       "    __pyx_v_prediction_matrix_raw = values[1];\n",
       "    __pyx_v_y_test = values[2];\n",
       "  }\n",
       "  goto __pyx_L6_skip;\n",
       "  __pyx_L5_argtuple_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"get_weighted_ensemble_prediction_de_cython\", 1, 3, 3, __pyx_nargs); <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L3_error)</span>\n",
       "  __pyx_L6_skip:;\n",
       "  goto __pyx_L4_argument_unpacking_done;\n",
       "  __pyx_L3_error:;\n",
       "  {\n",
       "    Py_ssize_t __pyx_temp;\n",
       "    for (__pyx_temp=0; __pyx_temp &lt; (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {\n",
       "      <span class='pyx_c_api'>__Pyx_Arg_XDECREF_FASTCALL</span>(values[__pyx_temp]);\n",
       "    }\n",
       "  }\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61.get_weighted_ensemble_prediction_de_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return NULL;\n",
       "  __pyx_L4_argument_unpacking_done:;\n",
       "  __pyx_r = __pyx_pf_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_2get_weighted_ensemble_prediction_de_cython(__pyx_self, __pyx_v_weights, __pyx_v_prediction_matrix_raw, __pyx_v_y_test);\n",
       "  int __pyx_lineno = 0;\n",
       "  const char *__pyx_filename = NULL;\n",
       "  int __pyx_clineno = 0;\n",
       "\n",
       "  /* function exit code */\n",
       "  {\n",
       "    Py_ssize_t __pyx_temp;\n",
       "    for (__pyx_temp=0; __pyx_temp &lt; (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {\n",
       "      <span class='pyx_c_api'>__Pyx_Arg_XDECREF_FASTCALL</span>(values[__pyx_temp]);\n",
       "    }\n",
       "  }\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_2get_weighted_ensemble_prediction_de_cython(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_weights, PyObject *__pyx_v_prediction_matrix_raw, PyObject *__pyx_v_y_test) {\n",
       "  PyObject *__pyx_v_clean_prediction_matrix = NULL;\n",
       "  PyObject *__pyx_v_weighted_prediction_matrix_array = NULL;\n",
       "  PyObject *__pyx_v_collapsed_weighted_prediction_matrix_array = NULL;\n",
       "  PyObject *__pyx_v_y_pred_best = NULL;\n",
       "  PyObject *__pyx_v_auc = NULL;\n",
       "  PyObject *__pyx_v_score = NULL;\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_v_weights);\n",
       "/*  */\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61.get_weighted_ensemble_prediction_de_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_clean_prediction_matrix);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_weighted_prediction_matrix_array);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_collapsed_weighted_prediction_matrix_array);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_y_pred_best);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_auc);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_score);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_weights);\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "/*  */\n",
       "  __pyx_tuple__8 = <span class='py_c_api'>PyTuple_Pack</span>(9, __pyx_n_s_weights, __pyx_n_s_prediction_matrix_raw, __pyx_n_s_y_test, __pyx_n_s_clean_prediction_matrix, __pyx_n_s_weighted_prediction_matrix_array, __pyx_n_s_collapsed_weighted_prediction_ma, __pyx_n_s_y_pred_best, __pyx_n_s_auc, __pyx_n_s_score);<span class='error_goto'> if (unlikely(!__pyx_tuple__8)) __PYX_ERR(0, 17, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__8);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__8);\n",
       "/*  */\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_CyFunction_New</span>(&amp;__pyx_mdef_54_cython_magic_697e9e395b79369c272f62f219c1d1ec2137ea61_3get_weighted_ensemble_prediction_de_cython, 0, __pyx_n_s_get_weighted_ensemble_prediction, NULL, __pyx_n_s_cython_magic_697e9e395b79369c27, __pyx_d, ((PyObject *)__pyx_codeobj__9));<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 17, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_get_weighted_ensemble_prediction, __pyx_t_2) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 17, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">18</span>: <span class=\"w\">    </span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">19</span>: <span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;Function used by DE algo to search for optimal weights with scoring&quot;&quot;&quot;</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">20</span>: </pre>\n",
       "<pre class=\"cython line score-16\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">21</span>:         <span class=\"n\">clean_prediction_matrix</span> <span class=\"o\">=</span> <span class=\"n\">prediction_matrix_raw</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span></pre>\n",
       "<pre class='cython code score-16 '>  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_prediction_matrix_raw, __pyx_n_s_copy);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 21, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = NULL;\n",
       "  __pyx_t_4 = 0;\n",
       "  #if CYTHON_UNPACK_METHODS\n",
       "  if (likely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_2))) {\n",
       "    __pyx_t_3 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_2);\n",
       "    if (likely(__pyx_t_3)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_2);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_3);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_2, function);\n",
       "      __pyx_t_4 = 1;\n",
       "    }\n",
       "  }\n",
       "  #endif\n",
       "  {\n",
       "    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_FastCall</span>(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 0+__pyx_t_4);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "    if (unlikely(!__pyx_t_1)) <span class='error_goto'>__PYX_ERR(0, 21, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  }\n",
       "  __pyx_v_clean_prediction_matrix = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-17\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">22</span>:         <span class=\"n\">weights</span> <span class=\"o\">=</span> <span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-17 '>  <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_t_2, __pyx_n_s_normalize);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 22, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = NULL;\n",
       "  __pyx_t_4 = 0;\n",
       "  #if CYTHON_UNPACK_METHODS\n",
       "  if (unlikely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_2))) {\n",
       "    __pyx_t_3 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_2);\n",
       "    if (likely(__pyx_t_3)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_2);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_3);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_2, function);\n",
       "      __pyx_t_4 = 1;\n",
       "    }\n",
       "  }\n",
       "  #endif\n",
       "  {\n",
       "    PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_v_weights};\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_FastCall</span>(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "    if (unlikely(!__pyx_t_1)) <span class='error_goto'>__PYX_ERR(0, 22, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  }\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_v_weights, __pyx_t_1);\n",
       "  __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">23</span>: </pre>\n",
       "<pre class=\"cython line score-38\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">24</span>:         <span class=\"n\">weighted_prediction_matrix_array</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">clean_prediction_matrix</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">weights</span><span class=\"p\">[:,</span> <span class=\"bp\">None</span><span class=\"p\">])</span></pre>\n",
       "<pre class='cython code score-38 '>  <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_t_2, __pyx_n_s_np);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 24, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_t_2, __pyx_n_s_array);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 24, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = NULL;\n",
       "  __pyx_t_4 = 0;\n",
       "  #if CYTHON_UNPACK_METHODS\n",
       "  if (unlikely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_3))) {\n",
       "    __pyx_t_2 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_3);\n",
       "    if (likely(__pyx_t_2)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_3);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_2);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_3, function);\n",
       "      __pyx_t_4 = 1;\n",
       "    }\n",
       "  }\n",
       "  #endif\n",
       "  {\n",
       "    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_clean_prediction_matrix};\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_FastCall</span>(__pyx_t_3, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "    if (unlikely(!__pyx_t_1)) <span class='error_goto'>__PYX_ERR(0, 24, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  }\n",
       "/*  */\n",
       "  __pyx_slice_ = <span class='py_c_api'>PySlice_New</span>(Py_None, Py_None, Py_None);<span class='error_goto'> if (unlikely(!__pyx_slice_)) __PYX_ERR(0, 24, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_slice_);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_slice_);\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_PyObject_GetItem</span>(__pyx_v_weights, __pyx_tuple__2);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 24, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyNumber_Multiply</span>(__pyx_t_1, __pyx_t_3);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 24, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  __pyx_v_weighted_prediction_matrix_array = __pyx_t_2;\n",
       "  __pyx_t_2 = 0;\n",
       "  __pyx_tuple__2 = <span class='py_c_api'>PyTuple_Pack</span>(2, __pyx_slice_, Py_None);<span class='error_goto'> if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 24, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__2);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__2);\n",
       "</pre><pre class=\"cython line score-13\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">25</span>:         <span class=\"n\">collapsed_weighted_prediction_matrix_array</span> <span class=\"o\">=</span> <span class=\"n\">weighted_prediction_matrix_array</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mf\">0</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-13 '>  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_weighted_prediction_matrix_array, __pyx_n_s_sum);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 25, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_PyDict_NewPresized</span>(1);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 25, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_t_3, __pyx_n_s_axis, __pyx_int_0) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 25, __pyx_L1_error)</span>\n",
       "  __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_t_2, __pyx_empty_tuple, __pyx_t_3);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 25, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  __pyx_v_collapsed_weighted_prediction_matrix_array = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">26</span>: </pre>\n",
       "<pre class=\"cython line score-16\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">27</span>:         <span class=\"n\">y_pred_best</span> <span class=\"o\">=</span> <span class=\"n\">round_v</span><span class=\"p\">(</span><span class=\"n\">collapsed_weighted_prediction_matrix_array</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-16 '>  <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_t_3, __pyx_n_s_round_v);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 27, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  __pyx_t_2 = NULL;\n",
       "  __pyx_t_4 = 0;\n",
       "  #if CYTHON_UNPACK_METHODS\n",
       "  if (unlikely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_3))) {\n",
       "    __pyx_t_2 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_3);\n",
       "    if (likely(__pyx_t_2)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_3);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_2);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_3, function);\n",
       "      __pyx_t_4 = 1;\n",
       "    }\n",
       "  }\n",
       "  #endif\n",
       "  {\n",
       "    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_collapsed_weighted_prediction_matrix_array};\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_FastCall</span>(__pyx_t_3, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "    if (unlikely(!__pyx_t_1)) <span class='error_goto'>__PYX_ERR(0, 27, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  }\n",
       "  __pyx_v_y_pred_best = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">28</span>: </pre>\n",
       "<pre class=\"cython line score-19\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">29</span>:         <span class=\"n\">auc</span> <span class=\"o\">=</span> <span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">roc_auc_score</span><span class=\"p\">(</span><span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">y_pred_best</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-19 '>  <span class='pyx_c_api'>__Pyx_GetModuleGlobalName</span>(__pyx_t_3, __pyx_n_s_metrics);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 29, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_t_3, __pyx_n_s_roc_auc_score);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 29, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  __pyx_t_3 = NULL;\n",
       "  __pyx_t_4 = 0;\n",
       "  #if CYTHON_UNPACK_METHODS\n",
       "  if (unlikely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_2))) {\n",
       "    __pyx_t_3 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_2);\n",
       "    if (likely(__pyx_t_3)) {\n",
       "      PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_2);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_3);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "      <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_2, function);\n",
       "      __pyx_t_4 = 1;\n",
       "    }\n",
       "  }\n",
       "  #endif\n",
       "  {\n",
       "    PyObject *__pyx_callargs[3] = {__pyx_t_3, __pyx_v_y_test, __pyx_v_y_pred_best};\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyObject_FastCall</span>(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 2+__pyx_t_4);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "    if (unlikely(!__pyx_t_1)) <span class='error_goto'>__PYX_ERR(0, 29, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "  }\n",
       "  __pyx_v_auc = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "</pre><pre class=\"cython line score-1\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">30</span>:         <span class=\"n\">score</span> <span class=\"o\">=</span> <span class=\"n\">auc</span></pre>\n",
       "<pre class='cython code score-1 '>  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_v_auc);\n",
       "  __pyx_v_score = __pyx_v_auc;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">31</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">32</span>:         <span class=\"c\">#mcc = metrics.matthews_corrcoef(y_test, y_pred_best)</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">33</span>: </pre>\n",
       "<pre class=\"cython line score-3\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">34</span>:         <span class=\"k\">return</span> <span class=\"mf\">1</span><span class=\"o\">-</span><span class=\"n\">score</span></pre>\n",
       "<pre class='cython code score-3 '>  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "  __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyInt_SubtractCObj</span>(__pyx_int_1, __pyx_v_score, 1, 0, 0);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 34, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  __pyx_r = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "  goto __pyx_L0;\n",
       "</pre></div></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cython -a\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "round_v = np.vectorize(round) \n",
    "\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n",
    "\n",
    "def get_weighted_ensemble_prediction_de_cython(weights, prediction_matrix_raw, y_test):\n",
    "    \n",
    "        \"\"\"Function used by DE algo to search for optimal weights with scoring\"\"\"\n",
    "\n",
    "        clean_prediction_matrix = prediction_matrix_raw.copy()\n",
    "        weights = normalize(weights)\n",
    "\n",
    "        weighted_prediction_matrix_array = (np.array(clean_prediction_matrix) * weights[:, None])\n",
    "        collapsed_weighted_prediction_matrix_array = weighted_prediction_matrix_array.sum(axis=0)\n",
    "\n",
    "        y_pred_best = round_v(collapsed_weighted_prediction_matrix_array)\n",
    "        \n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_best) \n",
    "        score = auc\n",
    "        \n",
    "        #mcc = metrics.matthews_corrcoef(y_test, y_pred_best)\n",
    "\n",
    "        return 1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "864b3b41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_auc(y_pred_best, algorithm_params):\n",
    "    plt.ion()\n",
    "    false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(\n",
    "        y_test_orig, y_pred_best\n",
    "    ) #does this need to be recomputed to fit ypred best size or predbest passed for final\n",
    "    auc = metrics.roc_auc_score(y_test_orig, y_pred_best)\n",
    "    plt.subplots(1, figsize=(10, 10))\n",
    "    plt.title(\"Receiver Operating Characteristic - ensemble \\n\" + algorithm_params)\n",
    "    plt.plot(\n",
    "        false_positive_rate1, true_positive_rate1, label=\"AUC=\" +\n",
    "        str(round(auc, 2))\n",
    "    )\n",
    "    plt.legend(loc=4)\n",
    "    plt.plot([0, 1], ls=\"--\")\n",
    "    plt.plot([0, 0], [1, 0], c=\".7\"), plt.plot([1, 1], c=\".7\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.savefig(\n",
    "        file_path\n",
    "        + \"figures/\"\n",
    "        + algorithm_params\n",
    "        + \"_AUC_:\"\n",
    "        + str(round(auc, 2))\n",
    "        + \"_.png\",\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.show(block=True)\n",
    "    plt.close(\"all\")\n",
    "    cf_matrix = confusion_matrix(y_test_orig, y_pred_best)\n",
    "    group_names = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"]\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\n",
    "        \"{0:.2%}\".format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)\n",
    "    ]\n",
    "    labels = [\n",
    "        f\"{v1}\\n{v2}\\n{v3}\"\n",
    "        for v1, v2, v3 in zip(group_names, group_counts, group_percentages)\n",
    "    ]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap=\"Blues\")\n",
    "    # fig = _.get_figure()\n",
    "    plt.savefig(\n",
    "        file_path\n",
    "        + \"figures/\"\n",
    "        + algorithm_params\n",
    "        + \"_AUC_:\"\n",
    "        + str(round(auc, 2))\n",
    "        + \"CM_.png\",\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2d53823",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#question: should fitness min...be fitness max? to maximise mcc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80c041c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fitnessMin, individual\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Creating fitnessMin, individual\")\n",
    "# creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "# creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cf1771a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33732edb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"evaluate\", evaluate_weighted_ensemble_auc) #evaluate #warning set evaluate below also\n",
    "# pool = multiprocessing.Pool()\n",
    "# toolbox.register(\"map\", pool.map)\n",
    "#toolbox.register(\"map\", futures.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f27d738a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def imputeMultipleDataFrame(dataFrame):\n",
    "    imputer = IterativeImputer( n_nearest_features=None, imputation_order='ascending', missing_values = np.nan) #If None, all features will be used.\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(dataFrame)\n",
    "    trans = imp.transform(dataFrame)\n",
    "    \n",
    "    to_return = pd.DataFrame(trans, columns=dataFrame.columns)  \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00e458ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd85c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'weighted': ['ann', 'de', 'unweighted'],\n",
    "    'use_stored_base_learners':[False],\n",
    "    'store_base_learners':[False], \n",
    "    'resample' : ['undersample'],\n",
    "    'scale'    : [True],\n",
    "    'n_features': ['all'],\n",
    "    'param_space_size':['medium'],\n",
    "    'n_unique_out': [10],\n",
    "    'outcome_var_n':['1',\n",
    "                     ],\n",
    "    'div_p':[0],\n",
    "    'percent_missing':[99.9, 95, 90],  #n/100 ex 95 for 95%\n",
    "                     'corr':[0.99, 0.9],\n",
    "                      'cxpb':[0.5, 0.75, 0.25],\n",
    "                       'mutpb':[0.2, 0.4, 0.8],\n",
    "                        'indpb':[0.025, 0.05, 0.075],\n",
    "                        't_size':[3, 6, 9],\n",
    "                     'data':[{'age':[True],\n",
    "                            'sex':[True],\n",
    "                             'bmi':[True],\n",
    "                             'ethnicity':[True],\n",
    "                            'bloods':[True],\n",
    "                            'diagnostic_order':[True],\n",
    "                            'drug_order':[True],\n",
    "                            'annotation_n':[True],\n",
    "                            'meta_sp_annotation_n':[True],\n",
    "                             'annotation_mrc_n':[True],\n",
    "                             'meta_sp_annotation_mrc_n':[True],\n",
    "                              'core_02':[True],\n",
    "                            'bed':[True],\n",
    "                            'vte_status':[True],\n",
    "                            'hosp_site':[True],\n",
    "                            'core_resus':[True],\n",
    "                            'news':[True],\n",
    "                            'date_time_stamp': [True]}],\n",
    "    'verbosity':[9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98facb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458\n"
     ]
    }
   ],
   "source": [
    "def c_prod(d):\n",
    "    if isinstance(d, list):\n",
    "         for i in d:\n",
    "            yield from ([i] if not isinstance(i, (dict, list)) else c_prod(i))\n",
    "    else:\n",
    "         for i in it.product(*map(c_prod, d.values())):\n",
    "            yield dict(zip(d.keys(), i))\n",
    "\n",
    "print(len(list(c_prod(grid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70933003",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_list = list(c_prod(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a18ed6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_list = random.sample(settings_list, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "955a5f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(settings_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c176c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "400d06f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_grid imported\n",
      "Imported logistic regression class\n"
     ]
    }
   ],
   "source": [
    "from ml_grid.util import grid_param_space_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "efb0a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " 'CONTRIBUTING.md',\n",
       " 'ga_env',\n",
       " 'grid_score_reader_GA_v2.2 (1).ipynb',\n",
       " 'HFE_GA_experiments',\n",
       " 'HFE_GA_v19.4.ipynb',\n",
       " 'LICENSE',\n",
       " 'ml_grid',\n",
       " 'percent_missing_dict.pickle',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'synthetic_sample_100_features_4.csv',\n",
       " 'venv',\n",
       " '_a_F_F_u_T_a_m_10_1_0_99.9_.9_.25_.2_.025_6111111111011110912HFE_GA_Grid_best_pop=4_g=2_nb=4.pkl',\n",
       " '_a_F_F_u_T_a_m_10_1_0_99.9_.9_.25_.8_.025_3111111111011110912HFE_GA_Grid_best_pop=4_g=2_nb=4.pkl',\n",
       " '_d_F_F_u_T_a_m_10_1_0_90_.99_.25_.4_.025_6111111111111110656HFE_GA_Grid_best_pop=4_g=2_nb=4.pkl',\n",
       " '_d_F_F_u_T_a_m_10_1_0_99.9_.99_.75_.8_.025_6111111111011110912HFE_GA_Grid_best_pop=4_g=2_nb=4.pkl',\n",
       " '_u_F_F_u_T_a_m_10_1_0_95_.9_.5_.2_.075_6111111111111110656HFE_GA_Grid_best_pop=4_g=2_nb=4.pkl',\n",
       " '_u_F_F_u_T_a_m_10_1_0_99.9_.99_.75_.4_.025_9111111111011110912HFE_GA_Grid_best_pop=4_g=2_nb=4.pkl']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58bda9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "output = ipw.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f7f82146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_substring_list(string, substr):\n",
    "    return [str for str in string if\n",
    "             any(sub in str for sub in substr) and 'bmi' not in str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3420b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generation_progress_fitness(generation_progress_list):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "\n",
    "\n",
    "    x = [x for x in range(0, len(generation_progress_list))]\n",
    "    ax.plot(x,generation_progress_list);\n",
    "    plt.savefig(file_path+\n",
    "                \"figures//\"\n",
    "                    + \"best_pop=\"\n",
    "                    + str(pop_val)\n",
    "                    + \"_g=\"\n",
    "                    + str(g_val)\n",
    "                    + \"_nb=\"\n",
    "                    + str(nb_val)\n",
    "                    + \".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19576158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7013049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_grid.model_classes_ga.logistic_regression_model import logisticRegressionModelGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01553549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFE_GA_experiments/2024-03-10_03-48-27_PM/\n",
      "Feature space slice sample_n 1\n",
      "Full settings_list size: 2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting... {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "_ann_False_False_undersample_True_all_medium_10_1_0_90_0.9_0.25_0.2_0.025_9111111111111111111\n",
      "_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656\n",
      "Init main on ml_grid/tests/synthetic_sample_100_features_4.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_param_dict data perturbation: \n",
      " {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 34/36 columns for outcome_var_1 outcome\n",
      "Omitting 2 :...\n",
      "['outcome_var_1', 'Unnamed: 0']...\n",
      "Identified 15 correlated features to drop at >0.9\n",
      "Identified 1 at > 90 threshold\n",
      "Extending all outcome list on drop list\n",
      "outcome_var_1not in drop list\n",
      "dropping duplicated columns\n",
      "Screening for non float data types:\n",
      "len final droplist: 113 \\ 36\n",
      "------------------------\n",
      "undersample..\n",
      "(100,)\n",
      "(100, 19)\n",
      "Data Split Information:\n",
      "Number of rows in self.X_train: 56, Columns: 19\n",
      "Number of rows in self.X_test: 19, Columns: 19\n",
      "Number of rows in self.y_train: 56\n",
      "Number of rows in self.y_test: 19\n",
      "Number of rows in self.X_test_orig: 25, Columns: 19\n",
      "Number of rows in self.y_test_orig: 25\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression -0.05556 4 0.4722 0\n",
      "HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs///model_store.json HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs/\n",
      "Feature space slice sample_n 1000\n",
      "Full settings_list size: 2916\n",
      "Passed main GA init\n",
      "Executing\n",
      "[(4, 4, 2)]\n",
      "(4, 4, 2) 16 model generation space\n",
      "(4, 4, 2) 8 individual evaluation space\n",
      "1\n",
      "Evolving ensemble:  nb_val: 4 pop_val: 4 g_val: 2 ...\n",
      "Registering toolbox elements\n",
      "Generate intial population n==4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:03<00:00,  1.73s/it]\n",
      "100%|| 2/2 [00:03<00:00,  1.71s/it]\n",
      "100%|| 2/2 [00:03<00:00,  1.70s/it]\n",
      "100%|| 2/2 [00:03<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=10.0, class_weight='balanced', max_iter=5, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present', 'Liver structure (body structure)_count_relative_not_present', 'Intermittent (qualifier value)_count_subject_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.05555555555555555, LogisticRegression(C=0.001, class_weight='balanced', max_iter=50, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.5278, array([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  379 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.67254 | Acc: 53.000 | AUC: 0.5240931510925293\n",
      "ANN unweighted ensemble AUC:  0.5277777777777778\n",
      "ANN weighted   ensemble AUC:  0.4778\n",
      "ANN weighted   ensemble AUC difference:  -0.04997777777777779\n",
      "ANN unweighted ensemble MCC:  0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  -0.044946657497549475\n",
      "Ensemble MCC -0.044946657497549475, AUC 0.4777777777777778, nb 2\n",
      "Ensemble MCC -0.044946657497549475, diversity weighted MCC 0.03677453795254048\n",
      "        , \n",
      " f1 0.4444444444444444 precision 0.5 recall 0.4 accuracy 0.47368421052631576\n",
      "        , \n",
      " AUC 0.4777777777777778, diversity weighted AUC -0.3909090909090909\n",
      "        , \n",
      " nb 2, diversity_score: 0.18181818181818182, diff: -0.8686868686868687 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.044946657497549475, LogisticRegression(C=10000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  379 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.67075 | Acc: 63.000 | AUC: -0.22312697768211365\n",
      "ANN unweighted ensemble AUC:  0.5222222222222223\n",
      "ANN weighted   ensemble AUC:  0.5\n",
      "ANN weighted   ensemble AUC difference:  -0.022222222222222254\n",
      "ANN unweighted ensemble MCC:  0.044946657497549475\n",
      "ANN weighted   ensemble MCC:  0.0\n",
      "Ensemble MCC 0.0, AUC 0.5, nb 2\n",
      "Ensemble MCC 0.0, diversity weighted MCC -0.0\n",
      "        , \n",
      " f1 0.0 precision 0.0 recall 0.0 accuracy 0.47368421052631576\n",
      "        , \n",
      " AUC 0.5, diversity weighted AUC -0.5\n",
      "        , \n",
      " nb 2, diversity_score: 0.0, diff: -1.0 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(-0.05555555555555555, LogisticRegression(C=100.0, class_weight='balanced', max_iter=7, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  379 free MiB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.69069 | Acc: 58.000 | AUC: 0.10424234718084335\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.5278\n",
      "ANN weighted   ensemble AUC difference:  0.05557777777777784\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.05555555555555555\n",
      "Ensemble MCC 0.05555555555555555, AUC 0.5277777777777778, nb 2\n",
      "Ensemble MCC 0.05555555555555555, diversity weighted MCC -0.05555555555555555\n",
      "        , \n",
      " f1 0.5263157894736842 precision 0.5555555555555556 recall 0.5 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5277777777777778, diversity weighted AUC -0.5277777777777778\n",
      "        , \n",
      " nb 2, diversity_score: 0.0, diff: -1.0555555555555556 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.0, LogisticRegression(C=0.0001, class_weight='balanced', max_iter=15, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count'], 0, 0.5, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int64)), (0.32539568672798425, LogisticRegression(C=1e-05, class_weight='balanced', max_iter=75, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present', 'Liver structure (body structure)_count_relative_not_present', 'Intermittent (qualifier value)_count_subject_present', '(2022, 11)_date_time_stamp', 'Programme (qualifier value)_count_subject_not_present', 'MRSA Screen_num-diagnostic-order', '(2006, 11)_date_time_stamp'], 0, 0.6, array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  379 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.70842 | Acc: 26.000 | AUC: -0.1000896543264389\n",
      "ANN unweighted ensemble AUC:  0.5\n",
      "ANN weighted   ensemble AUC:  0.35\n",
      "ANN weighted   ensemble AUC difference:  -0.15000000000000002\n",
      "ANN unweighted ensemble MCC:  0.0\n",
      "ANN weighted   ensemble MCC:  -0.4107919181288746\n",
      "Ensemble MCC -0.4107919181288746, AUC 0.35, nb 2\n",
      "Ensemble MCC -0.4107919181288746, diversity weighted MCC -0.0\n",
      "        , \n",
      " f1 0.5384615384615384 precision 0.4375 recall 0.7 accuracy 0.3684210526315789\n",
      "        , \n",
      " AUC 0.35, diversity weighted AUC 0.0\n",
      "        , \n",
      " nb 2, diversity_score: 1.0, diff: -0.35 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- Generation 1 --\n",
      "Selecting next generation individuals,  4\n",
      "Clone the selected individuals\n",
      "Apply crossover and mutation on the offspring\n",
      "mutate\n",
      "original individual of size 1:\n",
      "Mutating individual at index 0\n",
      "Successfully popped 0 from individual\n",
      "LogisticRegression 0.0 13 0.5 0\n",
      "HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs///model_store.json HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs/\n",
      "Evaluate the individuals with an invalid fitness\n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.0, LogisticRegression(C=1e-05, class_weight='balanced', max_iter=50, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present', 'Liver structure (body structure)_count_relative_not_present', 'Intermittent (qualifier value)_count_subject_present'], 0, 0.5, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.74288 | Acc: 42.000 | AUC: -0.7868884801864624\n",
      "ANN unweighted ensemble AUC:  0.5\n",
      "ANN weighted   ensemble AUC:  0.4722\n",
      "ANN weighted   ensemble AUC difference:  -0.02779999999999999\n",
      "ANN unweighted ensemble MCC:  0.0\n",
      "ANN weighted   ensemble MCC:  -0.05555555555555555\n",
      "Ensemble MCC -0.05555555555555555, AUC 0.4722222222222222, nb 2\n",
      "Ensemble MCC -0.05555555555555555, diversity weighted MCC -0.0\n",
      "        , \n",
      " f1 0.5 precision 0.5 recall 0.5 accuracy 0.47368421052631576\n",
      "        , \n",
      " AUC 0.4722222222222222, diversity weighted AUC 0.0\n",
      "        , \n",
      " nb 2, diversity_score: 1.0, diff: -0.4722222222222222 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.69259 | Acc: 58.000 | AUC: -0.00403740257024765\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.5278\n",
      "ANN weighted   ensemble AUC difference:  0.05557777777777784\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.05555555555555555\n",
      "Ensemble MCC 0.05555555555555555, AUC 0.5277777777777778, nb 2\n",
      "Ensemble MCC 0.05555555555555555, diversity weighted MCC -0.0505050505050505\n",
      "        , \n",
      " f1 0.5263157894736842 precision 0.5555555555555556 recall 0.5 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5277777777777778, diversity weighted AUC -0.4797979797979798\n",
      "        , \n",
      " nb 2, diversity_score: 0.09090909090909091, diff: -1.0075757575757576 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(-0.05555555555555555, LogisticRegression(C=100.0, class_weight='balanced', max_iter=7, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.044946657497549475, LogisticRegression(C=10000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020: | Loss: 0.68405 | Acc: 37.000 | AUC: 0.28522905707359314\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.5\n",
      "ANN weighted   ensemble AUC difference:  0.02777777777777779\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.0\n",
      "Ensemble MCC 0.0, AUC 0.5, nb 2\n",
      "Ensemble MCC 0.0, diversity weighted MCC -0.0\n",
      "        , \n",
      " f1 0.6896551724137931 precision 0.5263157894736842 recall 1.0 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5, diversity weighted AUC -0.45454545454545453\n",
      "        , \n",
      " nb 2, diversity_score: 0.09090909090909091, diff: -0.9545454545454546 \n",
      "Gather all the fitnesses in one list and print the stats\n",
      "min: 0.4722222222222222, max: 0.5277777777777778 , mean: 0.5069444444444444, std: 0.023032116599691007\n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.0, LogisticRegression(C=1e-05, class_weight='balanced', max_iter=50, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present', 'Liver structure (body structure)_count_relative_not_present', 'Intermittent (qualifier value)_count_subject_present'], 0, 0.5, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00, 4032.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.71139 | Acc: 37.000 | AUC: 0.13707922399044037\n",
      "ANN unweighted ensemble AUC:  0.5\n",
      "ANN weighted   ensemble AUC:  0.5\n",
      "ANN weighted   ensemble AUC difference:  0.0\n",
      "ANN unweighted ensemble MCC:  0.0\n",
      "ANN weighted   ensemble MCC:  0.0\n",
      "Ensemble MCC 0.0, AUC 0.5, nb 2\n",
      "Ensemble MCC 0.0, diversity weighted MCC 0.0\n",
      "        , \n",
      " f1 0.6896551724137931 precision 0.5263157894736842 recall 1.0 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5, diversity weighted AUC 0.0\n",
      "        , \n",
      " nb 2, diversity_score: 1.0, diff: -0.5 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(-0.05555555555555555, LogisticRegression(C=100.0, class_weight='balanced', max_iter=7, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.67351 | Acc: 58.000 | AUC: 0.2769395709037781\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.5278\n",
      "ANN weighted   ensemble AUC difference:  0.05557777777777784\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.05555555555555555\n",
      "Ensemble MCC 0.05555555555555555, AUC 0.5277777777777778, nb 2\n",
      "Ensemble MCC 0.05555555555555555, diversity weighted MCC -0.05555555555555555\n",
      "        , \n",
      " f1 0.5263157894736842 precision 0.5555555555555556 recall 0.5 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5277777777777778, diversity weighted AUC -0.5277777777777778\n",
      "        , \n",
      " nb 2, diversity_score: 0.0, diff: -1.0555555555555556 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00, 4027.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.80201 | Acc: 53.000 | AUC: 0.09952239692211151\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.4778\n",
      "ANN weighted   ensemble AUC difference:  0.005577777777777793\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  -0.044946657497549475\n",
      "Ensemble MCC -0.044946657497549475, AUC 0.4777777777777778, nb 2\n",
      "Ensemble MCC -0.044946657497549475, diversity weighted MCC 0.040860597725044974\n",
      "        , \n",
      " f1 0.4444444444444444 precision 0.5 recall 0.4 accuracy 0.47368421052631576\n",
      "        , \n",
      " AUC 0.4777777777777778, diversity weighted AUC -0.43434343434343436\n",
      "        , \n",
      " nb 2, diversity_score: 0.09090909090909091, diff: -0.9121212121212121 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(-0.05555555555555555, LogisticRegression(C=100.0, class_weight='balanced', max_iter=7, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.044946657497549475, LogisticRegression(C=10000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.63594 | Acc: 68.000 | AUC: -0.056202370673418045\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.55\n",
      "ANN weighted   ensemble AUC difference:  0.07777777777777783\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.22360679774997896\n",
      "Ensemble MCC 0.22360679774997896, AUC 0.55, nb 2\n",
      "Ensemble MCC 0.22360679774997896, diversity weighted MCC -0.20327890704543541\n",
      "        , \n",
      " f1 0.18181818181818182 precision 1.0 recall 0.1 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.55, diversity weighted AUC -0.5\n",
      "        , \n",
      " nb 2, diversity_score: 0.09090909090909091, diff: -1.05 \n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.63065 | Acc: 58.000 | AUC: -0.24989309906959534\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.5278\n",
      "ANN weighted   ensemble AUC difference:  0.05557777777777784\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.05555555555555555\n",
      "gen_eval_score == 0.5277777777777778 Generation 1\n",
      "gen_eval_score gain: 0.12777777777777777 rate: -0.5 ETA: 999999999999999967336168804116691273849533185806555472917961779471295845921727862608739868455469056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- Generation 2 --\n",
      "Selecting next generation individuals,  4\n",
      "Clone the selected individuals\n",
      "Apply crossover and mutation on the offspring\n",
      "mutate\n",
      "original individual of size 1:\n",
      "Mutating individual at index 1\n",
      "Successfully popped 1 from individual\n",
      "LogisticRegression -0.03581 8 0.4833 0\n",
      "HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs///model_store.json HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs/\n",
      "original individual of size 1:\n",
      "Mutating individual at index 1\n",
      "Successfully popped 1 from individual\n",
      "LogisticRegression 0.05556 18 0.5278 0\n",
      "HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs///model_store.json HFE_GA_experiments/2024-03-10_03-48-27_PM/_a_F_F_u_T_a_m_10_1_0_90_.9_.25_.2_.025_9111111111111110656HFE_GA_Grid_/logs/\n",
      "Evaluate the individuals with an invalid fitness\n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.03580574370197164, LogisticRegression(C=0.001, class_weight='balanced', max_iter=5, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present'], 0, 0.4833, array([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.71418 | Acc: 37.000 | AUC: 0.01645742356777191\n",
      "ANN unweighted ensemble AUC:  0.4833333333333334\n",
      "ANN weighted   ensemble AUC:  0.5\n",
      "ANN weighted   ensemble AUC difference:  0.016666666666666607\n",
      "ANN unweighted ensemble MCC:  -0.03580574370197164\n",
      "ANN weighted   ensemble MCC:  0.0\n",
      "Ensemble MCC 0.0, AUC 0.5, nb 2\n",
      "Ensemble MCC 0.0, diversity weighted MCC -0.0\n",
      "        , \n",
      " f1 0.6896551724137931 precision 0.5263157894736842 recall 1.0 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5, diversity weighted AUC -0.2727272727272727\n",
      "        , \n",
      " nb 2, diversity_score: 0.45454545454545453, diff: -0.7727272727272727 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.05555555555555555, LogisticRegression(C=0.001, class_weight='balanced', max_iter=7, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present', 'Liver structure (body structure)_count_relative_not_present', 'Intermittent (qualifier value)_count_subject_present', '(2022, 11)_date_time_stamp', 'Programme (qualifier value)_count_subject_not_present', 'MRSA Screen_num-diagnostic-order', '(2006, 11)_date_time_stamp', '(2013, 6)_date_time_stamp'], 0, 0.5278, array([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.67668 | Acc: 47.000 | AUC: 0.17845408618450165\n",
      "ANN unweighted ensemble AUC:  0.5277777777777778\n",
      "ANN weighted   ensemble AUC:  0.5056\n",
      "ANN weighted   ensemble AUC difference:  -0.02217777777777774\n",
      "ANN unweighted ensemble MCC:  0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.018077538151554683\n",
      "Ensemble MCC 0.018077538151554683, AUC 0.5055555555555555, nb 2\n",
      "Ensemble MCC 0.018077538151554683, diversity weighted MCC -0.014790713033090194\n",
      "        , \n",
      " f1 0.6666666666666666 precision 0.5294117647058824 recall 0.9 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5055555555555555, diversity weighted AUC -0.4136363636363636\n",
      "        , \n",
      " nb 2, diversity_score: 0.18181818181818182, diff: -0.9191919191919191 \n",
      "Gather all the fitnesses in one list and print the stats\n",
      "min: 0.5, max: 0.5277777777777778 , mean: 0.5152777777777777, std: 0.012653379971037906\n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(-0.05555555555555555, LogisticRegression(C=100.0, class_weight='balanced', max_iter=7, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.67858 | Acc: 58.000 | AUC: -0.04540574550628662\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.5278\n",
      "ANN weighted   ensemble AUC difference:  0.05557777777777784\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.05555555555555555\n",
      "Ensemble MCC 0.05555555555555555, AUC 0.5277777777777778, nb 2\n",
      "Ensemble MCC 0.05555555555555555, diversity weighted MCC -0.05555555555555555\n",
      "        , \n",
      " f1 0.5263157894736842 precision 0.5555555555555556 recall 0.5 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5277777777777778, diversity weighted AUC -0.5277777777777778\n",
      "        , \n",
      " nb 2, diversity_score: 0.0, diff: -1.0555555555555556 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.03580574370197164, LogisticRegression(C=0.001, class_weight='balanced', max_iter=5, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present'], 0, 0.4833, array([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  380 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.67029 | Acc: 63.000 | AUC: -0.06788744032382965\n",
      "ANN unweighted ensemble AUC:  0.4833333333333334\n",
      "ANN weighted   ensemble AUC:  0.4833\n",
      "ANN weighted   ensemble AUC difference:  -3.333333333338517e-05\n",
      "ANN unweighted ensemble MCC:  -0.03580574370197164\n",
      "ANN weighted   ensemble MCC:  -0.03580574370197164\n",
      "Ensemble MCC -0.03580574370197164, AUC 0.4833333333333334, nb 2\n",
      "Ensemble MCC -0.03580574370197164, diversity weighted MCC 0.019530405655620895\n",
      "        , \n",
      " f1 0.375 precision 0.5 recall 0.3 accuracy 0.47368421052631576\n",
      "        , \n",
      " AUC 0.4833333333333334, diversity weighted AUC -0.26363636363636367\n",
      "        , \n",
      " nb 2, diversity_score: 0.45454545454545453, diff: -0.7469696969696971 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (0.05555555555555555, LogisticRegression(C=0.001, class_weight='balanced', max_iter=7, solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present', 'Atrial structure (body structure)_count_subject_not_present', 'Small (qualifier value)_count', '10*12/liter (qualifier value)_count', 'Asthenia (finding)_count_subject_present', 'Liver structure (body structure)_count_relative_not_present', 'Intermittent (qualifier value)_count_subject_present', '(2022, 11)_date_time_stamp', 'Programme (qualifier value)_count_subject_not_present', 'MRSA Screen_num-diagnostic-order', '(2006, 11)_date_time_stamp', '(2013, 6)_date_time_stamp'], 0, 0.5278, array([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  366 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.64838 | Acc: 58.000 | AUC: 0.09404851496219635\n",
      "ANN unweighted ensemble AUC:  0.5277777777777778\n",
      "ANN weighted   ensemble AUC:  0.5278\n",
      "ANN weighted   ensemble AUC difference:  2.2222222222256782e-05\n",
      "ANN unweighted ensemble MCC:  0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.05555555555555555\n",
      "Ensemble MCC 0.05555555555555555, AUC 0.5277777777777778, nb 2\n",
      "Ensemble MCC 0.05555555555555555, diversity weighted MCC -0.04545454545454545\n",
      "        , \n",
      " f1 0.5263157894736842 precision 0.5555555555555556 recall 0.5 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.5277777777777778, diversity weighted AUC -0.4318181818181818\n",
      "        , \n",
      " nb 2, diversity_score: 0.18181818181818182, diff: -0.9595959595959596 \n",
      "evaluate_weighted_ensemble_auc: individual\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  366 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.66242 | Acc: 68.000 | AUC: 0.11451809108257294\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.55\n",
      "ANN weighted   ensemble AUC difference:  0.07777777777777783\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.22360679774997896\n",
      "Ensemble MCC 0.22360679774997896, AUC 0.55, nb 2\n",
      "Ensemble MCC 0.22360679774997896, diversity weighted MCC -0.20327890704543541\n",
      "        , \n",
      " f1 0.18181818181818182 precision 1.0 recall 0.1 accuracy 0.5263157894736842\n",
      "        , \n",
      " AUC 0.55, diversity weighted AUC -0.5\n",
      "        , \n",
      " nb 2, diversity_score: 0.09090909090909091, diff: -1.05 \n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Training ANN weighted ensemble on full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  364 free MiB\n",
      "{'column_length': 2, 'batch_size': 19, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.67437 | Acc: 68.000 | AUC: -0.09962727129459381\n",
      "ANN unweighted ensemble AUC:  0.4722222222222222\n",
      "ANN weighted   ensemble AUC:  0.55\n",
      "ANN weighted   ensemble AUC difference:  0.07777777777777783\n",
      "ANN unweighted ensemble MCC:  -0.05555555555555555\n",
      "ANN weighted   ensemble MCC:  0.22360679774997896\n",
      "gen_eval_score == 0.55 Generation 2\n",
      "gen_eval_score gain: 0.022222222222222254 rate: 0.013888888888888895 ETA: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2/3 [00:01<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Ensemble Model: \n",
      "LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag') n features:  7\n",
      "LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag') n features:  3\n",
      "Best Ensemble diversity score: 0.09090909090909091\n",
      "17.03263807296753\n",
      "Getting final final best pred for plot with validation set, get weights from xtrain ytrain\n",
      "Starting get_y_pred_resolver function...\n",
      "local_param_dict: {'weighted': 'ann', 'use_stored_base_learners': False, 'store_base_learners': False, 'resample': 'undersample', 'scale': True, 'n_features': 'all', 'param_space_size': 'medium', 'n_unique_out': 10, 'outcome_var_n': '1', 'div_p': 0, 'percent_missing': 90, 'corr': 0.9, 'cxpb': 0.25, 'mutpb': 0.2, 'indpb': 0.025, 't_size': 9, 'data': {'age': True, 'sex': True, 'bmi': True, 'ethnicity': True, 'bloods': True, 'diagnostic_order': True, 'drug_order': True, 'annotation_n': True, 'meta_sp_annotation_n': True, 'annotation_mrc_n': True, 'meta_sp_annotation_mrc_n': True, 'core_02': True, 'bed': True, 'vte_status': True, 'hosp_site': True, 'core_resus': True, 'news': True, 'date_time_stamp': True}}\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Using ANN weighted ensemble prediction...\n",
      "Evaluating ANN weighted ensemble on validation set: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00, 237.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00, 806.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU0 with  364 free MiB\n",
      "{'column_length': 2, 'batch_size': 56, 'deep_layers_1': 2, 'dropout_val': 0.001}\n",
      "{'epochs': 20, 'learning_rate': 0.0001}\n",
      "cpu\n",
      "Epoch 020: | Loss: 0.63067 | Acc: 70.000 | AUC: 0.7190372347831726\n",
      "ANN unweighted ensemble AUC:  0.6833333333333332\n",
      "ANN weighted   ensemble AUC:  0.6833\n",
      "ANN weighted   ensemble AUC difference:  -3.333333333321864e-05\n",
      "ANN unweighted ensemble MCC:  0.3595462477533374\n",
      "ANN weighted   ensemble MCC:  0.3595462477533374\n",
      "nb_val: 4 pop_val: 4 g_val: 2 AUC:  0.6833333333333332 g: 2\n",
      "Writing grid perturbation to log\n",
      "update_score_log\n",
      "Valid: True\n",
      "ML grid object: <ml_grid.pipeline.data.pipe object at 0x000001C2769C81F0>\n",
      "Scores: 0.6833333333333332\n",
      "Best prediction original: [1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0.]\n",
      "Current algorithm: [[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "Method name: [[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "PG: nan\n",
      "Start: 1710085708.2504082\n",
      "Number of iterations: nan\n",
      "X_train shape: (56, 19)\n",
      "y_train shape: (56,)\n",
      "X_test shape: (19, 19)\n",
      "y_test shape: (19,)\n",
      "X_test_orig shape: (25, 19)\n",
      "y_test_orig shape: (25,)\n",
      "Global parameters: <ml_grid.util.global_params.global_parameters object at 0x000001C2007A0AC0>\n",
      "best_pred_orig len 25\n",
      "Writing grid permutation to log\n",
      "Using self.y_test_orig for evaluation.\n",
      "current_algorithm\n",
      "[[(0.044946657497549475, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=20,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present', 'Suggestive of (attribute)_count_subject_not_present', 'Containing (qualifier value)_count_subject_present', 'Adult (person)_count_relative_not_present', 'Routine (qualifier value)_count_relative_not_present'], 0, 0.5222, array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64)), (-0.05555555555555555, LogisticRegression(C=100000.0, class_weight='balanced', max_iter=12,\n",
      "                   solver='sag'), ['Nursing (qualifier value)_count_relative_not_present', 'Aspirin (substance)_count_relative_not_present', 'Dermatologist (occupation)_count_relative_not_present'], 0, 0.4722, array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "      dtype=int64))]]\n",
      "   nb_size                                             f_list       auc  \\\n",
      "0       19  [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,...  0.683333   \n",
      "\n",
      "        mcc        f1  precision    recall  accuracy nb_val pop_val  ...  \\\n",
      "0  0.359546  0.714286   0.769231  0.666667      0.68    NaN     NaN  ...   \n",
      "\n",
      "  accuracy_m accuracy_std recall_m  recall_std  \\\n",
      "0        NaN          NaN      NaN         NaN   \n",
      "\n",
      "                            algorithm_implementation  \\\n",
      "0  [[(0.044946657497549475, LogisticRegression(C=...   \n",
      "\n",
      "                                    parameter_sample  \\\n",
      "0  [[(0.044946657497549475, LogisticRegression(C=...   \n",
      "\n",
      "                                         method_name  t_fits n_fits  i  \n",
      "0  [[(0.044946657497549475, LogisticRegression(C=...     nan    nan  0  \n",
      "\n",
      "[1 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:17<00:00, 17.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import ml_grid\n",
    "import pathlib\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ml_grid.util.project_score_save import project_score_save_class\n",
    "\n",
    "base_project_dir_global = 'HFE_GA_experiments/'\n",
    "\n",
    "pathlib.Path(base_project_dir_global).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "st_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%I-%M-%S_%p\")\n",
    "\n",
    "base_project_dir = 'HFE_GA_experiments/' + st_time + \"/\"\n",
    "additional_naming = \"HFE_GA_Grid_\"\n",
    "\n",
    "print(base_project_dir)\n",
    "\n",
    "pathlib.Path(base_project_dir).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "#input_csv_path = '/home/aliencat/samora/HFE/HFE/v20/30163_to_16408_imputed_outcome_grid.csv'\n",
    "\n",
    "input_csv_path = '/home/aliencat/samora/HFE/HFE/v22/hfe_TC_merge_T_Im_10k_1yr_mean_imputed.csv'\n",
    "\n",
    "input_csv_path = 'ml_grid/tests/synthetic_sample_100_features_4.csv'\n",
    "\n",
    "#init csv to store each local projects results\n",
    "\n",
    "project_score_save_class(base_project_dir)\n",
    "\n",
    "n_iter = 1\n",
    "\n",
    "grid_iter_obj = grid_param_space_ga.Grid(sample_n=n_iter).settings_list_iterator\n",
    "\n",
    "modelFuncList = [\n",
    "#         dummy_model_gen,\n",
    "#         dummy_model_gen,\n",
    "#       logModelGen,\n",
    "    logisticRegressionModelGenerator,\n",
    "    logisticRegressionModelGenerator,\n",
    "    #    perceptronModelGen,\n",
    "    #    extraTreesModelGen,\n",
    "    #    randomForestModelGen,\n",
    "    #    kNearestNeighborsModelGen,\n",
    "    #    XGBoostModelGen,\n",
    "    #    elasticNeuralNetworkModelGen,\n",
    "\n",
    "    #    DecisionTreeClassifier_ModelGen,\n",
    "    #    AdaBoostClassifier_ModelGen,\n",
    "    #    GaussianNB_ModelGen,\n",
    "    #    QuadraticDiscriminantAnalysis_ModelGen,\n",
    "    #    SVC_ModelGen,\n",
    "    #    GradientBoostingClassifier_ModelGen,\n",
    "    #    RandomForestClassifier_ModelGen,\n",
    "    #    MLPClassifier_ModelGen,\n",
    "    #     #KerasClassifier_ModelGen()\n",
    "    #    Pytorch_binary_class_ModelGen\n",
    "        ]\n",
    "\n",
    "\n",
    "config_dict = {'use_stored_base_learners': False,\n",
    "               'modelFuncList' : modelFuncList,\n",
    "\n",
    "               }\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, n_iter)):\n",
    "    output.clear_output(wait=True)\n",
    "\n",
    "    #get settings from iterator over grid of settings space\n",
    "    local_param_dict = next(grid_iter_obj)\n",
    "\n",
    "    #create object from settings\n",
    "    ml_grid_object = ml_grid.pipeline.data.pipe(input_csv_path,\n",
    "                                                drop_term_list=['chrom', 'hfe', 'phlebo'],\n",
    "                                                local_param_dict=local_param_dict,\n",
    "                                                base_project_dir = base_project_dir,\n",
    "                                                additional_naming = additional_naming,\n",
    "                                                test_sample_n = 0,\n",
    "                                                param_space_index = i,\n",
    "                                                config_dict=config_dict\n",
    "                                                )\n",
    "    \n",
    "    use_stored_base_learners = local_param_dict.get('use_stored_base_learners')\n",
    "\n",
    "    store_base_learners = local_param_dict.get('store_base_learners')\n",
    "    \n",
    "    \n",
    "    \n",
    "    from ml_grid.pipeline import main_ga\n",
    "\n",
    "\n",
    "    #pass object to be evaluated and write results to csv\n",
    "    res = main_ga.run(ml_grid_object, local_param_dict=local_param_dict).execute()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c03ba993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_store_dataframe.csv']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(ml_grid_object.logging_paths_obj.log_folder_path + \"/progress_logs_scores/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "461261ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_size</th>\n",
       "      <th>f_list</th>\n",
       "      <th>auc</th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>nb_val</th>\n",
       "      <th>pop_val</th>\n",
       "      <th>...</th>\n",
       "      <th>BL_62</th>\n",
       "      <th>BL_63</th>\n",
       "      <th>auc_m</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>f1_m</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>accuracy_m</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>recall_m</th>\n",
       "      <th>recall_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.359546</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_size  f_list                                                auc  \\\n",
       "0        0      19  [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,...   \n",
       "\n",
       "        mcc        f1  precision    recall  accuracy  nb_val  pop_val  ...  \\\n",
       "0  0.683333  0.359546   0.714286  0.769231  0.666667    0.68      NaN  ...   \n",
       "\n",
       "   BL_62  BL_63  auc_m auc_std  f1_m  f1_std accuracy_m  accuracy_std  \\\n",
       "0    NaN    NaN    NaN     NaN   NaN     NaN        NaN           NaN   \n",
       "\n",
       "   recall_m recall_std  \n",
       "0       NaN        NaN  \n",
       "\n",
       "[1 rows x 123 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ml_grid_object.base_project_dir + \"final_grid_score_log.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a24c3221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,...\n",
       "Name: BL_0, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BL_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c129a0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0.41666666666666663</th>\n",
       "      <th>0.4167</th>\n",
       "      <th>-0.41666666666666663</th>\n",
       "      <th>-0.1685499656158105</th>\n",
       "      <th>-0.1685499656158105.1</th>\n",
       "      <th>0.1685499656158105</th>\n",
       "      <th>0.47619047619047616</th>\n",
       "      <th>0.45454545454545453</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.42105263157894735</th>\n",
       "      <th>[\"LogisticRegression(C=0.001, class_weight='balanced', max_iter=12, solver='sag')\"]</th>\n",
       "      <th>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</th>\n",
       "      <th>[0.4167]</th>\n",
       "      <th>[-0.1685499656158105]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.522222</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=10.0, class_weight='bal...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1e-05, class_weight='ba...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.522222</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=10.0, class_weight='bal...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.401709</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.034574</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1, class_weight='balanc...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.522222</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=10.0, class_weight='bal...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.401709</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.034574</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1, class_weight='balanc...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1e-05, class_weight='ba...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.522222</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=10.0, class_weight='bal...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.522222</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1, class_weight='balanc...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.401709</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.034574</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1, class_weight='balanc...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.401709</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.034574</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1, class_weight='balanc...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.401709</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.034574</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1, class_weight='balanc...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.522222</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>[\"LogisticRegression(C=1, class_weight='balanc...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>[0.5222]</td>\n",
       "      <td>[0.044946657497549475]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  2  0.41666666666666663  0.4167  -0.41666666666666663  \\\n",
       "0   0  2             0.522222  0.5222             -0.522222   \n",
       "1   0  2             0.522222  0.5000              0.000000   \n",
       "2   0  2             0.522222  0.5222             -0.522222   \n",
       "3   0  2             0.522222  0.5222             -0.401709   \n",
       "4   0  2             0.522222  0.5222             -0.522222   \n",
       "5   0  2             0.522222  0.5222             -0.401709   \n",
       "6   0  2             0.522222  0.5000              0.000000   \n",
       "7   0  2             0.522222  0.5222             -0.522222   \n",
       "8   0  2             0.522222  0.5222             -0.522222   \n",
       "9   0  2             0.522222  0.5222             -0.401709   \n",
       "10  0  2             0.522222  0.5222             -0.401709   \n",
       "11  0  2             0.522222  0.5222             -0.401709   \n",
       "12  0  2             0.522222  0.5222             -0.522222   \n",
       "\n",
       "    -0.1685499656158105  -0.1685499656158105.1  0.1685499656158105  \\\n",
       "0              0.044947               0.044947           -0.044947   \n",
       "1              0.044947               0.000000            0.000000   \n",
       "2              0.044947               0.044947           -0.044947   \n",
       "3              0.044947               0.044947           -0.034574   \n",
       "4              0.044947               0.044947           -0.044947   \n",
       "5              0.044947               0.044947           -0.034574   \n",
       "6              0.044947               0.000000            0.000000   \n",
       "7              0.044947               0.044947           -0.044947   \n",
       "8              0.044947               0.044947           -0.044947   \n",
       "9              0.044947               0.044947           -0.034574   \n",
       "10             0.044947               0.044947           -0.034574   \n",
       "11             0.044947               0.044947           -0.034574   \n",
       "12             0.044947               0.044947           -0.044947   \n",
       "\n",
       "    0.47619047619047616  0.45454545454545453  0.5  0.42105263157894735  \\\n",
       "0              0.571429             0.545455  0.6             0.526316   \n",
       "1              0.571429             0.545455  0.6             0.526316   \n",
       "2              0.571429             0.545455  0.6             0.526316   \n",
       "3              0.571429             0.545455  0.6             0.526316   \n",
       "4              0.571429             0.545455  0.6             0.526316   \n",
       "5              0.571429             0.545455  0.6             0.526316   \n",
       "6              0.571429             0.545455  0.6             0.526316   \n",
       "7              0.571429             0.545455  0.6             0.526316   \n",
       "8              0.571429             0.545455  0.6             0.526316   \n",
       "9              0.571429             0.545455  0.6             0.526316   \n",
       "10             0.571429             0.545455  0.6             0.526316   \n",
       "11             0.571429             0.545455  0.6             0.526316   \n",
       "12             0.571429             0.545455  0.6             0.526316   \n",
       "\n",
       "   [\"LogisticRegression(C=0.001, class_weight='balanced', max_iter=12, solver='sag')\"]  \\\n",
       "0   [\"LogisticRegression(C=10.0, class_weight='bal...                                    \n",
       "1   [\"LogisticRegression(C=1e-05, class_weight='ba...                                    \n",
       "2   [\"LogisticRegression(C=10.0, class_weight='bal...                                    \n",
       "3   [\"LogisticRegression(C=1, class_weight='balanc...                                    \n",
       "4   [\"LogisticRegression(C=10.0, class_weight='bal...                                    \n",
       "5   [\"LogisticRegression(C=1, class_weight='balanc...                                    \n",
       "6   [\"LogisticRegression(C=1e-05, class_weight='ba...                                    \n",
       "7   [\"LogisticRegression(C=10.0, class_weight='bal...                                    \n",
       "8   [\"LogisticRegression(C=1, class_weight='balanc...                                    \n",
       "9   [\"LogisticRegression(C=1, class_weight='balanc...                                    \n",
       "10  [\"LogisticRegression(C=1, class_weight='balanc...                                    \n",
       "11  [\"LogisticRegression(C=1, class_weight='balanc...                                    \n",
       "12  [\"LogisticRegression(C=1, class_weight='balanc...                                    \n",
       "\n",
       "   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]  \\\n",
       "0   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "1   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "2   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "3   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "4   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "5   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "6   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "7   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "8   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "9   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "10  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "11  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "12  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...                          \n",
       "\n",
       "    [0.4167]   [-0.1685499656158105]  \n",
       "0   [0.5222]  [0.044946657497549475]  \n",
       "1      [0.5]                   [0.0]  \n",
       "2   [0.5222]  [0.044946657497549475]  \n",
       "3   [0.5222]  [0.044946657497549475]  \n",
       "4   [0.5222]  [0.044946657497549475]  \n",
       "5   [0.5222]  [0.044946657497549475]  \n",
       "6      [0.5]                   [0.0]  \n",
       "7   [0.5222]  [0.044946657497549475]  \n",
       "8   [0.5222]  [0.044946657497549475]  \n",
       "9   [0.5222]  [0.044946657497549475]  \n",
       "10  [0.5222]  [0.044946657497549475]  \n",
       "11  [0.5222]  [0.044946657497549475]  \n",
       "12  [0.5222]  [0.044946657497549475]  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(r'C:\\Users\\admin1\\Documents\\projects\\ensemble_genetic_algorithm\\HFE_GA_experiments\\2024-03-10_12-57-52_PM\\_d_F_F_u_T_a_m_10_1_0_95_.99_.25_.4_.05_9111111111011110912HFE_GA_Grid_\\logs\\progress_logs_scores\\log_store_dataframe.csv')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96a8671f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BL_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\admin1\\Documents\\projects\\ensemble_genetic_algorithm\\ga_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\admin1\\Documents\\projects\\ensemble_genetic_algorithm\\ga_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\admin1\\Documents\\projects\\ensemble_genetic_algorithm\\ga_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BL_0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBL_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin1\\Documents\\projects\\ensemble_genetic_algorithm\\ga_env\\lib\\site-packages\\pandas\\core\\frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3458\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3460\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\admin1\\Documents\\projects\\ensemble_genetic_algorithm\\ga_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BL_0'"
     ]
    }
   ],
   "source": [
    "df['BL_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564aa291",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ca493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%pip install eventlet\n",
    "# self,\n",
    "# ml_grid_object,\n",
    "# scores,\n",
    "# best_pred_orig,\n",
    "# current_algorithm,\n",
    "# method_name,\n",
    "# pg,\n",
    "# start,\n",
    "# n_iter_v,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95719038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_val = 2\n",
    "\n",
    "np.linspace(\n",
    "            2, len(ml_grid_object.X_train.columns), int(len(ml_grid_object.X_train.columns) + 1 - start_val)\n",
    "        ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(np.array([2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d35799",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_grid_object.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_grid_object.local_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff894bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for value in settings_list:\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    log_store_dataframe_path = 'log_store_dataframe'   \n",
    "   \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Running...\")\n",
    "    \n",
    "    \n",
    "\n",
    "    modelFuncList = [\n",
    "#         dummy_model_gen,\n",
    "#         dummy_model_gen,\n",
    "       logModelGen,\n",
    "       perceptronModelGen,\n",
    "       extraTreesModelGen,\n",
    "       randomForestModelGen,\n",
    "       kNearestNeighborsModelGen,\n",
    "       XGBoostModelGen,\n",
    "       elasticNeuralNetworkModelGen,\n",
    "\n",
    "       DecisionTreeClassifier_ModelGen,\n",
    "       AdaBoostClassifier_ModelGen,\n",
    "       GaussianNB_ModelGen,\n",
    "       QuadraticDiscriminantAnalysis_ModelGen,\n",
    "       SVC_ModelGen,\n",
    "       GradientBoostingClassifier_ModelGen,\n",
    "       RandomForestClassifier_ModelGen,\n",
    "       MLPClassifier_ModelGen,\n",
    "        #KerasClassifier_ModelGen()\n",
    "       Pytorch_binary_class_ModelGen\n",
    "        ]\n",
    "    print(len(modelFuncList))\n",
    "    \n",
    "    \n",
    "    fitted_perceptron = perceptronModelGen_dummy()[1]\n",
    "    dummy_columns = perceptronModelGen_dummy()[2]\n",
    "    #pop = toolbox.population(n=pop_val)\n",
    "    \n",
    "    gen_eval_score_threshold_early_stopping = 5\n",
    "\n",
    "    #%%prun -s cumulative\n",
    "    if __name__ == \"__main__\":\n",
    "        grid = [nb_params, pop_params, g_params]\n",
    "        param_grid = list(itertools.product(*grid))\n",
    "        print(param_grid)\n",
    "        for elem in param_grid:\n",
    "            print(elem, elem[0] * elem[1], \"model generation space\")\n",
    "            print(elem, elem[0] * elem[2], \"individual evaluation space\")\n",
    "        print(len(param_grid))\n",
    "\n",
    "        prediction_array = None\n",
    "\n",
    "        #shared.setCont(creator)\n",
    "\n",
    "        #def main():\n",
    "\n",
    "        #small test:\n",
    "        #param_grid = [(4, 5, 4)]\n",
    "\n",
    "\n",
    "        #param_grid = [(5,5,5), (50,5,5), (5,50,5), (5,5,50)]\n",
    "\n",
    "\n",
    "        #random.shuffle(param_grid)\n",
    "        date = datetime.datetime.now().strftime(\"%Y_%m_%d-%I:%M:%S_%p\")\n",
    "        current_log_filename = f'log_{date}.txt'\n",
    "        for i in range(0, len(param_grid)):\n",
    "        #         best = evolve_best_ensemble(\n",
    "        #             param_grid[i][0], param_grid[i][1], param_grid[i][2])\n",
    "\n",
    "\n",
    "            try:\n",
    "                nb_val  = param_grid[i][0]\n",
    "                pop_val = param_grid[i][1]\n",
    "                g_val   = param_grid[i][2]\n",
    "                print(\"Evolving ensemble: \", \"nb_val:\", nb_val,\n",
    "                      \"pop_val:\", pop_val, \"g_val:\", g_val, \"...\")\n",
    "\n",
    "\n",
    "                generation_progress_list = []\n",
    "                print(\"Preparing log file\")\n",
    "                with open(file_path+\"/progress_logs/\"+current_log_filename, 'w') as file:\n",
    "                    pass \n",
    "\n",
    "                with open(file_path+\"/progress_logs/\"+current_log_filename, \"a\") as myfile:\n",
    "                    myfile.write(' '.join(str(i) for i in[[\"Evolving ensemble: \", \"nb_val:\", nb_val,\n",
    "                      \"pop_val:\", pop_val, \"g_val:\", g_val, \"...\"]]))\n",
    "                    myfile.write('\\n')\n",
    "                #global master_result_list\n",
    "                    myfile.close()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                start = time.time()\n",
    "\n",
    "                # print(parameters)\n",
    "                #     nb_val = parameters[0]\n",
    "                #     pop_val = parameters[1]\n",
    "                #     g_val = parameters[2]\n",
    "                #         creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "                #         creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "                # nb_val = 2\n",
    "                #toolbox = base.Toolbox()\n",
    "                print(\"Registering toolbox elements\")\n",
    "                toolbox.register(\"ensembleGenerator\", ensembleGenerator, nb_val=nb_val)\n",
    "                toolbox.register(\n",
    "                    \"individual\",\n",
    "                    tools.initRepeat,\n",
    "                    creator.Individual,\n",
    "                    toolbox.ensembleGenerator,\n",
    "                    n=1, #could potentially increase this to pass to multiprocessing? \n",
    "                )\n",
    "                toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "                toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "                toolbox.register(\"mutate\", tools.mutFlipBit, indpb=global_param_dict.get('indpb'))\n",
    "                toolbox.register(\"mutateFunction\", mutateEnsemble)\n",
    "                toolbox.register(\"mutateEnsemble\", toolbox.mutateFunction)\n",
    "                toolbox.register(\"select\", tools.selTournament, tournsize=global_param_dict.get('t_size'))\n",
    "\n",
    "                #pool = multiprocessing.Pool()\n",
    "                #toolbox.register(\"map\", pool.map)\n",
    "\n",
    "                # print(nb_val, pop_val, g_val)\n",
    "                # print(\"pop_val\", pop_val)\n",
    "                start = time.time()\n",
    "                #     nb_val = param_grid[k][0]\n",
    "                #     pop_val = param_grid[k][1]\n",
    "                #     g_val = param_grid[k][2]\n",
    "                print(f\"Generate intial population n=={pop_val}\")\n",
    "                pop = toolbox.population(n=pop_val)\n",
    "\n",
    "                # Evaluate the entire population\n",
    "                fitnesses = list(toolbox.map(toolbox.evaluate, pop))\n",
    "                for ind, fit in zip(pop, fitnesses):\n",
    "                    ind.fitness.values = fit\n",
    "\n",
    "                # CXPB  is the probability with which two individuals\n",
    "                #       are crossed\n",
    "                #\n",
    "                # MUTPB is the probability for mutating an individual\n",
    "                CXPB, MUTPB = global_param_dict.get('cxpb'), global_param_dict.get('mutpb')\n",
    "\n",
    "                # Extracting all the fitnesses of\n",
    "                fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "                # Variable keeping track of the number of generations\n",
    "                g = 0\n",
    "\n",
    "                #testcrash\n",
    "\n",
    "                # Begin the evolution\n",
    "                chance_dummy_best_pred = [x for x in range(0, len(y_test))]\n",
    "\n",
    "                gen_eval_score = metrics.roc_auc_score(y_test, chance_dummy_best_pred)\n",
    "\n",
    "                gen_eval_score_counter = 0\n",
    "\n",
    "                pbar = tqdm(total = g_val+1)\n",
    "                #while currentData[0] <= runs:\n",
    "\n",
    "                stop_early = False\n",
    "\n",
    "                gen_eval_score_previous = gen_eval_score\n",
    "                gen_eval_score_gain = 0\n",
    "\n",
    "                highest_scoring_ensemble = (0, None)\n",
    "\n",
    "                while g < g_val and gen_eval_score < 0.999 and stop_early==False:\n",
    "\n",
    "\n",
    "                # while g < 50: alt ::  while g < g_val and  ?? eval some how measure AUC or mcc of ensemble? \n",
    "                #for i in tqdm(range(0, g_val)):\n",
    "                    # A new generation\n",
    "                    g = g + 1\n",
    "                    pbar.update(1)\n",
    "                    print(\"\\n -- Generation %i --\" % g)\n",
    "                    # Select the next generation individuals\n",
    "                    print(\"Selecting next generation individuals, \", len(pop))\n",
    "                    offspring = toolbox.select(pop, len(pop))\n",
    "                    # Clone the selected individuals\n",
    "                    print(\"Clone the selected individuals\")\n",
    "                    offspring = list(toolbox.map(toolbox.clone, offspring))\n",
    "                    print(\"Apply crossover and mutation on the offspring\")\n",
    "                    # Apply crossover and mutation on the offspring\n",
    "                    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                        if random.random() < CXPB:\n",
    "                            toolbox.mate(child1[0], child2[0])\n",
    "                            del child1.fitness.values\n",
    "                            del child2.fitness.values\n",
    "                    counter = 0\n",
    "                    print(\"mutate\")\n",
    "                    for mutant in offspring:\n",
    "                        if random.random() < MUTPB:\n",
    "                            # print(mutant[0][0])\n",
    "                            # mutant[0][0] = baseLearnerGenerator()#\n",
    "                            # print(offspring[counter])\n",
    "                            mutatedEnsemble = mutateEnsemble(offspring[counter])\n",
    "                            offspring[counter] = mutatedEnsemble\n",
    "                            # print(\"mutated into:\")\n",
    "                            # print(mutatedEnsemble)\n",
    "                            # toolbox.mutateEnsemble(mutant[0])\n",
    "                            # toolbox.mutate(mutant[0][0])\n",
    "                            del mutant.fitness.values\n",
    "                        counter = counter + 1\n",
    "                    print(\"Evaluate the individuals with an invalid fitness\")\n",
    "                    # Evaluate the individuals with an invalid fitness\n",
    "                    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "                    #fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "                    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "                    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                        ind.fitness.values = fit\n",
    "                    pop[:] = offspring\n",
    "                    print(\"Gather all the fitnesses in one list and print the stats\")\n",
    "                    # Gather all the fitnesses in one list and print the stats\n",
    "                    fits = [ind.fitness.values[0] for ind in pop]\n",
    "                    length = len(pop)\n",
    "                    mean = sum(fits) / length\n",
    "                    sum2 = sum(x * x for x in fits)\n",
    "                    std = abs(sum2 / length - mean**2) ** 0.5\n",
    "                    print(f\"min: {min(fits)}, max: {max(fits)} , mean: {mean}, std: {std}\")\n",
    "                    # pool.close() # experimental\n",
    "                    #Additional eval stage for generation truncation:\n",
    "                    #argmin... or argmax for auc\n",
    "\n",
    "                    #calculate the best individual from within the population by arg min or max on target metric\n",
    "                    best = pop[np.argmax([toolbox.evaluate(x) for x in pop])]\n",
    "                    #best_pred = get_best_y_pred(best)\n",
    "                    #gen_eval_score = metrics.roc_auc_score(y_test_orig, best_pred)\n",
    "\n",
    "                    #With best individual from population, evaluate their ensemble score on metric\n",
    "                    y_pred = get_y_pred_resolver(best, valid=False)\n",
    "\n",
    "                    gen_eval_score = metrics.roc_auc_score(y_test, y_pred)  \n",
    "                    print(f\"gen_eval_score == {gen_eval_score} Generation {g}\")\n",
    "                    generation_progress_list.append(gen_eval_score)\n",
    "\n",
    "\n",
    "\n",
    "                    if(gen_eval_score < highest_scoring_ensemble[0]):\n",
    "                        gen_eval_score_counter = gen_eval_score_counter + 1\n",
    "                        if(debug):\n",
    "                            print(f\"gen_eval_score_counter {gen_eval_score_counter}, highest so far: {highest_scoring_ensemble[0]}\")\n",
    "\n",
    "\n",
    "                        if(gen_eval_score_counter > gen_eval_score_threshold_early_stopping):\n",
    "                            stop_early = True\n",
    "                    elif(gen_eval_score > highest_scoring_ensemble[0]):\n",
    "                        if(debug):\n",
    "                            print(f\"gen_eval_score gain: {gen_eval_score-gen_eval_score_previous} rate: {(highest_scoring_ensemble[0]-0.5)/g} ETA: {round(((1-highest_scoring_ensemble[0])/(gen_eval_score_gain+1.00000000e-99)))}\")\n",
    "                        gen_eval_score_gain = gen_eval_score_gain + (gen_eval_score-gen_eval_score_previous)\n",
    "                        gen_eval_score_counter = 0\n",
    "\n",
    "                    if(gen_eval_score> highest_scoring_ensemble[0]):\n",
    "                        highest_scoring_ensemble = (gen_eval_score, best)  \n",
    "\n",
    "\n",
    "                    gen_eval_score_previous = gen_eval_score\n",
    "\n",
    "                pbar.close()  \n",
    "\n",
    "                #best = pop[np.argmax([toolbox.evaluate(x) for x in pop])] #was argmin\n",
    "\n",
    "                #Get stored highest ensemble\n",
    "                best = highest_scoring_ensemble[1]\n",
    "\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(\"Best Ensemble Model: \")\n",
    "                for i in range(0, len(best[0])):\n",
    "                    print(best[0][i][1], \"n features: \", len(best[0][i][2]))\n",
    "                    \n",
    "                print(f\"Best Ensemble diversity score: {measure_binary_vector_diversity(best)}\")\n",
    "                    \n",
    "                end = time.time()\n",
    "                print(end - start)\n",
    "\n",
    "\n",
    "                try:\n",
    "                    print(\"Getting final final best pred for plot with validation set, get weights from xtrain ytrain\")\n",
    "                    best_pred_orig = get_y_pred_resolver(best, valid=True)\n",
    "\n",
    "                    plot_auc(\n",
    "                        best_pred_orig,\n",
    "                        \"best_pop=\" + str(pop_val) + \"_g=\" + str(g_val) + \"_nb=\" + str(nb_val),\n",
    "                    )\n",
    "                    print(\"nb_val:\", nb_val, \"pop_val:\", pop_val, \"g_val:\", g_val,\n",
    "                          \"AUC: \", metrics.roc_auc_score(y_test_orig, best_pred_orig), \"g:\", g)\n",
    "                except Exception as e:\n",
    "                    print(\"Failed to get best y pred and plot auc\")\n",
    "                    print(e)\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                end = time.time()\n",
    "                print(\"nb_val:\", nb_val, \"pop_val:\", pop_val, \"g_val:\", g_val,\n",
    "                          \"AUC: \", metrics.roc_auc_score(y_test_orig, best_pred_orig), \"Run Time (min): \", round((end - start)/60, 3), \"g:\", g)\n",
    "                master_result_list.append([\"nb_val:\", nb_val, \"pop_val:\", pop_val, \"g_val:\", g_val,\n",
    "                          \"AUC: \", metrics.roc_auc_score(y_test_orig, best_pred_orig), \"Run Time (min): \", round((end - start)/60, 3), \"g:\", g])\n",
    "\n",
    "\n",
    "                with open(file_path+\"/progress_logs/\"+current_log_filename, \"a\") as myfile:\n",
    "                    myfile.write(' '.join([str(i) for i in [\"nb_val:\", nb_val, \"pop_val:\", pop_val, \"g_val:\", g_val,\n",
    "                          \"AUC: \", metrics.roc_auc_score(best_pred_orig, best_pred_orig), \"Run Time (min): \", round((end - start)/60, 3), \"g:\", g]]))\n",
    "                    myfile.write('\\n')\n",
    "                    myfile.close()\n",
    "                date = datetime.datetime.now().strftime(\"%Y_%m_%d-%I:%M:%S_%p\")\n",
    "\n",
    "                with open(f'{file_path}/results_master_lists/master_result_list_{date}.pkl', 'wb') as f:\n",
    "                    pickle.dump(master_result_list, f)\n",
    "\n",
    "                try:\n",
    "                    print(\"Writing grid perturbation to log\")\n",
    "                    #write line to best grid scores---------------------\n",
    "                    column_list = ['nb_size', 'f_list', 'auc','mcc','f1','precision','recall','accuracy', \n",
    "               'nb_val', 'pop_val', 'g_val', 'g', 'weighted', \n",
    "               'use_stored_base_learners', 'store_base_learners',\n",
    "               'resample', 'scale', 'n_features', 'param_space_size', 'n_unique_out',\n",
    "               'outcome_var_n', 'div_p', 'percent_missing', 'corr', \n",
    "                'age', 'sex', 'bmi','ethnicity', 'bloods', 'diagnostic_order',\n",
    "                'drug_order', 'annotation_n', 'meta_sp_annotation_n',\n",
    "                'meta_sp_annotation_mrc_n','annotation_mrc_n',\n",
    "                'core_02','bed','vte_status','hosp_site','core_resus','news',\n",
    "                'X_train_size', 'X_test_orig_size', 'X_test_size',\n",
    "                'run_time', 'cxpb', 'mutpb', 'indpb', 't_size']\n",
    "\n",
    "                    column_list = column_list +['BL_' + str(x) for x in range(0, 64)]\n",
    "\n",
    "                    line = pd.DataFrame( data = None, columns = column_list)\n",
    "\n",
    "\n",
    "                    auc = metrics.roc_auc_score(y_test_orig, best_pred_orig)\n",
    "                    mcc = matthews_corrcoef(y_test_orig, best_pred_orig)\n",
    "                    f1  = f1_score(y_test_orig, best_pred_orig, average='binary')\n",
    "                    precision = precision_score(y_test_orig, best_pred_orig, average='binary')\n",
    "                    recall = recall_score(y_test_orig, best_pred_orig, average='binary')\n",
    "                    accuracy = accuracy_score(y_test_orig, best_pred_orig)\n",
    "\n",
    "                    \n",
    "                    for key in global_param_dict:\n",
    "                        #print(key)\n",
    "                        if key != 'data':\n",
    "                            if(key in column_list):\n",
    "                                line[key] = [global_param_dict.get(key)]\n",
    "                        else:\n",
    "                            for key_1 in global_param_dict.get('data'):\n",
    "                                #print(key_1)\n",
    "                                if(key_1 in column_list):\n",
    "                                    line[key_1] = [global_param_dict.get('data').get(key_1)]\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    for iii in range(0, len(best[0])):\n",
    "                        f_list = []\n",
    "                        current_f = best[0][iii][2]\n",
    "\n",
    "                        current_f_vector = []\n",
    "                        for elem in orignal_feature_names:\n",
    "                            if(elem in current_f):\n",
    "                                current_f_vector.append(1)\n",
    "                            else:\n",
    "                                current_f_vector.append(0)\n",
    "                        #f_list.append(np.array(current_f_vector))\n",
    "                        f_list.append(current_f_vector)\n",
    "                        \n",
    "                        line['BL_' + str(iii)] = [f_list]\n",
    "\n",
    "\n",
    "                    line['nb_size'] = len(best[0])\n",
    "                    #line['f_list'] = [f_list]\n",
    "\n",
    "\n",
    "                    line['auc'] = [auc]\n",
    "                    line['mcc'] = [mcc]\n",
    "                    line['f1'] = [f1]\n",
    "                    line['precision'] = [precision]\n",
    "                    line['recall'] = [recall]\n",
    "                    line['accuracy'] = [accuracy]\n",
    "\n",
    "                    line['nb_val'] = [nb_val]\n",
    "                    line['pop_val'] = [pop_val]\n",
    "                    line['g_val'] = [g_val]\n",
    "                    line['g'] = [g]\n",
    "                    line['X_train_size'] = [len(X_train)]\n",
    "                    line['X_test_orig_size'] = [len(X_test_orig)]\n",
    "                    line['X_test_size'] = [len(X_test)]\n",
    "\n",
    "                    end = time.time()\n",
    "\n",
    "                    line['run_time'] = int((end - start) / 60)\n",
    "                    line['cxpb'] = global_param_dict.get('cxpb')\n",
    "                    line['indpb'] = global_param_dict.get('indpb')\n",
    "                    line['mutpb'] = global_param_dict.get('mutpb')\n",
    "                    line['t_size'] = global_param_dict.get('t_size')\n",
    "                                    \n",
    "\n",
    "\n",
    "                    line[column_list].to_csv(base_project_dir + 'final_grid_score_log.csv' , mode='a', header=False, index=True)   \n",
    "                    #---------------------------    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"Failed to upgrade grid entry\")\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                #Convert model definition to string for low file size\n",
    "                best_str = best.copy()\n",
    "\n",
    "                for i in range(0, len(best_str[0])):\n",
    "                    best_str[0][i] = list(best_str[0][i])\n",
    "                    best_str[0][i][1] = str(best_str[0][i][1])\n",
    "                    best_str[0][i] = tuple(best_str[0][i])\n",
    "\n",
    "                plot_generation_progress_fitness(generation_progress_list)\n",
    "\n",
    "                with open(\n",
    "                    file_path\n",
    "                    + \"best_pop=\"\n",
    "                    + str(pop_val)\n",
    "                    + \"_g=\"\n",
    "                    + str(g_val)\n",
    "                    + \"_nb=\"\n",
    "                    + str(nb_val)\n",
    "                    + \".pkl\",\n",
    "                    \"wb\",\n",
    "                ) as file:\n",
    "                    # dump best_str instead of best which contains actual model. \n",
    "                    #Unnecessary since ensemble can be fitted in deployment\n",
    "                    #Can model always be stored as string during operation of GA?\n",
    "                    pickle.dump(best_str, file)\n",
    "\n",
    "                #Try to reset DEAP for second run. Should be seperate:\n",
    "                from deap import algorithms, base, creator, tools\n",
    "                del toolbox\n",
    "                gc.collect()\n",
    "                creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "                creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "                toolbox = base.Toolbox()\n",
    "                toolbox.register(\"evaluate\", evaluate_weighted_ensemble_auc)\n",
    "\n",
    "\n",
    "\n",
    "            except Exception as Argument:\n",
    "\n",
    "                 date = datetime.datetime.now().strftime(\"%Y_%m_%d-%I:%M:%S_%p\")\n",
    "                 # creating/opening a file\n",
    "                 f = open(f\"{file_path}/GEC_log_{date}.txt\", \"a\")\n",
    "                 # writing in the file\n",
    "                 f.write(str(Argument))\n",
    "                 f.write(str(traceback.format_exc()))\n",
    "                 # closing the file\n",
    "                 f.close()\n",
    "                 print(Argument)\n",
    "\n",
    "\n",
    "\n",
    "                 print(traceback.format_exc())\n",
    "\n",
    "                 continue\n",
    "\n",
    "        for line in (master_result_list):\n",
    "            print(line)\n",
    "            #print(master_result_list)\n",
    "\n",
    "            #best_weight_current = super_ensemble_weight_finder(best)\n",
    "        #         date = datetime.now().strftime(\"%Y_%m_%d-%I:%M:%S_%p\")\n",
    "        #         with open(f'ensemble_weights_found{date}.pkl', 'wb') as f:\n",
    "        #             pickle.dump(best_weight_current, f)\n",
    "\n",
    "\n",
    "        #main()\n",
    "\n",
    "        #del creator.Individual\n",
    "        #optuna or hyperopt integration for defining parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c65b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ea44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a5242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ga_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
